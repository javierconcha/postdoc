\documentclass{book}

\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}
\newcommand{\bm}[1]{\boldsymbol{#1}} 
\usepackage{indentfirst}
\usepackage{multirow}
\usepackage{fullpage}
\usepackage{appendix}
\usepackage{setspace}
\usepackage[bf, small, center]{caption}
\setlength{\belowcaptionskip}{10pt}
\usepackage{longtable}

\usepackage{geometry}
\geometry{
%  top=1.0in,  
%  inner=1.5in,
%  outer=1.5in,
  bottom=1.2in,
%  headheight=3ex, 
  headsep=3ex,         
}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhead[LO, RE]{\rightmark}
\fancyhead[LE, RO]{\thepage}
\fancyfoot[]{}
%\renewcommand{\headrulewidth}{0.3pt}


\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\onehalfspacing

\usepackage[phd]{thesisfrontmatter}

% *** NOTE WHICH PROGRAM GENERATED IMAGES OR WHICH POWER POINT THEY ARE FROM
%compare methodology with script for final process
%how much detail in methodology?
%some sort of processing flowchart?
%how much do we care about processing?


\begin{document}

\degreetitle{Atmospheric Compensation for a Landsat Land Surface Temperature Product}
\degreeauthor{Monica J. Cook}
\degreedate{18 April 2013}
\prevdegreeA{B.S. Rochester Institute of Technology, 2010}
\advisor{Dr. John R. Schott}
\memberA{Dr. Carl Salvaggio}
\memberB{Dr. Emmett J. Ientilucci}
\memberC{Dr. Ernest Fokoue}
\memberD{Dr. Simon J. Hook}

\makeproposaldeclaration
\makePHDproposalapproval
% \makecopyright

\begin{abstract}

The Landsat series of satellites is the longest set of continuously acquired moderate resolution multispectral satellite imagery collected on a single maintained family of instruments.  The data are very attractive because the entire archive has been radiometrically calibrated and characterized so that the sensor reaching radiance values are well known.  Because of the spatial and temporal coverage provided by Landsat, it is an intriguing candidate for a land surface temperature (LST) product.  The entire archive has been calibrated, but effective spectral radiance values are often not intuitively applied, so this dataset has not been utilized to its fullest potential.  Land surface temperature is an important earth system data record for a number of fields including numerical weather prediction, climate research, and various agricultural applications.  The Landsat LST product will make an already existing dataset, that is largely untapped, truly useful to the remote sensing community.

Using the Landsat LWIR thermal band, LST can be derived with a well-characterized atmosphere and known surface emissivity.  This work focuses on atmospheric compensation at each Landsat pixel which will later be used with ASTER derived emissivity data from JPL to perform LST retrievals.  

We develop a method to automatically generate the effective in band radiative transfer parameters transmission, upwelled radiance, and downwelled radiance for each pixel by using the North American Regional Reanalysis dataset as atmospheric profile data in MODTRAN.  Due to differences is temporal and spatial sampling and computational limitations, a number of interpolations are required.  Using water temperatures derived from buoy data at five different validation sites, we can compare our predicted apparent temperature to ground truth data to evaluate the errors in our process.  Preliminary results are very encouraging for the implementation and accuracy of our process; consistent errors of less than 1 K can be achieved in clear atmospheres but hotter and more humid atmospheres have higher errors.  Because certain atmospheric characteristics introduce errors into LST retrievals, some of these errors cannot be improved with changes to our process, so we begin developing a confidence metric estimation to predict and inform users of these errors.  Two initial methods of confidence metric estimation, regression and threshold analysis, are explored; threshold analysis appears more promising and will be developed going forward.

Future work includes improving our method of confidence metric estimation by more appropriately setting thresholds, considering multiple thresholding levels, and using combinations of metrics.  We will also make any final adjustments and improvements to our process and extend our process to create a global product.  This involves selecting a dataset with global coverage and adjusting our process and confidence metric estimation accordingly.

\end{abstract}

\begin{acknowledgements}
We would like to thank NASA and JPL for funding this work.
\end{acknowledgements}

%\begin{dedication}
%This is the dedication text.
%\end{dedication}

\tableofcontents
\listoffigures
\listoftables

\chapter{Introduction}
\label{ch:introduction}

Land surface temperature (LST) is a valuable earth system data record most commonly applied in environmental endeavors, but it is useful in a large variety of applications.  It is difficult to measure without altering the temperature of a surface, so large scale LST results are usually derived from satellite data.  Deriving LST from satellite data requires multiple adjacent thermal bands to implement a split-window approach or a single thermal band with a well understood atmosphere and a surface emissivity.

The Landsat series of satellites is the longest set of continuously acquired moderate resolution multispectral satellite imagery collected on a single maintained family of instruments; they have historically collected a single thermal band.  The data are very attractive, for both current analysis and historical research, because the entire archive has been radiometrically calibrated and characterized so that sensor reaching radiance values are well known.  This, along with the spatial and temporal coverage of archived Landsat scenes, makes Landsat a very intriguing candidate for a wide scale LST product.  However, radiance values from the thermal band are not quantities that can be intuitively applied to solve problems, so this dataset has not been utilized to its fullest potential.  Developing a widely accessible LST product for Landsat would broaden the usability of this vast database of imagery but requires atmospheric characterization and surface emissivity for each Landsat scene.

Recently, a high spatial resolution (100 m) gridded, surface emissivity database has been generated using emissivity information from the Advanced Spaceborne Thermal Emission and Reflection (ASTER) radiometer.  Currently available from this source is the North American ASTER Land Surface Emissivity Database (NAALSED) but plans are underway to extend the dataset to global coverage \cite{hulley_2009}.  Assuming the availability of surface emissivity from the Jet Propulsion Laboratory (JPL), this work is focused on determining the necessary atmospheric characterization for each pixel in a Landsat scene.

The MODerate resolution atmospheric TRANsmission (MODTRAN) radiative transfer code is the standard moderate spectral resolution radiative transport model for the U.S. Air Force.  With the input of the appropriate atmospheric profiles, MODTRAN can be used to generate a characterization of the radiometric properties of the atmosphere at that time and place; we will use these characterizations to generate the atmospheric parameters necessary to solve for the temperature of the surface \cite{modtran}.  The atmospheric profiles required to execute MODTRAN are extracted from the North American Regional Reanalysis (NARR) dataset.  The NARR dataset provides atmospheric variables at a fixed array of pressures on a fixed spatial grid in three-hour intervals \cite{narr}.

The NARR data set is not sampled at the same resolution as the Landsat scenes, in time or space, and it is impractical to execute MODTRAN for every Landsat pixel.  Because of these differences in temporal and spatial resolution, we need to interpolate atmospheric profiles and radiative transfer parameters.  Our goal is to optimize this data integration and interpolation to minimize errors in the final retrieved LST.

As with any scientific product, an evaluation of the error in the final quantity is required.  The MODTRAN simulations, integration of datasets, and various interpolations make a traditional error analysis unreasonable.  Predicted temperatures were compared to actual water temperatures from moored buoys to calculate error values for the final retrieved LST.  Using a sample of points where the errors are known, a process will be developed to assign confidence values to the final LST based on derived temperature, cloud data, and atmospheric data.

Assuming the availability of an emissivity product, deliverables of this process include the Landsat thermal band radiance, elevation, transmission, upwelled radiance, and downwelled radiance of each pixel, along with the confidence metrics.  It is not yet clear whether the confidence estimation will be qualitative or quantitative.  With this information, only the emissivity, and any associated error, is required to develop the complete land surface temperature product.

As will be shown, initial results are extremely encouraging for the feasibility of a Landsat LST.  We will begin with a North American product and later extend this to a global product.

\chapter{Objectives}
\label{ch:objectives}

As alluded to in Chapter \ref{ch:introduction}, generating a land surface temperature product is a complex and multi-step process.  It is helpful to divide the project into separate tasks.  Section \ref{sec:problemstatement} details the problem being approached.  Section \ref{sec:objectives} outlines the project as four separate objectives and Section \ref{sec:tasks} expands on each of these tasks.  The chapter closes with a summary of the contribution of the project to the field of remote sensing.

\section{Problem Statement}
\label{sec:problemstatement}

The goal of our work is to develop a process to automatically generate the atmospheric parameters for a land surface temperature product for all current and historical Landsat scenes.  Characterizing the atmosphere and generating the atmospheric parameters necessary to calculate the LST at each pixel requires knowledge of the atmospheric profile data at the necessary temporal and spatial resolution and use of these profiles in the radiative transfer code to predict the radiative transfer parameters.

\section{Objectives}
\label{sec:objectives}

\begin{enumerate}

\item Determine a data source that can be integrated into MODTRAN with the appropriate atmospheric variables at reasonable temporal and spatial resolution and coverage for current and archived Landsat scenes in North America.

\item Develop an automated process to generate the appropriate radiative transfer parameters at each Landsat pixel.

\item Evaluate results and generate a confidence metric.

\item Extend this process to global coverage.

\end{enumerate}

\section{Tasks}
\label{sec:tasks}

\begin{enumerate}

{\bf \item Determine a data source that can be integrated into MODTRAN with the appropriate atmospheric variables at reasonable temporal and spatial resolution and coverage for current and archived Landsat scenes in North America.}

This process will require atmospheric profiles that accurately predict pressure, temperature, and one of a number of possible variables that predict humidity or water vapor at various heights.  Generally, this is most accurately characterized with a radiosonde, a weather balloon that is released and rises through the atmosphere transmitting observations of various atmospheric parameters.  However, because of the extent of spatial and temporal coverage and the resolution of the Landsat scenes, radiosonde data may not be the best solution for this work.  We need to identify and evaluate a dataset that is accessible and provides the same variables over the desired time and space.

{\bf \item Develop an automated process to generate radiative transfer parameters at each Landsat pixel.}

Once the atmospheric profiles have been determined, MODTRAN can be used to generate the appropriate radiative transfer parameters: transmission, upwelled radiance, and downwelled radiance.  There are various methods for generating such parameters using MODTRAN; each method needs to be evaluated for accuracy as well as computational considerations.  We need to develop an automated process to integrate the atmospheric profile data, execute the MODTRAN runs, and generate the parameters.

The spatial and temporal resolution of the atmospheric data will not match that of the Landsat scenes.  The computational requirements to use MODTRAN to generate radiative transfer parameters at every pixel are impractical.  Therefore, studies will need to be conducted in order to evaluate the necessary number of MODTRAN runs and their optimal locations and elevations.  The atmospheric profile data needs to be interpolated to the appropriate MODTRAN runs, and the resulting radiative transfer parameters need to be interpolated to the location and elevation of each pixel.  Both the nature and number of interpolations need to be optimized to reduce errors in the final product.

{\bf \item Evaluate results and generate a confidence metric.}

It is unreasonable to perform a traditional error analysis because of the complexity of the process, but our resulting quantity should include an estimation of uncertainty.  Directly measuring the temperature of any land surface is difficult because the act of measuring often changes the observed temperature.  However, the surface temperature of water can more easily be directly measured given the ability to submerge and acclimate an instrument.  Buoy data from various geographical locations can be used to calculate the actual error associated with the predicted land surface temperature at a sample of water pixels; these error results will be used to develop a process to predict a confidence value for the final retrieved temperature based on atmospheric data used in the process.  Analysis will determine if this confidence metric is qualitative or quantitative.

{\bf \item Extend this process to global coverage.}

This process will first be developed and validated for North American Landsat scenes.  However, one of the benefits of Landsat is the global coverage.  This product should utilize all scenes within the Landsat database and will be extended to a global product.

\end{enumerate}

\section{Contribution to Field}
\label{sec:contributiontofield}

This product will make unique contributions to the field of remote sensing.  

Firstly, we develop a novel approach to large-scale single band land surface temperature retrieval.  Most single band approaches require sounding data or other manual measurements to generate LST for only a single scene; our method of automatically integrating atmospheric data is unique.

Secondly, while there are other global temperature products, Landsat provides a unique combination of spatial and temporal resolution with at best 60 m pixels and a 16 day repeat cycle.  This moderate spatial and temporal resolution lends itself to the applications that can best make use of a land surface temperature product.

Finally, this project puts to use a large dataset with unrealized potential.  Landsat has been collecting thermal data singe 1982 but the potential of the such wide-reaching temporal and spatial coverage is unrealized because of the inability to intuitively apply radiance values.  The Landsat LST product will make an already existing dataset, that is largely untapped, truly useful to the remote sensing community.

\chapter{Background}
\label{ch:background}

Remote sensing can be described as the study from a distance of the interactions of electromagnetic energy with the object of interest and how this energy is measured by an imaging system.  The purpose of this chapter is to provide the necessary background knowledge and science to understand our approach to LST retrieval through remote sensing.  The chapter begins with a description of sensor reaching radiance and the thermal governing equation.  Secondly, a brief history of Landsat and the capabilities of each sensor in the family are discussed to provide an understanding of the data being used.  Thirdly, a description of applications that may utilize LST as well as both multiple and single band retrieval is discussed.  Next, a description of the NARR dataset is provided and the capabilities and uses of MODTRAN are described.  Finally, the chapter concludes with the explanation of data conversions used in the process.

\section{Sensor Reaching Radiance}
\label{sec:remotesensing}

This work only focuses on thermal energy reaching the sensor.  Tables \ref{tab:TMbands} and \ref{tab:ETMbands} show that the thermal band of Landsat is sensitive from approximately 10.40 $\mu$m to 12.50 $\mu$m.  Thermal energy in this portion of the electromagnetic spectrum is self-emitted from objects due to their temperature.  The thermal energy paths that contribute to the sensor reaching radiance are shown in Figure \ref{fig:energypaths}.  

The atmosphere above the target has some temperature, and therefore radiates energy, some of which reaches the sensor.  Path A in Figure \ref{fig:energypaths} is energy that is self-emitted from the atmosphere and scattered toward the sensor.  This is often referred to as upwelled or path radiance.  Self-emitted energy from the atmosphere can also be scattered toward and reflect off the target before reaching the sensor.  This is path B in Figure \ref{fig:energypaths} and referred to as the downwelled radiance.  Path C is the radiation due to the temperature of the target of interest.  This is ultimately the energy that we wish to quantify in order to determine the temperature of the target.  Finally, objects surrounding the target also have some temperature and therefore radiate energy.  This energy can reflect off the target and also reach the sensor, as shown in Path D.  When there are few background objects or they obscure only a small fraction of the sky, the photons from this energy path can often be considered negligible; we will make use of this assumption in our work \cite{schott}.  

% powerpoint in PROPOSAL/background
\begin{figure}%[H]
\centering
\includegraphics[scale = 0.75]{background/energypaths}
\caption{Thermal energy paths contributing to the sensor reaching radiance.}
\label{fig:energypaths}
\end{figure}

The summation of paths A, B, and C compose the thermal sensor reaching radiance captured by the thermal band of the Landsat sensors.  As will be described, separating and characterizing each energy path is critical to determining the temperature of the target.

\section{Governing Equation}
\label{sec:governingequation}

A governing equation includes all of the pertinent components of the sensor reaching radiance in the wavelength range of interest.  The governing equation for Landsat band 6 is shown in Equation \ref{eq:governing}

\begin{equation}
L_{obs{{\lambda}eff}} = (L_{T{{\lambda}eff}}\epsilon+(1-\epsilon)L_{d{\lambda}eff})\tau + L_{u{\lambda}eff}
\label{eq:governing}
\end{equation}

where $L_{obs{{\lambda}eff}}$ is the sensor reaching effective spectral radiance, $L_{T{\lambda{eff}}}$ is the effective spectral radiance due to temperature (path C in Figure \ref{fig:energypaths}), $\epsilon$ is the surface emissivity of the pixel of interest, $\tau$ is the transmission, $L_{u{\lambda{eff}}}$ is the upwelled effective spectral radiance (path A in Figure \ref{fig:energypaths}), and $L_{d{\lambda{eff}}}$ is the downwelled effective spectral radiance (path B in Figure \ref{fig:energypaths}).  The radiance due to the temperature of the target pixel is the term that needs to be isolated; it can then be inverted to temperature of the ground using Equation \ref{eq:planck}, a variation of Planck's Equation, where $M_{\lambda{eff}}$ is effective spectral exitance, h is Planck's constant, c is the speed of light, k is the Boltzman constant, and T is the desired temperature. The function $R(\lambda)$ is the spectral response function of the Landsat sensor; these spectral response functions vary slightly for each sensor.  The integration is over the wavelength range of interest, in this case, the sensitivity of Landsat band 6.  Equation \ref{eq:planck} cannot be directly solved for T, so we use a look up table (LUT) to determine T given the $L_{T{\lambda{eff}}}$ and range of wavelengths.  We generate an effective spectral radiance due to temperature value for every temperature (in 1 K increments) within a reasonable range of land surface temperatures; the integration is performed over the wavelength range of the thermal band.  When we determine a $L_{T{\lambda{eff}}}$ value from Equation \ref{eq:governing}, we use a two point linear interpolation in the LUT to determine T.

\begin{equation}
L_{T{{\lambda}eff}} = \frac{M_{\lambda{eff}}}{\pi} = \frac{[\int 2{h}c^2 \lambda^{-5} (e^{\frac{hc}{\lambda kT}}-1)^{-1}]R(\lambda) d\lambda}{\int{R(\lambda)d\lambda}}
\label{eq:planck}
\end{equation}

$L_{obs{{\lambda}eff}}$ is the effective spectral radiance reaching the sensor.  This can be determined (in $Wm^{-2}sr^{-1}\mu{m}^{-1}$) from the calibrated digital number in the Landsat image file using Equation \ref{eq:calibration}.  In Equation \ref{eq:calibration}, $Q_{cal}$ is the quantized pixel value in digital counts, $Q_{calmin}$ and $Q_{calmax}$ are the minimum and maximum quantized calibrated pixel values (digital counts 0 and 255) corresponding to $LMIN_\lambda$ and $LMAX_\lambda$ respectively.  Similarly, $LMIN_\lambda$ and $LMAX_\lambda$ are the effective spectral radiance values ($Wm^{-2}sr^{-1}\mu{m}^{-1}$) scaled to $Q_{calmin}$ and $Q_{calmax}$ respectively \cite{cHander_2003}.  $LMIN_\lambda$, $LMAX_\lambda$, $Q_{calmin}$, and $Q_{calmax}$ are given with the image metadata.  

Because of the longevity of the Landsat program, and the efforts that have been put forth to maintain and re-establish calibration, for the purpose of this research, a calibrated instrument can be assumed.  This means the given calibration coefficients can be used to convert digital count to radiance and this radiance value can be used and trusted without independent validation \cite{barsi_2003}, \cite{padula_2010}. \\

\begin{equation}
L_{obs{{\lambda}eff}} = \bigg(\frac{LMAX_\lambda - LMIN_\lambda}{Q_{calmax}}\bigg)Q_{cal}+LMIN_\lambda
\label{eq:calibration}
\end{equation}

In these cases, the ${\lambda}eff$ indicates an effective spectral value of radiance per unit wavelength in units of $Wm^{-2}sr^{-1}{\mu}m^{-1}$, which means that the spectral response function has been incorporated as shown in Equation \ref{eq:effective}, where L could represent any type of radiance value.  We use all effective spectral values in this work and therefore will continue from this point forward without the explicit notation.

\begin{equation}
L_{{\lambda}eff} = \frac{\int{L_{\lambda}R(\lambda)d\lambda}}{\int{R(\lambda)d\lambda}}
\label{eq:effective}
\end{equation}

\section{Landsat History}
\label{sec:landsathistory}

First conceived in the 1960s, Landsat is the longest set of continuously acquired moderate resolution satellite imagery.  Although there were various weather satellites monitoring the Earth's atmosphere, there was little imagery that documented Earth's surface and the terrain.  Initially, the idea of an Earth-observing satellite program was met with opposition due to concerns about cost, usability, and the political implications of capturing images of other countries.  Despite these concerns, NASA began constructing the first Landsat satellite in 1970, known at the time as the Earth Resources Technology Satellite (ERTS).

Landsat, as the longest and only continuous record of the global land surface, can be applicable in work concerning agriculture, geology, forestry, mapping, and change detection among other applications.  This dataset has been accessible to a wide community of users since all Landsat data became freely available in December 2009 \cite{landsat_nasa}.

A brief summary of all Landsat sensors is shown below;  this tool is designed for single thermal band imagery so that it can be used for all thermal infrared images in the archive (Landsats 4, 5, and 7).  The only modification from one sensor to another is inserting a different spectral response function.  Future work will include considering how this methodology can be utilized with Landsat 8.

\subsection{Landsats 1, 2, and 3}
\label{sec:landsats123}

ERTS was launched in July 1972.  This system, later renamed Landsat 1, operated until 1978, and exceeded expectations for both data quality and quantity.  Landsat 2 launched in January 1975 and Landsat 3 in March 1978 \cite{landsat_nasa}.  The first three landsat instruments carried the same two sensors.  The Return Beam Vidicon (RBV) and the Multi-Spectral Sensor (MSS) both had bands in the visible and near-infrared (NIR).  Landsat 3 MSS actually had an additional thermal band in the long wave infrared, but this channel failed shortly after launch.  Landsats 2 and 3 were decommissioned in July 1983 and September 1983 respectively \cite{landsat_nasa}.  These satellites cannot be used to calculate the land surface temperature because they did not capture a thermal band.

\subsection{Landsat 4}
\label{sec:landsat4}

Landsat 4 was launched in July 1982; this was the first Landsat to significantly differ from the original and the first to have a functioning long-wave thermal band (imagery that can be used to calculate land surface temperature).  Landsat 4 carried the MSS instrument, identical to that on Landsats 1, 2 and 3, with four spectral bands in the visible and NIR and 57 m x 79 m pixels.  Landsat 4 also carried the Thematic Mapper (TM) with 7 spectral bands composed of 3 visible, 2 NIR, 1 short wave IR, and 1 thermal band.  All bands had 30 m x 30 m pixels, except the thermal band which had 120 m x 120 m pixels.  The spectral bands of the TM instrument are shown in Table \ref{tab:TMbands}.  Each scene captured was 170 km x 185 km \cite{landsat_usgs}.  Landsat 4 was not decommissioned until December 2001, although it stopped downlinking data in 1993 \cite{landsat_nasa}.

\begin{table}[H]
\begin{center}
\begin{tabular}{|c | c | c | c |}
\hline
Band & Spectrum Area & Response ($\mu$m) & Resolution \\ \hline
Band 1 & Visible & 0.45 - 0.52 & 30 m \\ \hline
Band 2 & Visible & 0.52 - 0.60 & 30 m \\ \hline
Band 3 & Visible & 0.63 - 0.69 & 30 m \\ \hline
Band 4 & NIR & 0.76 - 0.90 & 30 m \\ \hline
Band 5 & NIR & 1.55 - 1.75 & 30 m \\ \hline
Band 6 & Thermal & 10.40 - 12.50 & 120 m \\ \hline
Band 7 & Mid-wave IR & 2.08 - 2.35 & 30 m \\ \hline
\end{tabular}
\caption{Spectral bands of the Landsat Thematic Mapper \cite{landsat_usgs}.}
\label{tab:TMbands}
\end{center}
\end{table}

The TM instrument is a line scanner and captures images using a Ritchey-Chretien telescope \cite{engel_1983}.  Line scanners, diagrammed in Figure \ref{fig:linescanner}, achieve along track motion by the advancement of the satellite and across track motion via an oscillating scan mirror.  An oscillating scan mirror requires a scan-line corrector to align scans to eliminate data gaps; this process is illustrated in Figure \ref{fig:slc}.

% from Schott's book
\begin{figure}%[H]
\centering
\includegraphics[scale = 0.65]{background/linescanner}
\caption{Optical layout of a line scanner \cite{schott}.}
\label{fig:linescanner}
\end{figure}

% from Schott's book
\begin{figure}[H]
\centering
\includegraphics[scale = 0.65]{background/slc}
\caption{Operation of the scan line corrector on a line scanner \cite{schott}.}
\label{fig:slc}
\end{figure}


\subsection{Landsat 5}
\label{sec:landsat5}

Landsat 5 launched in March 1984 carrying the same payload as Landsat 4.  The system has experienced some problems with downlinking data, and the MSS was deactivated in 1995, but the TM has been operating for 28 years, 25 years longer than the minimum design life of 3 years.  In November 2011, Landsat 5 stopped acquiring images due to degrading electrical components.  Rather than operating until complete failure, the system was turned off for a period to investigate restorations or other options for image-to-ground transmission \cite{landsat_nasa}.  The Landsat 5 TM already provides a tremendous amount of archived data.

Landsat 4 and Landsat 5 were privatized in 1984 and operated by a commercial vendor for 17 years.  This led to a host of problems, including rising image prices, gaps in data collection, and lapses in system characterization and calibration.  During this time of commercial operation, Landsat 6 was also built but failed to reach orbit.  Landsats 4 and 5 were the only two of the series to ever be commercialized; operational control was returned to the federal government in 2001 \cite{landsat_nasa}.

\subsection{Landsat 6}
\label{sec:landsat6}

Privately owned, Landsat 6 failed to reach orbit during its October 1993 launch due a ruptured rocket fuel chamber.  The loss of Landsat 6 led to concerns about a data-gap, which would have been realized had Landsat 5 not long out-lasted its expected lifetime \cite{landsat_nasa}.

\subsection{Landsat 7}
\label{sec:landsat7}

Landsat 7 launched in April 1999 carrying the Enhanced Thematic Mapper Plus (ETM+), also a line scanner.  The spectral bands on the ETM+ are shown in Table \ref{tab:ETMbands}; improvements includes better resolution for the thermal band and the addition of a higher resolution panchromatic band \cite{landsat_usgs}.

\begin{table}[H]
\begin{center}
\begin{tabular}{|c | c | c | c |}
\hline
Band & Spectrum Area & Response ($\mu$m) & Resolution \\ \hline
Band 1 & Visible & 0.45 - 0.52 & 30 m \\ \hline
Band 2 & Visible & 0.52 - 0.60 & 30 m \\ \hline
Band 3 & Visible & 0.63 - 0.69 & 30 m \\ \hline
Band 4 & NIR & 0.77 - 0.90 & 30 m \\ \hline
Band 5 & NIR & 1.55 - 1.75 & 30 m \\ \hline
Band 6 & Thermal & 10.40 - 12.50 (High and Low Gain Options) & 60 m \\ \hline
Band 7 & Mid-wave IR & 2.08 - 2.35 & 30 m \\ \hline
Band 8 & Panchromatic (PAN) & 0.52 - 0.90 & 15 m \\ \hline
\end{tabular}
\caption{Spectral bands of the Landsat Enhanced Thematic Mapper Plus \cite{landsat_usgs}.}
\label{tab:ETMbands}
\end{center}
\end{table}

Landsat 7 was designed to have improved calibration from previous Landsat instruments to be better for land cover monitoring, change detection and global mapping.  Unfortunately, the scan line corrector on the ETM+ failed in May 2003 leaving gaps in each scene as illustrated in Figure \ref{fig:slc}(a).  Better calibrated data is difficult to effectively utilize with so many missing pixels, but the instrument continues to collect and downlink imagery that is archived in ``SLC-off mode," which captures approximately 75 percent of each scene.  To deal with scan gaps as well as missing data due to clouds, the science community is increasingly looking to data composited from ``good" pixels from multiple acquisitions.  For this to be effective, the data often need to be in physical unity (reflectance, temperature, etc.) to be useful.  Thus, while not a primary objective, this effort will provide support for compositing activities. 

\subsection{LDCM}
\label{sec:ldcm}

The Landsat Data Continuity Mission (LDCM) is scheduled to launch in February 2013 to continue Landsat's continuous observation of the Earth's surface.  With Landsat 5 ailing and Landsat 7 operating in SLC-off mode, the launch of LDCM is imperative to avoid a data gap \cite{landsat_usgs}.

\section{Land Surface Temperature}
\label{sec:landsurfacetemperature}

The land surface is the first solid surface between the lowest layer of the atmosphere and the Earth.  From the point of view of thermal imaging from a satellite, this is generally considered to be a few millimeters thick and could consist of forest and shrubs, crops, grasslands, bodies of water, wetlands, ice or snow, barren or desert, urban, bare soil, bedrock, sand or sediments \cite{wan_1996}.  Although not immediately obvious, the temperature of this land surface is individually an important data record as well as a tool used in obtaining and analyzing other variables.  Identified by NASA as an important Earth System Data Record as part of the Earth Observing System (EOS) program \cite{king_1999}, LST can be utilized in a number of fields for a wide variety of applications.

LST products from a number of different satellites are already produced and various methods exist for obtaining LST from a single image for a number of different instruments.  These, along with multiple channel methods, will be reviewed as a basis for existing work and accuracy in the field.  However, the spatial and temporal coverage of a global Landsat land surface temperature product is not yet realized and would be extremely useful to a wide array of users.

\subsection{Applications}
\label{sec:applications}

Land surface temperature results from interactions with and energy fluxes from the ground, making it a variable with far-reaching uses and applications in the physics of land surface processes \cite{sellers_1988}.  On large scales, it can be used to evaluate land surface energy balance \cite{diak_1993}.  Because land surface temperature results from interactions between the atmosphere and the ground and is affected by various environmental variables, it is useful in terrestrial biosphere dynamics, change detection, hydrologic balances, and biogeochemistry of greenhouse gases.  Hydrologic processes, such as evapotranspiration and snow melt, are sensitive to LST, as well as climate change and carbon cycles.  Ecological processes, mostly associated with agriculture and the growing season, such as leaf phenology, photosynthesis, respiration and decomposition can all be affected by LST.  Finally, LST not only affects land cover change but can also be used to delineate regional land cover classes \cite{running_1994}.  It can be applied in land cover and land cover change analysis \cite{ehrlich_1996}.

LST is also invaluable in climate studies and meteorological research.  There are various surface properties that are required to estimate energy, momentum, and moisture fluxes at Earth's surface used in numerical meteorological predictions.  These surface properties, such as LST, can be estimated from satellite data, to be used in climatology and weather science \cite{price_1982}.  LST can also be used to study other weather patterns, such as the monsoon season is Asia, where the land-sea temperature contrast is a critical concept.  Stronger summer monsoons, and lower land albedos, are associated with greater land-sea temperature contrast and warmer land temperature among other variables \cite{meehl_1994}.

On smaller scales, LST can be used to determine moisture availability and absorbed radiation used in estimating sensible and latent heat fluxes \cite{kimuru_1994}.  There are many applications in agriculture, specifically uses in canopy temperature or soil temperature.  Canopy temperatures can be used to estimate sensible heat flux \cite{vinning_1992}, evaluate water requirements \cite{jackson_1977}, and determine frosts in orange groves \cite{caselles_1989}.  Soil temperatures can be used to monitor and prepare response to drought \cite{feldhake_1996}.  In summary, uses of LST are highly variable and many are well-matched to the coverage and resolution of the Landsat data, giving us confidence in the purpose of our work.

\subsection{Multiple Thermal Bands}
\label{sec:multiplethermalbands}

The most commonly used LST algorithms require two adjacent spectral bands.  Instead of utilizing atmospheric compensation that requires accurate atmospheric profiles like the single band methodology, the split-window techniques use differences in absorption in adjacent thermal bands to make the necessary corrections for atmospheric effects.

Wan and Dozier (1996) propose a generalized split-window technique using regression analysis and radiative transfer simulations.  They point out that the success of any LST algorithm depends on the atmospheric compensation, the characterization of the surface emissivity, and the quality of the thermal infrared data.  With the Landsat and ASTER databases, the basis of this research assumes high radiometric data quality and surface emissivity, and therefore focuses solely on dealing with the atmospheric effects.  This generalized split-window algorithm utilizes differential absorption in adjacent thermal bands.  The split-window algorithms are less sensitive to errors in atmospheric optical properties because it does not rely on the absolute atmospheric transmission of a single band.  They do, however, require radiative transfer simulations over a wide range of atmospheric and surface conditions in order to generate the necessary coefficients \cite{wan_1996}.

Because of the requirement for both atmospheric compensation and emissivity data, many LST algorithms are not operational.  Vazquez et al. (1997) compares four split window algorithms for the National Oceanic and Atmospheric Administration (NOAA) Advanced Very High Resolution Radiometer (AVHRR) using directly measured 5 cm subsurface temperatures of soils in an area of low water vapor and low probability of cloudiness (good conditions) as ground based truth validation.  All methods require a priori knowledge of the surface emissivity.  For these four split-window algorithms, the root mean square deviations from ground based temperatures are 3.8 K, 3.0 K, 2.3 K, and 1.9 K and the mean bias deviations are 3.3 K, 1.8 K, 0.1 K, and 0.7 K respectively; all showed an overestimation of the high, summer morning temperatures and had maximum deviations between 4 K and 8 K \cite{vazquez_1997}.  This shows that while LST retrieval from AVHRR data is feasible, it requires accurate knowledge of surface emissivity and can be highly variable.

Sun and Pinker (2003) discuss algorithms for use with the Geostationary Operational Environmental Satellite (GOES).  While this satellite provides good spatial coverage and would allow for frequent estimates of LST, these algorithms are not implemented operationally due to the requirement of emissivity and the variation of coefficients with emissivity and atmospheric water vapor.  They compare previously published generalized split-window algorithms, with and without water vapor correction, to a newly proposed algorithm and a three-channel approach.  The generalized split-window algorithm has errors greater than 0.5 K, and greater than 1 K at temperatures over 290 K.  The split-window with water vapor correction was an improvement with error less than 0.5 K for temperatures less than 290 K.  The newly proposed algorithm was a slight improvement over these results.  The three-channel algorithm, for nighttime retrieval, shows improvement over the generalized split-window approach.  Errors in the retrieved LST also differ with season, with an RMS error of 2.3 K in the summer but an RMS error as low as 1.38 K in the winter \cite{sun_2003}.

Finally, the Earth Observing System (EOS) Moderate Resolution Imaging Spectroradiometer (MODIS) instrument produces a daily  land surface temperature product using multiple thermal bands.  This is, therefore, an operational algorithm.  MODIS can provide global coverage, high spectral resolution, and accurately calibrated data.  MODIS utilizes multiple bands in atmospheric windows for its LST retrieval; it implements a generalized split-window algorithm and a physics-based day/night algorithm.  With seven available thermal infrared bands, this algorithm can adjust for uncertainties in temperature and water vapor profiles without simultaneous retrieval of surface data or atmospheric variable profiles.  Emissivity is also immediately required for an operational product, so MODIS estimates classification-based emissivities from land-cover types using thermal infrared BRDFs and emissivity modeling.  Over certain land cover types in the range of 263 K to 300 K, the MODIS LST can be better than 1 K, but can underestimate temperatures in semi-arid regions due to inaccuracies in the estimated surface emissivity \cite{wan_2004}.  MODIS does have lower spatial resolution than Landsat, which makes this product difficult to apply in certain applications that require LST, such as field specific agriculture or irrigation studies.

\subsection{Single Thermal Band}
\label{sec:singlethermalband}

As mentioned above, and noted by Sobrino et al. (2004), one thermal band limits the ability to retrieve LST due to the inability to apply a split-window algorithm or a temperature-emissivity separation.

Sobrino et al. (2004) compare three methods of temperature retrieval using Landsat band 6 data.  The first uses radiosonde data and the radiative transfer equation, the second Qin et al.'s (2001) mono-window algorithm, and the third Jimenez-Munoz and Sobrino's (2003) single-channel method.  They propose obtaining land surface emissivity using the NDVI method, which requires atmospheric compensation of Landsat bands 3 and 4 for the most accurate results.  They use the LST derived from radiosonde data and in situ emissivity measurements as ``truth," or a basis for comparison to all other methods, illustrating that these are considered the most accurate even though the radiative transfer equation still requires the use of MODTRAN to generate the necessary atmospheric parameters.  Qin et al.'s (2001) mono-window algorithm requires not only emissivity, but also an estimate of water vapor content and near-surface temperature to calculate atmospheric transmissivity.  Jimenez-Munoz's (2003) single-channel method also requires emissivity and an estimate of water vapor content \cite{sobrino_2004}, \cite{jimenez-munoz_2003}, \cite{qin_2001}.

They found that compared to using the radiosonde with the radiative transfer equation and in situ emissivity measurement, Qin et al.'s algorithm with emissivity from NDVI has a root mean square deviation (RMSD) of 2.2 K and Jimenez-Munoz and Sobrino's single channel method has a RMSD of 0.9 K \cite{sobrino_2004}.

Jimenez-Munoz and Sobrino (2004) provide a study of the error contributed to land surface temperature by several parameters based on using MODTRAN to simulate various conditions.  Such parameters include atmospheric compensation, sensor noise, land surface emissivity, aerosols and other gaseous absorbers, angular effects, wavelength uncertainty and band-pass effects.  Of particular interest to this work, it was found that atmospheric effects are the most important source of error and could introduce errors of 0.2 K or 0.7 K if in situ or remote sensing data is used respectively.  Also, uncertainty in emissivity can lead to errors of 0.4 K, so a minimum error of 0.3 K can be obtained with all in situ data, and a minimum error of 0.8 K is expected when all remote sensing data is used \cite{jimenez-munoz_2004}.

Our work is necessary because previously developed methods cannot be implemented due to requirements to produce an operational solution for the single band Landsat product.  However, consideration of previous work gives us knowledge of what has been successfully implemented and the magnitude of accuracy achieved in the field.

\section{MODTRAN}
\label{sec:modtran}

MODTRAN radiative transfer code, created by Spectral Science Inc. and the United States Air Force, was developed from LOWTRAN, the original low resolution version of the program.  MODTRAN radiative transfer code utilizes a propagation model that assumes the atmosphere is divided into a number of homogenous layers \cite{schott}.  The user must input, or select pre-defined, vertical atmospheric profiles for parameters such as pressure, temperature, and humidity, and specify visibility, season, or time of year among other inputs.  MODTRAN solves the radiative transfer equation to characterize molecular and particular absorption, emission, and scattering, as well as reflections, emissions and transmissions among other outputs \cite{modtranweb}. 

The applications and uses of MODTRAN are far-reaching, but for the purpose of this work, atmospheric profiles of height, temperature, pressure and humidity were input in order to calculate from the MODTRAN output the transmission, upwelled radiance, and downwelled radiance, which are not explicitly given in the output.  There are various methods that can be used to calculate these three values from the spectral arrays contained in the output, as detailed in Appendix \ref{app:modtranrunstudy}, but contributions to error as well as processing time and memory constraints indicated the method detailed in Section \ref{sec:parameters} is optimal for the implementation of this operational algorithm.

\section{NARR Data Set}
\label{sec:narrdataset}

Reanalysis, or retrospective-analysis, is the process of using observing systems with numerical models to generate, in a spatially and temporally consistent set, a set of variables that are not easily observed or measured \cite{merra}.  Reanalysis data is a regional or global estimate to take empirical data from various inputs and re-estimate characteristics of the atmosphere on a regular spatial and temporal grid.  The NARR dataset is produced by the National Center for Environmental Prediction (NCEP).  This dataset is an extension of the NCEP global analysis, improving resolution and the number of variables over North America.  Inputs to NARR includes radiosondes, dropsondes, pibals, aircraft, surface data, and cloud drift winds.  NARR provides data for sea level, surface level, specified pressure levels, specified heights above ground, hybrid level, and below surface as well as wind data, cloud data, tropopause, and atmospheric columns \cite{narr}.

This work uses variables provided at specific pressure levels.  The NARR data includes geopotential height [gpm], temperature [K], specific humidity [kg/kg], pressure vertical velocity [Pa/s], u wind [m/s], v wind [m/s], cloud water [kg/kg], ice mixing ratio [kg/kg], and turbulent kinetic energy [J/kg] at pressure levels of 1000 hPa, 975 hPa, 950 hPa, 925 hPa, 900 hPa, 875 hPa, 850 hPa, 825 hPa, 800 hPa, 775 hPa, 750 hPa, 725 hPa, 700 hPa, 650 hPa, 600 hPa, 550 hPa, 5-- hPa, 450 hPa, 400 hPa, 350 hPa, 300 hPa, 275 hPa, 250 hPa, 225 hPa, 200 hPa, 175 hPa, 150 hPa, 125 hPa, and 100 hPa.  These data are provided in a 349 by 277 array on the Lambert Conformal Conic grid.  This is roughly 0.3$^\circ$ or 32 km spacing at the lowest latitude.  The corners of this spatial coverage are (12.2$^\circ$N, 133.5$^\circ$W), (54.5$^\circ$N, 152.9$^\circ$W), (57.3$^\circ$N, 49.4$^\circ$W), and (14.3$^\circ$N, 65.1$^\circ$W), covering North America.  There are three different temporal resolutions: eight times daily, once daily, or once monthly depending on the variable and desired temporal coverage. NCEP currently provides this data in the original GRIB format starting at 1 January 1979 with plans for continuing coverage and data provision.  Data for this work was downloaded as GRIB files using the NOMADS data access FTP or HTTP site at {\tt nomads.ncdc.noaa.gov/data.php?name=access\#narr\_datasets} \cite{narr_data}.

The geopotential height, air temperature, and specific humidity will all be used at 29 pressure levels and eight times daily to input atmospheric profiles into MODTRAN.  However, MODTRAN accepts only certain variables in certain units and therefore these data will need to be converted to the proper input variables. \\

\section{Conversions}
\label{sec:conversions}

MODTRAN requires the temperature, pressure, and some humidity variable at various heights at the same set of heights to characterize the atmospheric profiles.  The heights can be at any spacing as long as they provide sufficient coverage to accurately characterize the desired atmospheric column and are the same for all provided variables.  The atmospheric variables from the NARR data at specified pressure levels can be used to characterize the atmospheric profiles in MODTRAN.

The pressure and air temperature can be input into MODTRAN as given in the NARR data in hPa and K respectively.  However, it is necessary to have a corresponding geometric height [km] and one humidity variable.  MODTRAN accepts the volume mixing ratio [ppmv], number density [molecules/cm$^3$], mass mixing ratio [g/kg], mass density [g/m$^3$], partial pressure [mb], dew point temperature [K or $^\circ$C], or relative humidity [\%].

The geopotential height, provided by the NARR dataset, is the height of a given point in the atmosphere in units proportional to the potential of unit mass or geopotential at the height relative to sea level.  There is an adjustment to the geometric height using the variation of gravity with latitude and elevation.  The geometric height, the desired MODTRAN input, is simply the elevation above mean sea level.  Therefore, the conversion from geopotential height to geometric height requires knowledge of the latitude of the location.  Variables and constants for this conversion are summarized in Table \ref{tab:heightConversion}.

\begin{table}[H]
\begin{center}
\begin{tabular}{|c | c | c |}
\hline
Variable & Data & Value [Units] \\ \hline
H & given geopotential height & [m] \\ \hline
$\phi$ & latitude at location of heights & [radians] \\ \hline
$g_0$ & standard acceleration due to gravity & 9.80665 [m/s$^2$] \\ \hline
$R_{max}$ & Earth's equatorial radius & 6378.137 [km] \\ \hline
$R_{min}$ & Earth's polar radius & 6356.752 [km] \\ \hline
\end{tabular}
\caption{Variables and constants for geopotential to geometric height conversion \cite{wright_1997}.}
\label{tab:heightConversion}
\end{center}
\end{table}

The acceleration due to gravity, g [m/s$^2$], at the desired latitude must be computed as shown in Equation \ref{eq:g} and the gravity ratio, G, as shown in Equation \ref{eq:G}. 

\begin{equation}
g = 9.80616[1-0.002637cos(2\phi)+0.0000059cos^2(2\phi)]
\label{eq:g}
\end{equation}

\begin{equation}
G = \frac{g}{g_0}
\label{eq:G}
\end{equation}

Finally, the radius of the Earth at the desired latitude, $R_e$ [km], must be solved for from Equation \ref{eq:radius}.

\begin{equation}
R_e^2\bigg(\frac{cos^2(\phi)}{R_{max}^2}+\frac{sin^2(\phi)}{R_{min}^2}\bigg) = 1
\label{eq:radius}
\end{equation}

With these values, the desired geometric height, Z [m], can be calculated as shown in Equation \ref{eq:geometric} \cite{wright_1997}.

\begin{equation}
Z = \frac{HR_e}{GR_e - H}
\label{eq:geometric}
\end{equation}

The humidity variable given in the NARR dataset, specific humidity, is not directly accepted by MODTRAN to characterize the atmospheric profiles.  Through numerous intermediate steps, relative humidity can be calculated from specific humidity given the corresponding temperatures and pressures.  Variables and constants for this conversion are summarized in Table \ref{tab:humidityConversion}.

\begin{table}[H]
\begin{center}
\begin{tabular}{|c | c | c |}
\hline
Variable & Data & Value [Units] \\ \hline
T$_C$ & air temperature & [$^\circ$C] \\ \hline
T$_K$ & air temperature & [K] \\ \hline
q & specific humidity & [kg/kg] \\ \hline
p & pressure & [hPa] \\ \hline
$N_L$ & Avogadro's constant & 6.0221415 x 10$^{23}$ [mol$^{-1}$] \\ \hline
R & universal gas constant & 8.301447215 [J/(mol K)] \\ \hline
M$_{H_2O}$ & molar mass of water & 18.01534 [g/mol] \\ \hline
M$_{dry}$ & molar mass of dry air & 28.9644 [g/mol] \\ \hline
\end{tabular}
\caption{Variables and constants for specific to relative humidity conversion \cite{kruger_2010}.}
\label{tab:humidityConversion}
\end{center}
\end{table}

The Goff-Gratch equation, shown in Equation \ref{eq:goff}, was selected from various methods to calculate the saturation water vapor pressure, e [hPa] \cite{goff_1946}.

\begin{equation}
\begin{split}
\mbox{log}(e) = & -7.90298\bigg(\frac{373.15}{T_K} - 1\bigg) \\
           & + 5.02808 log\bigg(\frac{373.15}{T_K}\bigg) \\
           & - 1.3816\mbox{ x }10^{-7}(10^{11.344(1-\frac{T_k}{373.15})}-1) \\ 
           & + 8.1328\mbox{ x }10^{-3}(10^{-3.49149(\frac{373.15}{T_K}-1)}-1) \\
           & + \mbox{log}(1013.25) \\
\end{split}
\label{eq:goff}
\end{equation}

The volume mixing ratio, $X_{H_2O}$, is required to calculate the partial pressure, $P_{H_2O}$ [hPa] shown in Equations \ref{eq:xh2o} and \ref{eq:ph2o} respectively.

\begin{equation}
X_{H_2O} = \frac{{q}{M_{dry}}}{M_{H_2O}-{q}{M_{H_2O}}+{q}{M_{dry}}}
\label{eq:xh2o}
\end{equation}

\begin{equation}
P_{H_2O} = pX_{H_2O}
\label{eq:ph2o}
\end{equation}

And finally, the desired relative humidity, RH [\%], can be calculated from the partial pressure and saturation water vapor pressure using Equation \ref{eq:rh} \cite{kruger_2010}.

\begin{equation}
RH = \frac{P_{H_2O}}{e}*100
\label{eq:rh}
\end{equation}

\section{Concluding Remarks}

Chapter \ref{ch:background} aimed to provide a summary of all of the information that will be utilized in our land surface temperature retrieval methodology.  We began by presenting thermal radiance and the governing equation in Sections \ref{sec:remotesensing} and \ref{sec:governingequation}.  This provides the basic physical and scientific theory that is the basis for our work.  We then provided a brief history of Landsat and applications for and methods of LST retrieval in Sections \ref{sec:landsathistory} and \ref{sec:landsurfacetemperature}.  This historical information and investigation into already developed methods is important to understanding where our work fits in the field.  Finally, in Sections \ref{sec:modtran}, \ref{sec:narrdataset}, and \ref{sec:conversions}, we briefly discuss programs, datasets, and calculations with which we will assume familiarity throughout the rest of the work.

We use all of the above information to present our initial approach and methodology in Chapter \ref{ch:methodology}.  We explain each step in the process and briefly provide support or validation for each one.  More comprehensive validation and verification is provided in Chapter \ref{ch:initialresults} where we present our initial results.  This includes both the errors of our initial process and methods for the assignment of confidence metrics.  Finally, in Chapter \ref{ch:futurework}, we detail future work, which includes both improvement to the initial methodology and new work.

\chapter{Methodology and Approach}
\label{ch:methodology}

Chapter \ref{ch:background} includes the basic scientific process and other information necessary for land surface temperature retrieval, but Chapter \ref{ch:methodology} explains the specifics of the approach of this work.  Section \ref{sec:parameters} describes the process chosen for calculating the necessary radiative transfer parameters from the MODTRAN output.  This procedure is central not only to the final product but also the development, validation, and verification of the process and will be used and referenced throughout.  It is difficult to understand how each step contributes to the process without considering an end-to-end workflow; therefore, Section \ref{sec:overview} gives a process overview and subsequent sections detail each individual step.  Sections \ref{sec:narrregistrationwithlandsat} and \ref{sec:narrdatatomodtran} consider the integration of the NARR data.  The methods, and brief sensitivity studies validating these selections, for temporal and height interpolation are explored in Sections \ref{sec:temporalinterpolation} and \ref{sec:heightinterpolation} respectively.  We deal with NARR point selection in Section \ref{sec:pixeliteration} before the final step in the process, interpolation of radiative transfer parameters in elevation and location, is explained and initially validated in Section \ref{sec:spatialinterpolation}.

\section{Generating Radiative Transfer Parameters}
\label{sec:parameters}

The necessary effective in band radiative transfer parameters, transmission, upwelled radiance, and downwelled radiance, are not explicit outputs from MODTRAN.  There are numerous ways to generate these parameters from the spectral outputs given in the MODTRAN output files, but both accuracy and computational time are important when selecting a method for this process.  Appendix \ref{app:modtranrunstudy} outlines each of the different methods considered and the sensitivity study performed to determine which is optimal; here we explain only the selected method.

The governing equation, again from Section \ref{sec:governingequation},

\[
L_{obs} = (L_T\epsilon+(1-\epsilon)L_d)\tau + L_u
\]

reduces to 

\[
L_{obs} = L_T{\tau} + L_u
\]

if $\epsilon=1$.  If $L_{obs}$ is plotted against $L_T$, then transmission is the slope and $L_u$ is the intercept as shown in Figure \ref{fig:threeModtranInterp} where $T_1$ and $T_2$ are temperatures corresponding to $L_T$ in Planck's equation from Equation \ref{eq:planck} in Section \ref{sec:governingequation}.

% 17Jan2012/17Jan2012.pptx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/threeModtranInterp}
\caption{Illustration of the linear relationship between $L_T$ and $L_{obs}$ when $\epsilon$=1.}
\label{fig:threeModtranInterp}
\end{figure}

Because transmission, upwelled radiance, and downwelled radiance are characteristics of the atmosphere, surface properties, such as emissivity and self-emitted radiance, can be varied in MODTRAN to determine the radiative transfer parameters.  It is important to note that these emissivities and temperatures are simply specified as a tool in calculations and are different than the emissivity and temperature of the pixel where these radiative transfer parameters will be used to characterize the atmosphere for LST retrieval.  In the LWIR, characteristics of the atmosphere above a location are independent from the surface properties of that location; therefore we can model and adjust surface properties when characterizing the atmosphere.  Temperature ($L_T$) and emissivity are MODTRAN inputs and the observed radiance ($L_{obs}$) can be derived from MODTRAN output, so, in two MODTRAN runs with two different surface temperatures and an emissivity equal to 1, the transmission and upwelled radiance can be generated.  The two temperatures used corresponding to the self-emitted radiance, 273 K and 310 K, were chosen to span a range that includes most land surface temperatures that will be encountered when generating this product.  When the emissivity is not equal to one, the governing equation can be solved for downwelled radiance as shown in Equation \ref{eq:downwelled}.

\begin{equation}
L_d = \frac{\frac{L_{obs}-L_u}{\tau}-L_T\epsilon}{1-\epsilon}
\label{eq:downwelled}
\end{equation}

Therefore, a single MODTRAN run with $\epsilon < 1$ can generate the final parameter once the transmission and upwelled radiance are known.  It is a bit precarious to calculate downwelled radiance from a single point at a single temperature and emissivity.  If we calculate the downwelled radiance at a ground temperature of 273 K and again at a ground temperature of 310 K, we would get slightly different values.  By specifying the boundary temperature in MODTRAN as the air temperature of the initial atmospheric layer, we guarantee that our calculation of downwelled radiance is using a simulated temperature that is reasonably close to the LSTs we will be predicting.  In MODTRAN, if the ground temperature is entered as `000', it specifies the air temperature of the initial atmospheric layer as the boundary temperature of the image pixel.  The initial atmospheric profile temperature and LST at a given location do not generally span a large range, so this should also be characteristic of the LSTs the downwelled radiance will be used to determine.  Therefore, the third MODTRAN run is executed with T = `000' and $\epsilon$ = 0.9 to calculate downwelled radiance.

\section{Process Overview}
\label{sec:overview}

As described in Section \ref{sec:objectives}, once an appropriate data set has been identified, the second objective is to develop an automated process to generate the three radiative transfer parameters at each Landsat pixel.  Section \ref{sec:governingequation} illustrates that with a calibrated sensor and known surface emissivity, transmission, upwelled radiance, and downwelled radiance (radiative transfer parameters) are required to generate land surface temperature.  Section \ref{sec:narrdataset} describes the identified dataset and this chapter describes how that dataset is utilized to generate the radiative transfer parameters.

% methodology/processFigures.ppts
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/overlay.png}
\caption{NARR points overlaid and subset to a Landsat scene.  On the left, the gray box represents a Landsat scene and each black circle a NARR point.  On the right, the grid represents the layout of the Landsat coordinate system in comparison to the NARR points.  Note that neither schematic is to scale.}
\label{fig:overlay}
\end{figure}

Because the NARR dataset covers all of North America, when a particular Landsat scene has been identified, the first step to spatially subset the NARR data based on the extent of the Landsat scene as shown in Figure \ref{fig:overlay}.  NARR data is on a fixed grid, so once the appropriate points have been identified, the relevant data (geometric height, temperature, and specific humidity at points pertinent to the current Landsat scene) at the samples before and after (NARR data is given on three hour intervals) the acquisition time of the Landsat scene are subset (described in Section \ref{sec:narrregistrationwithlandsat}).  When the subset of NARR data has been extracted, it must be manipulated so that it can be used as atmospheric profiles in MODTRAN (described in Section \ref{sec:narrdatatomodtran}).

% methodology/processFigures.ppts
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/temporal.png}
\caption{Illustration of temporal resolution.  The black circles represents NARR points and the gray circles represent Landsat scenes in time.  At a single location, each Landsat scene is collected at the same time each day.  In this case, data from each NARR point at 12Z and 15Z would be interpolated to the Landsat collection time of 14.3Z.}
\label{fig:temporal}
\end{figure}

The first data interpolation occurs in the temporal domain.  The NARR data is given every three hours so the geometric height, temperature, and relative humidity profiles from datasets before and after the Landsat acquisition time are linearly interpolated to the Landsat acquisition time (described in Section \ref{sec:temporalinterpolation}).  This is illustrated in Figure \ref{fig:temporal}.  There are now atmospheric profiles for each necessary variable corresponding to the Landsat acquisition time at each NARR point location for the Landsat scene.

The necessary radiative transfer parameters are required at every pixel in order to generate a unique LST, which presents the issue of spatial resolution and the varying and unique elevation of each pixel.  The ground altitude at which MODTRAN is executed changes the resulting radiative transfer parameters, but it is unreasonable to run MODTRAN for every pixel in a scene.

% methodology/processFigures.ppts
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/datacube.png}
\caption{The data cube that is created for the Landsat scene by generating radiative transfer parameters at a set of elevations for each NARR point subset for the scene.  Note that the cube is larger than the scene due to the selection of NARR points beyond the scene for interpolation. (Image from http://www.scisoft-gms.com).}
\label{fig:datacube}
\end{figure}

The proposed solution generates the necessary radiative transfer parameters at set elevations at each NARR point location.  The execution of MODTRAN at various elevations at the same location requires a linear interpolation of the atmospheric layers (described in Section \ref{sec:heightinterpolation}).  Generating the radiative transfer parameters at a set of elevations at each NARR point results in a three-dimensional (spatial and height) cube of data encompassing the entire Landsat scene as shown in Figure \ref{fig:datacube}; radiative transfer parameters for each pixel will be interpolated from this cube.  Once this cube of data has been generated, the four appropriate NARR points must be identified for every pixel in the scene (described in Section \ref{sec:pixeliteration}).  The radiative transfer parameters are linearly interpolated to the appropriate elevation at all four NARR locations, illustrated in Figure \ref{fig:elevation}, and these resulting parameters are interpolated to the pixel location using Shepard's method, illustrated in Figure \ref{fig:spatial} (described in Section \ref{sec:spatialinterpolation}).

% methodology/processFigures.ppts
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/elevation.png}
\caption{Illustration of interpolation in elevation.  The black circles represent elevations at which the radiative transfer parameters were generated.  For any NARR point, the radiative transfer parameters can be interpolated to the elevation of any pixel of interest, represented for two different pixels by the gray circles.}
\label{fig:elevation}
\end{figure}

% methodology/processFigures.ppts
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/spatial.png}
\caption{Illustration of spatial interpolation.  The grid represents the spacing of the Landsat pixels and the black circles the NARR points (not to scale).  The four nearest NARR points are be interpolated to the current pixel, represented by the gray circle.}
\label{fig:spatial}
\end{figure}

The following sections describe the individual steps in the process, including how interpolators were chosen and the sensitivity studies performed to examine the error they can contribute to the final product.  Note that the sensitivity studies in this chapter serve only as reasonableness tests for each process; it is difficult to isolate the error contributed by each interpolation and it is also difficult to find actual truth data for comparison.  In many cases, correcting radiosondes to the appropriate location using surface weather data for example, the truth data presented in the sensitivity study is another best guess that does not account for differences in one or more dimensions, such as changes in time or space.  We are using methods proven in other studies to give reliable results.  Therefore, we use these reasonableness tests to broadly evaluate the interpolations and then use actual ground truth data later in Chapter \ref{ch:initialresults} to perform more rigorous and diligent testing of our results.

\section{NARR Registration with Landsat}
\label{sec:narrregistrationwithlandsat}

The NARR data is natively in a 349 by 277 point Lambert Conformal Conic grid.  This grid is approximately evenly spaced at 32 km with each grid point specified by an (i,j) coordinate.  The U.S. Climate Prediction Center provides a grid that gives the latitude and longitude of each (i,j) Lambert Conformal coordinate generated by bilinear interpolation \cite{narr_data}.

Landsat data is natively given in Universal Transverse Mercator (UTM).  In this coordinate system, the Earth is divided in 60 zones, each approximately 6$^\circ$ wide.  A location is specified by a zone, an easting value, and a northing value.  To avoid negative coordinates, each zone has a reference parallel and reference meridian.  The equator is the reference parallel for all zones and assigned a false northing value of 10,000,000 m.  Points in the southern hemisphere have northing values less than 10,000,000 m but greater than 0 m; points in the northern hemisphere have northing values greater than 10,000,000 m.  Similarly, each zone has a false meridian (central meridian) that is assigned a false easting of 500,000 m.  Points west of the central meridian have an easting value less than 500,000 m but greater than 0 m; points east of the central meridian have easting values greater than 500,000 m \cite{utm}.  In the metadata of each Landsat scene, the zone of the upper left corner is specified; all UTM coordinates for a single scene are given in reference to the false parallel and central meridian of that zone, even if the scene spans more than one zone.  The UTM coordinates and latitude and longitude for each corner of the image are all provided in the Landsat metadata.  The UTM coordinates of any pixel can be determined using these corner values, the pixel indices within the scene, and the size of each pixel, also given in the metadata.

As described in Section \ref{sec:overview}, the NARR data must be spatially subset based on the extent of the Landsat scene, illustrated in Figure \ref{fig:overlay}.  The first step is to convert to a common coordinate system.  The latitude and longitude coordinates are known for both the NARR points and the corners of the Landsat scene.  Because the NARR data and Landsat scene are given in different native coordinate systems, when the NARR data is overlaid on the Landsat scene, the data no longer appears as a regular grid.  Using the corners of the Landsat scene, the NARR points that fall within the scene can be determined.  Considering the interpolations that will need to be made later in the process, some NARR points beyond the edges of the Landsat scene need to be included.  Therefore, the range determined by the corners of the Landsat scene is increased by approximately the spacing of the NARR points in degrees, in order to include at least one additional NARR point in each direction.  The maximum and minimum i and j values are determined and the NARR points are subset based on these ranges of Lambert Conformal coordinates (min$_i$:max$_i$, min$_j$:max$_j$).  This results in, when considered in their native grid, a rectangle that includes all NARR locations necessary to process the current Landsat scene.  Figure \ref{fig:overlay} can be considered to be in the native grid of the Landsat scene where the Landsat pixels are regularly spaced and the NARR points are irregularly spaced.  Figure \ref{fig:narrgrid} shows the same set of data, NARR points subset to the Landsat scene, in the NARR native Lambert Conformal coordinates.  Here the Landsat scene has an irregular shape and the NARR points are in a regular grid.  Note that the NARR points extend beyond the Landsat scene in all directions.

% methodology/processFigures.ppts
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/narrgrid.png}
\caption{Illustration of NARR points overlaid on Landsat scene in NARR native Lambert Conformal coordinates.}
\label{fig:narrgrid}
\end{figure}

\section{NARR Data to MODTRAN}
\label{sec:narrdatatomodtran}

Various considerations need to be made before this NARR data can be used in MODTRAN.  NARR includes air temperature, specific humidity, and geopotential height profiles at fixed pressure levels at each NARR location.  As detailed in Section \ref{sec:conversions}, MODTRAN requires corresponding points in pressure, air temperature, geometric height and one of the following humidity variables: volume mixing ratio [ppmv], number density [molecules/cm$^3$], mass mixing ratio [g/kg], mass density [g/m$^3$], partial pressure [mb], dew point temperature [K or $^\circ$C], or relative humidity [\%].

By the methods detailed in Section \ref{sec:conversions}, the geopotential height profiles are converted to geometric height profiles using the latitude of the NARR point and the specific humidity profiles are converted to relative humidity profiles using the temperature and pressure profiles of the NARR point.

Because the NARR data is provided at fixed pressure levels, the highest pressure level, corresponding to the lowest elevation, may correspond to a negative geometric height after the conversion.  Any levels with negative geometric heights are cut from the profile in MODTRAN and the first pressure level with a positive geometric height becomes the lowest level of the profile.

It is also necessary for the atmospheric profiles to reach higher into the atmosphere than the height of the lowest NARR pressure level.  MODTRAN supplies various standard atmospheres, corresponding to different seasons and areas of the Earth.  Contents of the atmosphere at these heights are largely negligible when considering the generation of the radiative transfer parameters, but they are required to be present to execute MODTRAN.  Therefore, MODTRAN's mid-latitude summer atmosphere is appended to the top of each NARR profile to run MODTRAN.  To create a smooth transition between the two profiles, linear interpolations are made between the highest NARR point and the second closest standard atmosphere point.  These points are chosen to avoid sudden variations in the profile.  This is procedure is performed for all four variables.

% NARRDATA/plot_atmospheres.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{methodology/pressureProfiles.png}
\caption{Plot of standard atmosphere and NARR pressure profiles.}
\label{fig:pressureProfiles}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{methodology/interpolatedPressure.png}
\caption{Plot of interpolated pressure profile for MODTRAN input.}
\label{fig:interpolatedPressure}
\end{minipage}
\end{figure}

Figure \ref{fig:pressureProfiles} shows the pressure levels for the NARR profiles and the MODTRAN provided standard atmosphere.  Figure \ref{fig:interpolatedPressure} shows where the standard atmosphere has been truncated above, interpolated to, and appended on the NARR profile.  Figures \ref{fig:temperatureProfiles} and \ref{fig:interpolatedTemperature} show the same for temperature and Figures \ref{fig:relHumProfiles} and \ref{fig:interpolatedRelHum} show the same for the relative humidity profiles.  Note that the NARR data usually reaches just under 20 km.

% NARRDATA/plot_atmospheres.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{methodology/temperatureProfiles.png}
\caption{Plot of standard atmosphere and NARR temperature profiles.}
\label{fig:temperatureProfiles}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{methodology/interpolatedTemperature.png}
\caption{Plot of interpolated temperature profile for MODTRAN input.}
\label{fig:interpolatedTemperature}
\end{minipage}
\end{figure}

% NARRDATA/plot_atmospheres.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{methodology/relHumProfiles.png}
\caption{Plot of standard atmosphere and NARR relative humidity profiles.}
\label{fig:relHumProfiles}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{methodology/interpolatedRelHum.png}
\caption{Plot of interpolated relative humidity profile for MODTRAN input.}
\label{fig:interpolatedRelHum}
\end{minipage}
\end{figure}

\section{Temporal Interpolation}
\label{sec:temporalinterpolation}

Relative to the course temporal sampling of the NARR data, all pixels in the Landsat scene can be assumed to be collected at the scene center scan time; all radiative transfer parameters need to be generated for this time.

The NARR profiles provide characterizations of the atmosphere to generate in MODTRAN the radiative transfer parameters necessary for calculating the land surface temperature.  The NARR data is a 3-hourly product available at eight evenly spaced samples per day based on Greenwich Mean Time (GMT) or Zulu time (Z).

To determine the optimal temporal interpolation techniques, the structure of the NARR data was investigated.  NARR data for a single date was chosen (2 August 2007) and points were selected in the northeast (42.809$^\circ$N, 78.473$^\circ$W) and southwest (32.303$^\circ$N, 115.453$^\circ$W) regions of the United States.  The temperatures for pressure levels 1000 hPa, 875 hPa, 750 hPa, and 550 hPa at all eight samples throughout the day for both coordinates were plotted and are shown in Figures \ref{fig:ne_temp_all} and \ref{fig:sw_temp_all}.

% TIME/read_grib_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/ne_temp_all}
\caption{Temperature at four pressure levels plotted against time for a NARR point in the northeast region of the United States (42.809$^\circ$N, 78.473$^\circ$W).}
\label{fig:ne_temp_all}
\end{figure}

% TIME/read_grib_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/sw_temp_all}
\caption{Temperature at four pressure levels plotted against time for a NARR point in the southwest region of the United States (32.303$^\circ$N, 115.453$^\circ$W).}
\label{fig:sw_temp_all}
\end{figure}

Figures \ref{fig:ne_temp_all} and \ref{fig:sw_temp_all} do not show any obvious pattern in temperature as a function of time except for the low amplitude diurnal edge at the lowest level.  However, the temperature range on each plot is fairly large, which could be diminishing our ability to observe finer patterns over smaller ranges.  Also, the layers at the highest pressure levels (lowest heights) have the largest affect on the MODTRAN results.  For further investigation, temperatures at the five highest pressure levels (1000 hPa, 975 hPa, 950 hPa, 925 hPa, and 900 hPa) were plotted against time for the same two coordinates on the same date, shown in Figures \ref{fig:ne_temp_lower} and \ref{fig:sw_temp_lower}.

% TIME/read_grib_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/ne_temp_lower}
\caption{Temperature at five highest pressure levels plotted against time for a NARR point in the northeast region of the United States (42.809$^\circ$N, 78.473$^\circ$W).}
\label{fig:ne_temp_lower}
\end{figure}

% TIME/read_grib_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/sw_temp_lower}
\caption{Temperature at five highest pressure levels plotted against time for a NARR point in the southwest region of the United States (32.303$^\circ$N, 115.453$^\circ$W).}
\label{fig:sw_temp_lower}
\end{figure}

These plots over a smaller temperature range show a greater variation in temperature with time.  Sinusoidal, cubic spline, and nearest neighbor interpolators were all considered.  However, one interpolator may best fit a single pressure level or location, but none were good or better fits to all points or pressure levels and using a larger number of data points did not seem to improve the accuracy of the interpolation.  A piecewise linear interpolation using one point before and one point after was implemented as an initial method.

The same analysis was conducted to investigate patterns in relative humidity.  Figures \ref{fig:ne_rh_all} and \ref{fig:sw_rh_all} show relative humidity plotted as a function of time for four pressure levels throughout the range of the NARR data (1000 hPa, 875 hPa, 750 hPa, and 550 hPa) for the same northeast and southwest coordinates on the same date.  

% TIME/read_grib_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/ne_rh_all}
\caption{Relative humidity at four pressure levels plotted against time for a NARR point in the northeast region of the United States (42.809$^\circ$N, 78.473$^\circ$W).}
\label{fig:ne_rh_all}
\end{figure}

% TIME/read_grib_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/sw_rh_all}
\caption{Relative humidity at four pressure levels plotted against time for a NARR point in the southwest region of the United States (32.303$^\circ$N, 115.453$^\circ$W).}
\label{fig:sw_rh_all}
\end{figure}

These plots show more variation than was found with temperature but in a less uniform manner.  The five highest pressure levels were also investigated, shown in Figures \ref{fig:ne_rh_lower} and \ref{fig:sw_rh_lower}.  Unlike temperature, these are not shown over a smaller range because each individual pressure level has a large amount of variability.  The shape and extent of this variability changes with pressure level and location.

% TIME/read_grib_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/ne_rh_lower}
\caption{Relative humidity at five highest pressure levels plotted against time for a NARR point in the northeast region of the United States (42.809$^\circ$N, 78.473$^\circ$W).}
\label{fig:ne_rh_lower}
\end{figure}

% TIME/read_grib_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{methodology/sw_rh_lower}
\caption{Relative humidity at five highest pressure levels plotted against time for a NARR point in the southwest region of the United States (32.303$^\circ$N, 115.453$^\circ$W).}
\label{fig:sw_rh_lower}
\end{figure}

Due to the non-uniformity of the variability in relative humidity, a simple piecewise linear interpolator using one point before and one point after the Landsat acquisition time was selected.  

There are also slight variations in geometric height with time at each fixed pressure level, so a piecewise linear interpolation of geometric height was implemented for consistency.  These temporal interpolations are performed at each pressure level in the atmospheric profile space.  Because errors in the values of the individual radiative transfer parameters are difficult to interpret, our goal is to isolate the error in the final apparent temperature contributed only from these temporal interpolations.

In order to isolate the error contributed by the temporal interpolation, a ground temperature ($T_{MODTRAN}$) and a truth atmosphere are input into MODTRAN to generate a sensor reaching radiance, transmission, upwelled radiance, and downwelled radiance ($L_{obs}$, $\tau_{truth}$, $L_{u\_truth}$, and $L_{d\_truth}$).  This sensor reaching radiance and these radiative transfer parameters are used to calculate radiance due to temperature as shown in Equation \ref{eq:governing}; this is inverted to an apparent ground temperature using Equation \ref{eq:planck}.  This apparent ground temperature from the truth atmosphere ($T_{truth}$) should be approximately the same as the temperature input in MODTRAN ($T_{MODTRAN}$).  Any differences can be contributed to the method of generating radiative transfer parameters explained in Section \ref{sec:parameters}.  $T_{truth}$ is calculated in order to isolate the error contributed by the temporal interpolation.  The interpolated NARR profiles are then used to generate radiative transfer parameters ($\tau_{NARR}$, $L_{u\_NARR}$, and $L_{d\_NARR}$) via the method described in Section \ref{sec:parameters}.  The same sensor reaching radiance values ($L_{ons}$) is used with this set of radiative transfer parameters to calculate the corresponding apparent ground temperature ($T_{NARR}$) using Equations \ref{eq:governing} and \ref{eq:planck}.  The error contributed by the method of temporal interpolation can then be calculated as the difference between $T_{truth}$ and $T_{NARR}$ as shown in Equation \ref{eq:tempInterp}.  Note that the absolute value operation is omitted; negative errors indicate the apparent ground temperature underestimated the actual temperature.  Recall, as described in Section \ref{sec:overview}, the following studies use estimated rather than absolute truth.  Larger errors than will be acceptable in our final results may be tolerated because this is a simple test of the implementation and reasonability of this interpolation.

% USGS_11Oct2011/USGSsept.pptx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{methodology/tempInterp}
\caption{Method of determining error contributed by temporal interpolation of NARR profiles.}
\label{fig:tempInterp}
\end{figure}

\begin{equation}
\mbox{Error} = T_{truth} - T_{NARR}
\label{eq:tempInterp}
\end{equation}

As an initial worse case scenario, the truth atmospheric profile is a NARR profile at time 12 Z, and the NARR profiles for 9 Z and 15 Z are linearly interpolated to estimate this time for a day in August 2007 at a location in the northeast region of the United States (42.809$^\circ$N, 78.473$^\circ$W).  These profiles, six hours apart and each three hours from the desired time of ground temperature prediction, cover a longer time span than the longest that could be required in our operation process (two profiles three hours apart and each 1.5 hours from the time of ground temperature prediction).  Ground temperatures ($T_{MODTRAN}$) of 273 K, 295 K, and 310 K are used to illustrate the effects over a range of temperatures.  Predictions are also made at a range of ground altitudes to examine the effect of elevation.

Results of this investigation, presented graphically in Figure \ref{fig:20070802_12fake}, give initial confidence in the implementation of the interpolation and showed errors that encourage further testing.

% TIME/linear_interp_study_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{methodology/20070802_12fake}
\caption{Error in apparent temperature contributed by linear interpolation of 9 Z and 15 Z NARR profiles; error computed in comparison to temperature predicted using 12 Z NARR profile.}
\label{fig:20070802_12fake}
\end{figure}

Plotting the NARR profiles gives an idea of the variability of the atmospheric variables (temperature, relative humidity, and height) with time but not how this variability can affect the predicted ground temperature.  To gain a better understanding of how atmospheric variability can alter the predicted LST, the 15 Z and 18 Z NARR profiles were interpolated to 16.5 Z.  In respect to Equation \ref{eq:tempInterp}, $T_{NARR}$ was calculated with this interpolated profile but $T_{truth}$ was calculated with the 15 Z profile, results presented in Figure \ref{fig:20070802_165_15}, and the 18 Z profile, results presented in Figure \ref{fig:20070802_165_18}.  By knowingly comparing the retrieved temperature to a temperature from a different time, this error captures how much changes in the atmosphere with time can alter the apparent temperature.  If we were to assume our bilinear interpolator is accurate, large errors in this investigation would be an argument against nearest neighbor interpolation.

% TIME/linear_interp_study_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{methodology/20070802_165_15}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to 15 Z NARR profile.}
\label{fig:20070802_165_15}
\end{figure}

These results suggest that the atmospheric variability corresponds to 3 K or less of variability in apparent ground temperature; if our assumption of linearity is perfectly correct and we used nearest neighbor interpolation, our predicted error would 3 K or less.  Results in Figure \ref{fig:20070802_12fake} suggest our assumption of linearity is not unreasonable; the goal of this study was to assure ourselves that the variability shown in Figures \ref{fig:ne_temp_all} through \ref{fig:sw_rh_lower} does not lead to  widely variable predictions of ground truth temperature.  The smaller the range of Figures \ref{fig:20070802_165_15} and \ref{fig:20070802_165_18}, the smaller the magnitude of errors that can be introduced with our temporal interpolation.

% TIME/linear_interp_study_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{methodology/20070802_165_18}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to 18 Z NARR profile.}
\label{fig:20070802_165_18}
\end{figure}

Finally, to generate a more dynamic set of test cases, radiosonde soundings are used as truth atmospheres.  There are generally two radiosonde soundings available each day (00 Z and 12 Z); one sounding is chosen and then interpolated from the boundary layer to surface using surface weather at the time of interest.  Refer to Padula's thesis for a complete description of this method \cite{padula_2008}.  In order to capture the longest time span for the linear interpolation that could be required in the proposed operational LST process, the radiosonde is corrected to surface weather from 16.5 Z and the 15 Z and 18 Z NARR profiles are linearly interpolated to that time.  Although this method of radiosonde correction has proven reliable in other studies \cite{padula_2008}, this is still as estimate of truth rather than an absolute measurement.  More importantly, the errors compared to the radiosonde profile do not account for the difference in location in the available radiosonde and surface weather and the nearest NARR point.  While the final LST process includes a more involved spatial interpolation, for this simple comparison, nearest neighbor interpolation was used (the closest available points were simply compared).  This is a very important consideration when analyzing results.

Time of year needs to be considered in the accuracy of temperature retrieval.  It is important to determine if errors are being caused by interpolation techniques or simply by the characteristics of the atmosphere inherent to that time and location.  As will be discussed in Chapter \ref{ch:initialresults}, certain atmospheric characteristics that can vary with season and location make temperature retrieval inherently more difficult; errors can still result even when the atmosphere is correctly characterized.  An analysis of the temporal interpolation was performed in each month.  The 15 Z and 18 Z profiles were interpolated to 16.5 Z and temperature retrieval results were compared to those for a radiosonde corrected to 16.5 Z surface weather from the same day.  The location of the NARR profiles, radiosonde data, and surface weather data were consistent for each month.  For initial testing, a point in the northeast was selected based on the accessibility of radiosonde and surface weather data.  The results for the error in apparent temperature between ground temperatures predicted using the interpolated NARR profile and the corrected radiosonde profile for each month are shown in Figures \ref{fig:20090116_165_rad} through \ref{fig:20081225_165_rad}.  Again, differences in location are not considered.

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20090116_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 16 January 2009.}
\label{fig:20090116_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20070201_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 1 February 2007.}
\label{fig:20070201_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20080314_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 14 March 2008.}
\label{fig:20080314_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20090415_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 15 April 2009.}
\label{fig:20090415_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20090530_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 30 May 2009.}
\label{fig:20090530_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20080606_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 6 June 2008.}
\label{fig:20080606_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20090720_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 20 July 2009.}
\label{fig:20090720_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20070802_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 2 August 2007.}
\label{fig:20090802_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20080924_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 24 September 2008.}
\label{fig:20090802_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20091020_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 20 October 2009.}
\label{fig:20091020_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20071104_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 4 November 2007.}
\label{fig:20071104_165_rad}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20081225_165_rad}
\caption{Error in apparent temperature contributed by linear interpolation of 15 Z and 18 Z NARR profiles; error computed in comparison to ground temperature predicted with radiosonde profile corrected to surface weather at 16.5 Z for 25 December 2008.}
\label{fig:20081225_165_rad}
\end{figure}

Higher errors at lower altitudes are expected due to the volume of atmosphere being considered.  It is important to consider that arbitrary ground temperatures were used; errors may be higher when the input ground temperature is further from the actual LST at the location (resulting in larger differences between the LST and air temperatures in the atmospheric profile).  Mismatched ground temperatures and atmospheric profiles can increase error.  Also, atmospheres at different times of year, particularly when it is warmer and more humid, are more difficult to compensate for.  Therefore, for this location near Buffalo, New York, LSTs predicted in the summer months tend to have higher errors than in the winter months.  These factors, as well as the differences in location that are not considered, make it difficult to attribute all of the error in Figures \ref{fig:20090116_165_rad} through \ref{fig:20081225_165_rad} solely to temporal interpolation.

From Figures \ref{fig:20090116_165_rad} through \ref{fig:20081225_165_rad}, results from 6 June 2008 and 20 July 2009 are particularly alarming and merit further investigation.  As will be discussed in Section \ref{sec:confidencemetrics}, lower transmission and higher relative humidities create larger errors in land surface temperature retrieval due to the nature of the atmosphere.  Figures \ref{fig:20080606_tau} and \ref{fig:20090720_tau} show the transmission curves from both the corrected radiosonde and the interpolated NARR profiles for 6 June 2008 and 20 July 2009.  Compare these curves, particularly at lower altitudes, to Figure \ref{fig:20081225_tau}, the radiosonde and NARR transmission curve for 12 December 2008, which results in land surface temperature retrieval errors less than 1 K as shown in Figure \ref{fig:20081225_165_rad}.  This gives us more confidence that the poor results in Figures \ref{fig:20080606_165_rad} and \ref{fig:20090720_165_rad} may be inherent to the atmosphere, rather than the interpolation method, and also provides insight to the confidence estimations we will have to consider later in Chapter \ref{ch:initialresults}.  Given the lack of spatial consideration in particular, single digit errors in most results are reasonable enough to initially infer that temporal linear interpolation for the NARR profiles will be sufficient for LST retrieval.

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20080606_tau}
\caption{Transmission profiles for both the radiosonde and interpolated NARR profile from 6 June 2008.  Notice transmission values are low, particularly at the lower altitudes, contributing to large errors in land surface temperature retrieval.}
\label{fig:20080606_tau}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20090720_tau}
\caption{Transmission profiles for both the radiosonde and interpolated NARR profile from 20 July 2009.  Notice transmission values are low, particularly at the lower altitudes, contributing to large errors in land surface temperature retrieval.}
\label{fig:20090720_tau}
\end{figure}

% TIME/radiosonde_grib_compare_time.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20081225_tau}
\caption{Transmission profiles for both the radiosonde and interpolated NARR profile from 25 December 2008.  Notice, in comparison to Figures \ref{fig:20080606_tau} and \ref{fig:20090720_tau}, transmission values are higher and land surface temperature retrieval results are better.}
\label{fig:20081225_tau}
\end{figure}

As shown, it is difficult to isolate errors contributed from individual interpolation techniques and determine how this error will contribute to the final LST product.  Rather than attempting to optimize each step as the process is developed, we will make an initial guess at each interpolator with a brief sensitivity study and complete an automated LST process in its entirety.  By later considering errors in the final retrieved temperature with ground truth data and more rigorous testing, we can determine limiting factors and more closely investigate and improve each interpolator if necessary.

\section{Height Interpolation}
\label{sec:heightinterpolation}

Each Landsat pixel has an associated elevation; this elevation affects the NARR parameters necessary for computing the LST.  When considering the view from the satellite, generally upwelled and downwelled radiances decrease and transmission increases as the elevation of the ground increases because the volume of atmosphere we are compensating for decreases.  However, it is unrealistic to execute MODTRAN for every pixel or every elevation in the image.  By executing MODTRAN at a specific set of heights at each NARR location, and generating radiative transfer parameters at each of these heights, these parameters can later be spatially interpolated for the appropriate elevation of each pixel.  This requires determining the optimal number and values of the heights at which MODTRAN should be executed.

As an initial test, MODTRAN was executed at nine different heights evenly spaced between 0 km and 4 km.  Although most pixels will have an elevation in the lower half of this range, 0 km to 4 km was selected to include most possible elevations around the globe.  Nine heights was chosen as the initial number of heights as a computationally reasonable amount.  Both of the selections can be reconsidered and optimized later.  Figure \ref{fig:profileWithHeights} shows a typical atmospheric profile on the left with a closer look at the bottom of this profile on the right.  The horizontal lines represent the elevations at which radiative transfer parameters are currently generated.

% USGS_11Oct2011/USGSsept.pptx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{methodology/profileWithHeights}
\caption{A typical atmospheric profile on the left with a closer look at the lowest elevations on the right.  The horizontal lines represent the elevations at which radiative transfer parameters are currently generated.}
\label{fig:profileWithHeights}
\end{figure}

% DIRS_21Oct2011/dirs21oct_new.pptx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{methodology/heightInterp}
\caption{The top of a MODTRAN tape5 file illustrating the linear interpolation of atmospheric profile layers.}
\label{fig:heightInterp}
\end{figure}

In order to execute MODTRAN at a specific height, an additional interpolation is required.  While the ground altitude is an input to MODTRAN, this only appropriately affects the results if the atmosphere is modified accordingly.  The lowest level of the input atmosphere must have a geometric height equal to the specified ground altitude for MODTRAN to produce the results we desire.  The elevations of the levels in the atmospheric profiles are determined by the set pressure levels of the NARR data.  To run MODTRAN at a particular elevation, the atmospheric layers below the ground altitude are removed and the closest layer above and below the ground altitude are linearly interpolated to form an atmospheric layer at the desired ground altitude.  Figure \ref{fig:heightInterp} shows the top of a typical tape5 file, the input file for a MODTRAN run (see Appendix \ref{app:modtranIO}).  The first four lines contain various inputs for the program while the fifth line (shown crossed out in Figure \ref{fig:heightInterp}) is the first layer of the atmospheric profile.  So, for example, if the MODTRAN run specified by the tape5 file in Figure \ref{fig:heightInterp} was to be executed at a ground altitude of 0.468 km, then 0.468 would be entered for gdalt keyword and the first two rows of the atmospheric profile would be deleted.  Using 0.358 km, 0.468 km, and 0.585 km as elevations for a linear interpolation, pressure, temperature, and relative humidity, the second, third, and fourth columns respectively, are linearly interpolated and this new atmospheric layer is inserted as the first atmospheric layer in the MODTRAN tape5 file.  Intuition suggests that, although this layer is required for the desired MODTRAN result and the lowest layers of the atmospheric characterization are the most influential, we are very slightly changing the geometric height without drastically modifying the atmosphere, so this step should contribute little error for the final apparent LST.  This basic method was developed and a simple study was implemented to explore the effects of using linear interpolation.  Linearly interpolating two layers to generate an atmospheric profile layer at an existing elevation (for example, linearly interpolating layers at 0.136 km and 0.585 km to get a layer at 0.358 km in Figure \ref{fig:heightInterp}) showed the effects were reasonable.  Also  considering the established used of linear interpolation in the recreation of the atmospheric column \cite{padula_2008}, this process was deemed adequate and implemented.  It is difficult to generate a study to determine the total effect on the final apparent temperature because any error will be compounded with error from the following step.  If necessary, further investigation can optimize this step once an entire process is implemented.

The process described above was used to run MODTRAN at 9 heights, evenly spaced between 0 km and 4 km, as shown in Figure \ref{fig:profileWithHeights}.  The lowest height is always the first layer of the NARR profile and the next 8 are the same for every point (0.6 km, 1.1 km, 1.6 km, 2.1 km, 2.6 km, 3.1 km, 3.6 km, and 4.05 km).  The radiative transfer parameters at these nine heights need to be interpolated to the elevation of each pixel, obtained from a digital elevation model (DEM).  As an initial method, a simple piecewise linear interpolation using one point above and one point below the desired elevation is implemented.  We expect the radiative transfer parameters to vary monotonically with height and expect this provides more accuracy that nearest neighbor interpolation.  To determine the error contributed by this interpolation, atmospheric parameters were generated at these nine heights, and then for the same NARR profile, atmospheric parameters were generated at eighty finely spaced elevations between 0 km and 4 km.  This is only used in validation because it is computationally unreasonable operationally.  These finely sampled ``truth" parameters were used, with input temperatures of 273 K, 205 K, and 310 K, to generate ``truth" temperatures as described in Section \ref{sec:parameters}.  As with temporal interpolation, this is an estimation of truth rather than absolute measurements.  Using only the elevation closest above and closest below, parameters from the sampled nine elevations were linearly interpolated to generate parameters at each of the eighty finely spaced elevations.  These linearly interpolated parameters are used to estimate an apparent land surface temperature, which can be compared to that generated from the ``truth" parameters.  Figures \ref{fig:20070201_heights} and \ref{fig:20070802_heights} show the errors in apparent temperature for two dates in February and August respectively.  The location of the NARR profile was the same as that used in the temporal interpolation study, near Buffalo, NY, at 42.809$^\circ$N, 78.473$^\circ$W.

% HEIGHT/linear_interp_study_height.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20070201_heights}
\caption{Errors in apparent temperature contributed by elevation interpolation for a NARR location in the northeastern United States in February.}
\label{fig:20070201_heights}
\end{figure}

% HEIGHT/linear_interp_study_height.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20070802_heights}
\caption{Errors in apparent temperature contributed by elevation interpolation for a NARR location in the northeastern United States in August.}
\label{fig:20070802_heights}
\end{figure}

As expected, there are higher errors at lower altitudes.  But even on a summer day where we expect that the warmer, humid atmosphere may hinder retrieval, the largest errors were not greater than 1 K.  Because this is only an initial test and the goal is to determine the error in the final product, compounded by all interpolations and contributed from all datasets, this simple study was enough to implement this interpolation in the initial process.

However, the largest errors are at the lowest elevations and most pixels will have elevations of less than 2 km.  To decrease errors and optimize results for the maximum number of pixels, it could be beneficial to later investigate irregular spacing of the generation of the radiative transfer parameters with more samples between 0 km and 2 km.

\section{Pixel Iteration and NARR Point Selection}
\label{sec:pixeliteration}

To this point, all operations, temporal interpolation of NARR profiles and MODTRAN runs at each elevation, have been at the location of each NARR point on the native Lambert Conformal grid.  Generation of a complete LST product requires pixel-wise operations.  At each pixel, the four nearest NARR points, guaranteeing two above and two below to account for varying conditions in each direction, will be utilized to interpolate the necessary atmospheric parameters.  However, because the Landsat pixels are natively in UTM coordinates and the NARR points are natively on a  Lambert Conformal grid, the selection of these four points is not trivial.  It is important to consider computational intensity because the following operations are performed at every pixel and Landsat scenes are on the order of 7000 by 8000 pixels.

The latitude and longitude coordinates of each NARR point corresponding to the Lambert Conformal (i,j) coordinate are readily available and these latitude and longitude coordinates can be converted to UTM coordinates; in UTM coordinates, where locations are specified in meters, distance calculations are more easily calculated \cite{narr_data}.  For each image, all UTM coordinates are computed in reference to the zone specified in the Landsat metadata.

Initially, distance calculations to every NARR point pertinent to the scene were considered to find the four points nearest to each pixel.  This quickly became too computationally intensive.  Instead, a systematic iteration through pixels from top to bottom and left to right was developed.  As described above, each pixel will be interpolated from the four nearest NARR points, two above and two below to account for varying conditions in each direction, so the NARR points for each pixel will be selected in quads.

Schematically represented as a grid as they appear in the Lambert Conformal coordinates, although spacing is irregular in the UTM coordinate system, Figure \ref{fig:pixeliteration} represents each NARR point using a letter.  Each number represents a possible quad for the pixel to fall within.  Although due to the irregular spacing of the pixels and NARR points, it is possible that the two nearest NARR points above a pixel and the two nearest NARR points below a pixel do not follow this gridded pattern, NARR points are forced to their native Lambert Conformal grid.  Quads are defined by the upper left NARR point.  For example, quad three is defined by NARR point D in Figure \ref{fig:pixeliteration}.

% 28Feb2012/28Feb2012.pptx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{methodology/pixeliteration}
\caption{Schematic figure of NARR points and pixels for pixel interpolation and NARR point selection.}
\label{fig:pixeliteration}
\end{figure}

For the first pixel in each row, distance calculations are performed to every NARR point subset for the scene.  The closest pixel above and left is found and the rest of the quad is defined using the Lambert Conformal NARR grid.  If the closest pixel above and left is (i,j) in Lambert Conformal coordinates, the quad is (i,j), (i+1,j), (i,j+1), and (i+1, j+1).  Once the quad for the first pixel in each row is determined, the quads for the rest of the pixels in the row, if iterating from left to right, can be determined using six distance calculations.  Compared to using a method that finds the distance to every NARR point at for each pixel, this can reduce the number of calculations on an order of magnitude of 100 for every pixel.

For each successive pixel, assuming iteration from left to right in the image, there are six possible quads.  The quad can remain the same or move right and the quad can remain the same or move up or down.  Therefore, if the current pixel falls in quad three in Figure \ref{fig:pixeliteration}, the next pixel could fall in any of the six quads shown.  

If the current pixel, r,  falls in quad three, we want to determine the quad for the next pixel, s, moving from left to right.  The distance from pixel s to NARR point D and NARR point F would be calculated.  If the distance to D is smaller, the quad does not move right, and if the distance to NARR point F is smaller, the quad does move right.  Similarly, the distance from the pixel s to NARR point B and NARR point H is calculated.  If the distance to B is smaller, the quad moves up and if the distance to H is smaller, the quad does not move up.  Finally, the distance from pixel s to NARR point E and NARR point K is calculated.  If the distance to K is smaller, the quad moves down, and if the distance to E is smaller, the quad does not move down.  This combination of move right or not, move up or not, and move down or not, determines the quad for pixel s.  This requires six distance calculations and a few logical operations to determine the four NARR points for each pixel after the first pixel in each row.

\section{Radiative Transfer Parameter Interpolation}
\label{sec:spatialinterpolation}

Once the necessary NARR points have been determined, the last five pixel-wise operations can be performed.  As discussed in Section \ref{sec:heightinterpolation}, the radiative transfer parameters at each of the four NARR points in the quad are piecewise linearly interpolated to the elevation of the pixel specified in the DEM.  This results in all three parameters at the appropriate elevation at each NARR point in the quad.  The final step is the spatial interpolation to the pixel location.

Various spatial interpolation methods were explored to optimally utilize the information available from the NARR points in the quad.  The goal was to use an inverse distance weighting interpolation,  weighting NARR points closer to the pixel of interest as more influential than those further from the pixel of interest.  The chosen method, Shepard's method, is shown in Equations \ref{eq:shepard1}, \ref{eq:shepard2}, and \ref{eq:shepard3}.  

\begin{equation}
d_i = \sqrt{(x-x_i)^2+(y-y_i)^2}
\label{eq:shepard1}
\end{equation}

\begin{equation}
w_i = \frac{d_i^{-p}}{\sum_{j=1}^nd_j^{-p}}
\label{eq:shepard2}
\end{equation}

\begin{equation}
F(x,y) = \sum_{i=1}^nw_if_i
\label{eq:shepard3}
\end{equation}

% USGS_11Oct2011/USGSsept.pptx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{methodology/shepard}
\caption{Schematic figure for points in Shepard's Method.}
\label{fig:shepard}
\end{figure}

As shown in Figure \ref{fig:shepard}, ($x_i,y_i$) are the coordinates of the points being interpolated, $f_i$ are the values begin interpolated, (x,y) is the coordinate being interpolated to, and F is the final interpolated value.  In Equation \ref{eq:shepard1}, $d_i$ are distance values from each point to the interpolated point; in Equation \ref{eq:shepard2}, n is the number of points being interpolated, in our case this is four, and $w_i$ are weighting values for each point, inversely related to the distance of the point from the interpolated value.  Also, p is a weighting exponent.  This is generally an arbitrary positive real number and the default is 2.  This can be adjusted in later optimizations.  Equation \ref{eq:shepard1} calculates each distance value, Equation \ref{eq:shepard2} calculates each weighting value using the distance values, and Equation \ref{eq:shepard3} calculates the final interpolated value as a weighted summation of the original values \cite{shepard_1968}.

Although we initially choose to use four points, based on the selection of the NARR points in quads, Shepard's method can be performed with any number of points n $>$ 1.  The number of points to be used can be further investigated in later optimizations.

As with both the temporal and height interpolations, it is necessary to isolate the error contributed by this interpolation.  Like the height interpolations, we used radiosonde data as a truth profile for comparison.  The nearest radiosonde profile will be corrected to the location of a surface weather station and this will be used as a truth profile.  Using this profile, the apparent ground temperature was generated using the process described in Section \ref{sec:parameters} at the same nine heights given in Section \ref{sec:heightinterpolation}.  These are the ``truth" apparent ground temperatures.  The location of the surface weather station is then treated as the desired pixel location.  The four nearest NARR points are selected as described in Section \ref{sec:pixeliteration} and the radiative transfer parameters are generated at the same nine heights at each of these four NARR locations as described in Section \ref{sec:heightinterpolation}.  This utilizes the height interpolation within the tape5 file but not the height interpolation to the elevation of each individual pixel so we not compounding these errors.

These radiative transfer parameters at each height are interpolated to the location of the surface weather station and these interpolated radiative transfer parameters are used to generate an array of apparent ground temperatures.  These temperatures are compared to the array of ``truth" temperatures to analyze the error contributed by the spatial interpolation.  In order to avoid compounding errors with temporal interpolation, the radiosonde profiles are corrected to surface weather at 15 Z and the 15 Z NARR profiles were used.  This is another best estimate of truth and should be considered only a test of the reasonability of implementing Shepard's method.

Figure \ref{fig:20070201_spatial} and Figure \ref{fig:20070802_spatial} show the error contributed by the spatial interpolation for the same surface weather location in the northeast used in Sections \ref{sec:temporalinterpolation} and \ref{sec:heightinterpolation} for dates in February and August respectively.  As with previous investigations, three temperatures are considered.

% SPACE/bilinear_interp_study.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20070201_spatial}
\caption{Errors in apparent temperature contributed by spatial interpolation to a location in the northeastern United States in February.}
\label{fig:20070201_spatial}
\end{figure}

% SPACE/bilinear_interp_study.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{methodology/20070802_spatial}
\caption{Errors in apparent temperature contributed by spatial interpolation to a location in the northeastern United States in August.}
\label{fig:20070802_spatial}
\end{figure}

Similar to the results from the temporal interpolation, the results in the colder weather are much better than those in the warmer weather.  Results in February are acceptable, even better than expected, and results from August also are reasonable enough to allow us to proceed with this method.  Once an entire process has been implemented, further optimizations can be investigated.  For any step, especially because errors from this step are already small, it is important to consider limiting factors and how much will be gained in optimization.

\section{Deliverables}
\label{sec:deliverables}

Because the goal of this work is atmospheric compensation, the deliverable is not a single temperature value at each pixel.  Rather, the deliverable includes all components necessary to determine the LST once the emissivity is known.  For each Landsat scene, a five band geotiff image is produced, the same size as the original Landsat image.  Table \ref{tab:deliverables} details each band of this file.  Explained further in Chapter \ref{ch:initialresults}, we also expect to add to this five band geotiff some form of confidence metric from our error analysis.

\begin{table}[H]
\begin{center}
\begin{tabular}{|c | c | c |}
\hline
Band & Contents & Units \\ \hline
0 & Landsat Band 6 in Radiance (L$_{obs}$)  & $Wm^{-2}sr^{-1}{\mu}m^{-1}$ \\ \hline
1 & Elevation & m \\ \hline
2 & Transmission &  \\ \hline
3 & Upwelled Radiance & $Wm^{-2}sr^{-1}{\mu}m^{-1}$ \\ \hline
4 & Downwelled Radiance & $Wm^{-2}sr^{-1}{\mu}m^{-1}$ \\ \hline
\end{tabular}
\caption{Details for each layer of the deliverable five band geotiff file.}
\label{tab:deliverables}
\end{center}
\end{table}

\section{Concluding Remarks}

This chapter aimed to explain each step in the automated process of LST prediction.  We began by describing our selected method for generating radiative transfer parameters from MODTRAN output and a general overview of our entire process in Section \ref{sec:parameters} and \ref{sec:overview}.  We then detailed each individual step in the process beginning with data manipulation in Sections \ref{sec:narrregistrationwithlandsat} and \ref{sec:narrdatatomodtran}.  Sections \ref{sec:temporalinterpolation} and \ref{sec:heightinterpolation} describe temporal and height interpolations respectively and Section \ref{sec:pixeliteration} and \ref{sec:spatialinterpolation} deal with the pixel-wise operations required to generate a complete operational LST product.  We conclude with a very brief summary of deliverables in Section \ref{sec:deliverables}.

Most of the above steps included not only an explanation but a brief validation.  However, a common theme was the need to implement and consider results from an entire process, to investigate feasibility and limiting factors, before revising or optimizing any one step.  With an entire process outlined, such results can be generated and initial results are presented in Chapter \ref{ch:initialresults}.  We explain how we quantify error, what our initial results show, and two proposed methodologies of confidence metric estimation.  With these results, we can outline future work in Chapter \ref{ch:futurework}, which includes optimizations, improvements, and extensions to the current process.

\chapter{Initial Results}
\label{ch:initialresults}

This chapter aims to summarize our initial results.  In Chapter \ref{ch:methodology}, radiosonde profiles were used as truth profiles to evaluate each of the interpolation methods, usually aiming to quantify only error from that step in the final predicted temperature.  Because these radiosonde profiles do not provide absolute truth, sensitivity studies in Chapter \ref{ch:methodology} only provided a check of the feasibility of our interpolation methods, not a rigorous evaluation of error.  In this chapter, temperatures from buoys or instrument platforms will be used to evaluate the error in apparent temperature from the entire process.  These temperatures can be considered actual ground truth and used for a more intense evaluation of the error.  Each of these stations gives a water temperature, and because the emissivity of water is known, we can compute the temperature predicted by our product and compare this to the ground truth temperature observed from the water.  In Section \ref{sec:groundtruthsites} we describe each of the ground truth sites and in Section \ref{sec:initialerror} we describe the quality of the initial results based on comparisons to temperatures obtained from these sites.  Section \ref{sec:confidencemetrics} describes two initial approaches to predicting confidence in our results and how this will presented to the user.

\section{Ground Truth Sites}
\label{sec:groundtruthsites}

From each of the sites described below, we were given or can obtain the ground truth land surface temperature of the water.  Although obtained using different methods, in all cases we call what we assume to be the accurate land surface temperature ``ground truth data" in our validation.  Here we first encounter the notation for specifying Landsat scenes.  The second Worldwide Reference System (WRS-2) specifies a nominal scene center as an integer path and integer row in a grid that covers the globe.  WRS-2 path, row is used only for scene specifications; scene centers and corners can vary and are obtained from the metadata.  

\subsection{The Salton Sea}
\label{sec:saltonsea}

The Salton Sea is located in southeastern California.  It is a saline lake that is 60 km long and 30 km wide and has an average depth of 9 m; the surface of the lake is approximately 70 m below sea level.  Measurements are made from a platform located at 33.22532$^\circ$N, 115.82425$^\circ$W, which falls with WRS-2 path 39, row 37, shown in Figure \ref{fig:39_37_overlaid}.  Ground truth data from this site is available from 2006 to present \cite{hook_salton}.  The ground truth land surface temperatures of the water from this platform are obtained in a similar fashion as the ground truth temperatures from the Lake Tahoe buoys as described in Section \ref{sec:laketahoe}.  These corrections were made and the data were provided by JPL.

% plot_narr.pro with B5
\begin{figure}[H]
\centering
\includegraphics[scale = 0.45]{results/39_37_overlaid.png}
\caption{Landsat scene (band 5) including the Salton Sea (path 39, row 37).  The white square represents the approximate location of the platform.}
\label{fig:39_37_overlaid}
\end{figure}

\subsection{Lake Tahoe}
\label{sec:laketahoe}

Lake Tahoe is located on the California-Nevada border approximately 1895 m above sea level.  It has a surface area of 500 km$^2$, an average depth of 330 m and is known for its high water clarity.  It does not freeze in the winter because of its large thermal mass.  There are four permanently moored buoys in the lake that provide various observables.    For the purposes of this work, we focused on a single buoy, referred to as TB4, located at 39.155$^\circ$N, 120.0721667$^\circ$W; this falls within WRS-2 path 43, row 33 and is shown in Figure \ref{fig:43_33_overlaid}.  This buoy has data available beginning in May 1999 through the present \cite{hook_tahoe}.  The instrumentation at these buoys, maintained by JPL, includes surface contact thermistors, nadir viewing calibrated radiometers, and weather stations.  The water temperature is corrected for the skin temperature using the radiometric temperature, surface contact temperature and downwelled radiance to account for the Landsat passband because the individual radiometers do not \cite{hook_2004} and \cite{hook_2007}.  These corrections were made and the ground truth land surface temperature of the water from this buoy was provided by JPL.

% plot_narr.pro with B5
\begin{figure}[H]
\centering
\includegraphics[scale = 0.45]{results/43_33_overlaid.png}
\caption{Landsat scene (band 5) including Lake Tahoe (path 43, row 33).  The white square represents the approximate location of the buoy.}
\label{fig:43_33_overlaid}
\end{figure}

\subsection{Rochester, New York}
\label{sec:rochester}

A 2.4 m foam hull buoy owned and maintained by the National Buoy Data Center is located in eastern Lake Ontario northeast of Rochester at 43.619$^\circ$N, 77.405$^\circ$W.  This site is 74.7 m above sea level.  In order to avoid problems with ice, this buoy is retrieved for a period of time in the winter and redeployed in the spring, so the data is only available for a portion of the year.  Retrieval and redeployment dates can vary but data for part of the year is available from 2002 to present.  This buoy falls in the overlap between Landsat paths, so it falls within WRS-2 path 16, row 30 and path 17, row 30 as shown in Figures \ref{fig:16_30_overlaid} and \ref{fig:17_30_overlaid} \cite{ndbc_rochester}.  The observed water temperature from this site was obtained from the NDBC and corrected to the ground truth land surface temperature using the skin temperature method \cite{schott_2012}, \cite{schott_2010}.

% plot_narr.pro with B5
\begin{figure}[H]
\begin{minipage}[b]{0.5\linewidth}
\centering
\includegraphics[scale = 0.33]{results/16_30_overlaid.png}
\caption{Landsat scene (band 5) including Rochester, NY (path 16, row 30).  The white square represents the approximate location of the buoy.}
\label{fig:16_30_overlaid}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[b]{0.5\linewidth}
\centering
\includegraphics[scale = 0.33]{results/17_30_overlaid.png}
\caption{Landsat scene (band 5) including Rochester, NY (path 17, row 30).  The white square represents the approximate location of the buoy.}
\label{fig:17_30_overlaid}
\end{minipage}
\end{figure}

\subsection{Delaware Bay (Delmar)}
\label{sec:delmar}

A 3 m discus buoy owned and maintained by the National Buoy Data Center is located in Delaware Bay near the Delaware-Maryland line at 38.464$^\circ$N, 74.702$^\circ$W.  This buoy is located at sea level.  Standard meteorological data is available as early as 1984 but most other forms of data from this buoy are available beginning in the late 1990s.  This station stopped transmitting data in December 2012 but will be restored to regular functionality as soon as it can be serviced.  This buoy also falls in the overlap of Landsat paths, so it provides ground truth data for WRS-2 path 13, row 33 and path 14, row 33 as shown in Figures \ref{fig:13_33_overlaid} and \ref{fig:14_33_overlaid} \cite{ndbc_delmar}.  The observed water temperature from this site was obtained from the NDBC and corrected to the ground truth land surface temperature using the skin temperature method \cite{schott_2012}, \cite{schott_2010}.


% plot_narr.pro with B5
\begin{figure}[H]
\begin{minipage}[b]{0.5\linewidth}
\centering
\includegraphics[scale = 0.33]{results/13_33_overlaid.png}
\caption{Landsat scene (band 5) including Delaware Bay (path 13, row 33).  The white square represents the approximate location of the buoy.}
\label{fig:13_33_overlaid}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[b]{0.5\linewidth}
\centering
\includegraphics[scale = 0.33]{results/14_33_overlaid.png}
\caption{Landsat scene (band 5) including Delaware Bay (path 14, row 33).  The white square represents the approximate location of the buoy.}
\label{fig:14_33_overlaid}
\end{minipage}
\end{figure}

\subsection{Georgia Coast}
\label{sec:georgia}

A 3 m discus buoy owned and maintained by the National Buoy Data Center is located at sea level off the coast of Georgia, southeast of Savannah at 31.402$^\circ$N, 80.869$^\circ$W.  This buoy is located in Gray's Reef National Marine Sanctuary.  Standard meteorological data is first available in 1988 and other forms of data become available in the late 1990s and mid 2000s; all are through present.  This buoy falls within the WRS-2 path 16, row 38 Landsat scene as shown in Figure \ref{fig:16_38_overlaid}.  The observed water temperature from this site was obtained from the NDBC and adjusted to the ground truth land surface temperature using the skin temperature method \cite{schott_2012}, \cite{schott_2010}.

% plot_narr.pro with B5
\begin{figure}[H]
\centering
\includegraphics[scale = 0.45]{results/16_38_overlaid.png}
\caption{Landsat scene (band 5) off the coast of Georgia (path 16, row 33).  The white square represents the approximate location of the buoy.}
\label{fig:16_38_overlaid}
\end{figure}

\section{Initial Error}
\label{sec:initialerror}

Initial scenes to be processed were selected for spatial and temporal variation based on the location of the test sites described in Section \ref{sec:groundtruthsites} and the availability of ground truth data.  The predicted land surface temperatures for each site at the pixel location of each buoy are compared to the ground truth temperatures.  It is important to consider scene variety and selection when considering the results.  Initial investigations are aimed at determining if accurate land surface temperatures can be retrieved with this process.  We investigate later, particularly in the development of confidence metrics, how these results are affected by differing atmospheres and changes in time and location.  As mentioned, ground truth data for Lake Tahoe and the Salton Sea were provided by JPL; scenes from these sites were selected to lend themselves to good temperature retrieval (clear skies, no clouds, etc.).  Ground truth data from the other sites is obtained from the buoys and adjusted to the ground truth land surface temperature using the skin temperature method \cite{schott_2012}, \cite{schott_2010}.  Scene selection at these locations was less stringent than the selection requirements for Lake Tahoe and the Salton Sea.  It is important to consider this when analyzing results.  Rochester, Delmar, and Georgia are expected to have more variability because they were not preselected for clear stable atmospheres.

Error in the following sections is defined in Equation \ref{eq:initialerror}; a negative value indicates that the land surface temperature retrieval process underestimated the temperature and a positive value indicates that our process overestimated the temperature.

\begin{equation}
\mbox{error} = \mbox{Predicted LST} - \mbox{Ground Truth Temperature}
\label{eq:initialerror}
\end{equation}

\subsection{The Salton Sea}

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/saltonsea_plot.png}
\caption{Plot of predicted apparent LST values against the ground truth values for the Salton Sea.}
\label{fig:saltonsea_plot}
\end{figure}

Only 14 scenes were considered and compared to ground truth data for the Salton Sea validation site.  This should be remembered when considering the results.  Figure \ref{fig:saltonsea_plot} shows the predicted apparent LST values plotted against the ground truth temperature data; for reference, a one to one line is also plotted.  Figure \ref{fig:saltonseahistogram_large} shows a histogram of error values calculated using Equation \ref{eq:initialerror}, and Figure \ref{fig:saltonseahistogram_small} shows a closer look at the smallest error values in the histogram.

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/saltonseahistogram_large.png}
\caption{Histogram of error values for scenes including the Salton Sea.}
\label{fig:saltonseahistogram_large}
\end{figure}

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/saltonseahistogram_small.png}
\caption{Histogram of the smallest error values for scenes including the Salton Sea.}
\label{fig:saltonseahistogram_small}
\end{figure}

These results are slightly skewed negative; the bins on the negative side of the histogram are larger.  Of the 14 scenes processed, 12 scenes have an error between (-2 K, 2 K] and all 12 of these fall between (-1 K, 1 K].  The average of the absolute values of the error of all scenes processed over the Salton Sea is 0.739 K with a standard deviation of 1.096 K, with nearly all of the error attributable to one bad point.  Again, although these results neglect considerations of varying atmosphere and weather conditions, they give us confidence in our implementation and the ability of the process to accurately predict the land surface temperature.  Without considering how the system reacts to variability, Salton Sea results encourage us that our process is functioning at least as we intended.  Note that the Salton Sea is below sea level and is not expected to produce best case results, thus making these results very encouraging.

\subsection{Lake Tahoe}
\label{sec:laketahoeresults}

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/laketahoe_plot.png}
\caption{Plot of predicted apparent LST values against the ground truth values for Lake Tahoe.}
\label{fig:laketahoe_plot}
\end{figure}

There are 140 scenes that were initially processed and compared to ground truth data for the Lake Tahoe validation site.  A plot of the predicted apparent LST values versus the ground truth data is shown in Figure \ref{fig:laketahoe_plot}; the line again represents perfect retrieval results.  A histogram of error values is shown in Figure \ref{fig:laketahoehistogram_large} and a closer look at the distribution of the smallest errors in Figure \ref{fig:laketahoehistogram_small}.

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/laketahoehistogram_large.png}
\caption{Histogram of error values for scenes including Lake Tahoe.}
\label{fig:laketahoehistogram_large}
\end{figure}

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/laketahoehistogram_small.png}
\caption{Histogram of the smallest error values for scenes including Lake Tahoe.}
\label{fig:laketahoehistogram_small}
\end{figure}

Figure \ref{fig:laketahoe_plot} implies that the predicted temperatures more frequently underestimate the ground truth values; more points fall below the red line.  Figures \ref{fig:laketahoehistogram_large} and \ref{fig:laketahoehistogram_small} also show errors centered around zero but slightly skewed toward the negative side.  Of the 140 scenes processed, 132 scenes have errors within (-2 K, 2 K] and of these, 97 have errors within (-1 K, 1 K].  The average of the absolute value of the errors for all Lake Tahoe scenes is 0.795 K with a standard deviation of 0.674 K.  As mentioned above, these scenes were also selected for optimal LST retrieval from a dataset that had been collected to verify the calibration of Landsat 5.  However, if we remove cloudy scenes, the average of the absolute values of the errors is 0.707 K with a standard deviation of 0.574 K.  We identify cloudy scenes based on the cloud detection method discussed in Section \ref{sec:clouddetection}.  Without considering other factors such as varying atmospheres and changing weather, these initial results are very encouraging for the accuracy  and feasibility of the proposed temperature retrieval process.  Note that we expect good results at Tahoe because of its thin atmosphere (high altitude).

\subsection{Rochester}

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/rochester_plot.png}
\caption{Plot of predicted apparent LST values against the ground truth values for Rochester.}
\label{fig:rochester_plot}
\end{figure}

A total of 77 scenes containing the buoy northeast of Rochester were processed; initial results for path 16, row 30 and path 17, row 30 are combined.  These scenes were not preselected for clear stable atmospheres like the Lake Tahoe or Salton Sea scene selection.  The outcome is more variable results that can include cloudy scenes and inconsistent atmospheres.  Figure \ref{fig:rochester_plot} plots the predicted apparent LST values against the ground truth temperature data; the line represents perfect retrieval results.  Note that many points fall below this line.  Figures \ref{fig:rochesterhistogram_large} and \ref{fig:rochesterhistogram_small} are histograms of the error values calculated using Equation \ref{eq:initialerror} for all and the smallest of the error values respectively.

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/rochesterhistogram_large.png}
\caption{Histogram of error values for scenes including Rochester.}
\label{fig:rochesterhistogram_large}
\end{figure}

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/rochesterhistogram_small.png}
\caption{Histogram of the smallest error values for scenes including Rochester.}
\label{fig:rochesterhistogram_small}
\end{figure}

These results are more variable than those for Lake Tahoe and the Salton Sea.  Of the 77 scenes, 43 scenes have an error within (-2 K, 2 K] and of those, 29 scenes have an errors (-1 K, 1 K].  In Figure \ref{fig:rochester_plot}, many results lie below the red line indicating underestimation of the actual temperature.  Comparing Figures \ref{fig:laketahoehistogram_large} and \ref{fig:saltonseahistogram_large} to Figure \ref{fig:rochesterhistogram_large}, the negative errors are generally larger.  This histogram spurred a more manual investigation of the scenes.  Bands 5 and 6 were displayed and visually analyzed individually; the location of the buoy was considered in this visual investigation.  From this, we can conclude with a high degree of certainty that the left most bin in Figure \ref{fig:rochesterhistogram_large} can be attribtued to clouds in the scene.  When the satellite is sensing a cloud but the ground truth temperature is actually from the lake, the LST predicted by the satellite will be much lower than the ground truth temperature.  These results should not necessarily be deemed inaccurate or incorrect.  The process determines the temperature of what the satellite is sensing, and this is not the ground in all cases.  Although the volume of atmosphere being compensated for would be incorrect because the clouds are higher than the ground, this is likely a good estimate of the cloud temperature.  Considering an average cloud temperature of roughly 260 K, it would seem reasonable that errors of -10 K to -20 K or more are estimating cloud temperatures.  Eventually, an indicator for scenes with clouds or results that are the temperature of clouds rather than of the ground will need to be implemented.  Some scenes that are not in the left most bin but have large negative errors can still be attributed to clouds or wetter, colder atmospheres.  It scenes with a moderate amount of negative error (approximately (-4 K, -10 K]) that warrant further investigation.  We are concerned with why these errors are occurring and if we can predict or improve them depending on their cause.  Scenes with the smallest errors in Figures \ref{fig:rochesterhistogram_small} still show the slightly negative skew observed at all locations so far.  The average of the absolute values of the errors of all Rochester scenes is 10.642 K with a standard deviation of 22.717 K.  These values are skewed by the large error values of the cloudy scenes.  If we remove the cloudy scenes based on the cloud detector described in Section \ref{sec:clouddetection}, the average of the absolute value of the errors is reduced to 1.907 K with a standard deviation of 2.395 K.  Although these values drop considerably with cloud removal, note that the standard deviation is still relatively large and the errors are skewed to colder temperatures as would be expected for pixels contaminated by thin clouds.  Considering the clouds and variability in the atmospheres, these results are still encouraging as initial results for the ability of the process to retrieve land surface temperature under cloud free conditions.

\subsection{Delaware Bay (Delmar)}
\label{sec:delmarresults}

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/delmar_plot.png}
\caption{Plot of predicted apparent LST values against the ground truth values for Delmar.}
\label{fig:delmar_plot}
\end{figure}

Combining the path 13, row 33 and path 14, row 33 results, 108 scenes were processed containing the Delmar buoy.  Figure \ref{fig:delmar_plot} shows the predicted apparent LST values plotted against the ground truth temperatures with the line representing perfect retrieval results.  Figure \ref{fig:delmarhistogram_large} is a histogram of error values, calculated using Equation \ref{eq:initialerror}, and Figure \ref{fig:delmarhistogram_small} is a subset of the smallest error values.  

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/delmarhistogram_large.png}
\caption{Histogram of error values for scenes including Delmar.}
\label{fig:delmarhistogram_large}
\end{figure}

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/delmarhistogram_small.png}
\caption{Histogram of low error values for scenes including Delmar.}
\label{fig:delmarhistogram_small}
\end{figure}

The Delmar results more closely resemble the Rochester results, as opposed to Lake Tahoe or Salton Sea, because they contain scenes with clouds and inconsistent weather conditions as no preselection has occurred.  Of the 108 scenes processed, 62 scenes have errors between (-2 K, 2 K] and of these, 38 scenes have errors between (-1 K, 1 K].  The average of the absolute value of the error for all scenes processed over Delmar is 5.723 K with a standard deviation of 10.916 K.  Again, the left most bin in Figure \ref{fig:delmarhistogram_large} represents clouds; these large negative errors are not incorrect and unfairly bias the average error and standard deviation.  The average and standard deviation of the absolute values of the errors of non-cloudy scenes is 2.449 K and 3.164 K.  As with the Rochester results, underestimation is more common than overestimation and the moderate number of errors between (-3 K, -6 K] are most concerning.  Further investigation of our process and atmospheric properties is necessary to determine if we can improve or predict these results.  Even with this variability, there are enough scenes with reasonable errors that these results are encouraging for the functionality of the process being generated.  The proportion of good scenes is the first indication that moderate errors may be attributed to atmospheric properties rather than steps in our process.  This means there will be errors even if we correctly characterize and compensate for the atmosphere; this means we should focus on correlation between atmospheric variables and error rather than optimizing interpolations as they may not be limiting factors or contributing significant errors.  A more systematic error, such as the negative skew of the smallest errors, is more likely to be a result of something inherent to our process that we could work to determine and optimize.

\subsection{Georgia Coast}

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/georgia_plot.png}
\caption{Plot of predicted apparent LST values against the ground truth values for scenes off the Georgia coast.}
\label{fig:georgia_plot}
\end{figure}


Finally, 59 scenes were processed containing the buoy off the Georgia coast.  Figure \ref{fig:georgia_plot} plots predicted apparent LST against the ground truth temperature data; the one-to-one line represents perfect retrieval.  Figure \ref{fig:georgiahistogram_large} is a histogram of all errors calculated using Equation \ref{eq:initialerror} and Figure \ref{fig:georgiahistogram_small} is a histogram containing a subset of scenes scenes with the smallest error.  

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/georgiahistogram_large.png}
\caption{Histogram of error values for scenes off the Georgia coast.}
\label{fig:georgiahistogram_large}
\end{figure}

% validations/metrics.xlsx
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{results/georgiahistogram_small.png}
\caption{Histogram of the smallest error values for scenes off the Georgia coast.}
\label{fig:georgiahistogram_small}
\end{figure}

Similar to Rochester and Delmar, a handful of these scenes can be concluded to contain clouds over the buoy, most obviously illustrated in the left most bin of Figure \ref{fig:georgiahistogram_large}.  Again, the error values are negatively skewed as shown in Figure \ref{fig:georgiahistogram_small} and illustrated by the points below the line in Figure \ref{fig:georgia_plot}.  Of the 59 scenes processed, 39 results had errors between (-2 K, 2 K] and 24 of these had errors within (-1 K, 1 K].  The average of the absolute values of the error of all 59 scenes is 3.440 K with a  standard deviation of 5.523 K.  More so than the  Rochester and Delmar results, Georgia has a distribution of scenes centered around zero error and a cluster of scenes with larger negative errors that can be attributed to clouds.  After removing cloudy scenes using the cloud detection method discussed in Section \ref{sec:clouddetection}, the mean and standard deviation of the absolute values of the errors is 2.379 K and 3.485 K.  The handful of scenes with a moderate amount of unaccounted for error will be investigated further for the same reasons as described above in Section \ref{sec:delmarresults}.

\subsection{Summary of Initial Errors}

Overall, these initial results are extremely encouraging for the ability of our process to accurately retrieve land surface temperature.  In good conditions, temperature retrievals with errors between (-2 K, 2 K) are common and most of the larger negative errors (greater in magnitude than 6 K) can be attributed to sensing clouds.  Smaller errors in the majority of scenes are extremely encouraging for the functionality of our process.

It is important to understand that perfect land surface temperature retrieval results will not be achievable at all pixels or in all scenes.  For example, when the satellite images clouds, it is accurately retrieving the temperature of what is in the image, but it is not imaging the ground.  Additionally, when the atmosphere is warmer or more humid, accurate land surface temperature results may not be achievable with satellite imaging.  Results that warrant further investigation are the slight negative skew of even the best results (errors between -2 K and 2 K); we need to determine if this is due to a systematic error in the analytical approach or to a slight residual miscalibration of the instrument (see Barsi et al., 2003). Also, we need to understand and predict moderate amounts of error, within (-6 K, -3 K] and (3 K, 6 K], likely attributed to thin clouds not characterized by the NARR data

\section{Confidence Metrics}
\label{sec:confidencemetrics}

Making improvements to the process described above, such as adjustments to the interpolation methods, can only improve the characterization of the atmosphere or the retrieval of such radiative transfer parameters from the atmosphere; even when the characterization of the atmosphere is accurate, ground temperature retrieval can be hindered by the presence of clouds or the composition of the atmosphere.  When the ground leaving radiance cannot be accurately measured by the sensor due to the atmosphere, the predicted LST will not be an accurate estimation of the ground temperature.  If the atmospheric characterization is accurate, we should be able to predict when this will occur.  Therefore, an important aspect of the results is a measure of confidence or error in the predicted ground temperature based on the atmospheric composition and radiative transfer parameters.

Because of the fusion of multiple data sources, use of radiative transfer and reanalysis code, and multiple interpolations, a traditional error analysis is impractical.  The goal of the error analysis is to provide the user with a metric, qualitative or quantitative, that describes how accurate the final predicted ground temperature should be based on our atmospheric compensation.  We want to be able to predict for users when they can have high confidence in quality data, while still providing a best estimate solution for all pixels with higher expected errors for the lower confidence conditions.  Because this work does not include emissivity estimation, this metric only considers the error contributed from the atmospheric compensation and not the emissivity component (which is being developed by JPL for inclusion in the final product).

Two methods of confidence estimation are described below.  Regression analysis provides a qualitative analysis of the error contributed by the atmospheric compensation; this provides the user with a numerical value of the estimated error for each pixel.  The threshold analysis is a qualitative investigation of this error; this provides the user with a categorical judgement of the usability of each pixel as an apparent ground temperature.

\subsection{Metrics}
\label{sec:metrics}

Both methods of error analysis are based on the theory that as certain atmospheric variables increase or decrease, the ability to accurately retrieve the land surface temperature improves or worsens.  Rather than incorporate an additional data source, the confidence estimation will be made with metrics already contained within or generated from the atmospheric profile data and radiative transfer code.  Five metrics were chosen are described below.

The transmission, generated as described in Section \ref{sec:parameters}, is one metric used to estimate the confidence in the predicted land surface temperature.  Certain conditions do not lend themselves to accurate LST estimation, regardless of the performance of the method or process used.  Low transmission of the atmosphere above the pixel of interest is one of these.  With a low transmission, less radiance from the ground can reach the sensor; there is no way for a sensor to be able to predict the temperature of the ground if it is unable to measure the radiance due to temperature at the surface.  Therefore, the LST retrieval is less accurate with a lower atmospheric transmission and more accurate with a higher atmospheric transmission.

The second metric is the maximum air temperature in the atmospheric profile.  This is retrieved from the NARR atmospheric profile data.  Because this is an input to MODTRAN and MODTRAN is not executed at every pixel, an atmospheric profile does not exist for every pixel.  However, the same four NARR locations used to interpolate the radiative transfer parameters to that pixel location, as described in Section \ref{sec:spatialinterpolation}, are used to estimate the maximum air temperature in the atmospheric profile at a single pice.  The maximum air temperatures from each of these four NARR profiles are spatially interpolated using Shepard's method, as described in Section \ref{sec:spatialinterpolation}, to generate an estimation of the maximum air temperature in the atmospheric profile above the pixel of interest.  This does not consider the height in the profile of the maximum temperature; we simply select the highest temperature from each profile and interpolate regardless of elevation.  A higher maximum temperature tends to indicate a thicker, denser atmosphere, generating more path radiance.  Upwelled radiance can be a large contributor to error, so a small error in the measurement of a hot temperature can lead to a large error in upwelled radiance.  A similar magnitude error in a cold temperature would not cause as large an error in path radiance.  Less intuitive but similar to a low transmission, it is less likely that the ground leaving radiance is accurately sensed from the satellite with higher air temperatures because the additive path radiance effect introduces error.  Therefore, higher maximum air temperatures in the atmospheric profile indicate less accurate predicted land surface temperatures.

The last three metrics are all related to the amount of humidity in the atmosphere above the pixel of interest.  Just like maximum air temperature, because MODTRAN is not executed at every pixel, an atmospheric profile does not exist for every pixel.  The following three parameters are spatially interpolated from the four NARR points used to interpolate the radiative transfer parameters, like maximum temperature described above.

The relative humidity profile is one of the variables derived from the NARR data and used as an input profile in MODTRAN.  This profile is a measure of the amount of water in the air at various heights at that location.  Higher humidity levels hinder the amount of radiance reaching the sensor, and therefore a higher relative humidity means a less accurate land surface temperature retrieval.  The maximum relative humidities from each of the four NARR points are interpolated to generate as estimate of the maximum relative humidity at the pixel of interest.  As with maximum air temperature, elevation is not considered.  Theoretically, the lower the maximum relative humidity the more accurate the land surface temperature retrieval.  

The dew point depression is another measure of humidity in the atmosphere.  The dew point temperature, directly related to relative humidity, is the temperature at which humidity in the air will condense to liquid water.  The closer the air temperature is to the dew point temperature, the higher the water vapor content.  The dew point depression is the difference between the dew point temperature and the air temperature.  A smaller dew point depression indicates a higher level of humidity and therefore should correlate to less accurate land surface temperature prediction.  This information is largely redundant to the maximum relative humidity level but both are considered; one may exhibit better confidence estimation due to differences in magnitude or interpretability.

The final metric is the total column water vapor.  Also a measure of water in the profile, the column water vapor can be interpreted in two ways.  If all water molecules in the atmosphere were brought to the surface of the Earth at a pressure of one atmosphere and temperature of 0$^\circ$C, the water column would have some thickness in atmosphere-centimeters.  Similarly, over each square centimeter of ground surface, the water molecules in that column of the atmosphere have some mass in grams per centimeter squared (gm/cm$^2$).  Because the density of liquid water is 1 gm/cm$^2$, the mass of the water molecules in the column in grams per centimeter squared is equal to the centimeters of water on the ground if all of the water rained out of the atmosphere.  Similar to relative humidity and dew point depression, more water in the atmosphere makes it more difficult for the sensor to accurately measure the radiance due to temperature leaving the ground; theoretically a larger column water vapor would lead to a less accurate predicted land surface temperature.  

\subsection{Initial Cloud Detection}
\label{sec:clouddetection}

As described in Section \ref{sec:initialerror}, it is impossible to accurately predict the land surface temperature when the satellite is imaging a cloud.  While it is expected that cloudy scenes will have large errors, low transmission, high relative humidity, small dew point depression, and high column water vapor, clouds may behave differently and have errors on a different order of magnitude than the scenes we are attempting to segment with our confidence metrics.  Therefore, prior to confidence metric estimation, a simple cloud detector is implemented.  If the retrieved temperature is less than 275 K or if the retrieved temperature is more than 15 K below the air temperature of the lowest atmospheric layer in the profile, the pixel is classified as cloudy.  These pixels are not used in the regressions described below and are also segmented as a separate category for the threshold analysis.

From our visual investigation of scenes, this is a conservative cloud detector.  While it may not classify all clouds as clouds, it has a very low instance of classifying non-clouds as clouds.  Our main goal with this detector is to eliminate the most obvious clouds, the left-most bin in the histograms in Section \ref{sec:initialerror}, from our confidence metric analysis.  A more sophisticated cloud detection algorithm can be investigated later.

\subsection{Regression Analysis}
\label{sec:regression}

As described above, it is expected that the accuracy of the land surface temperature retrieval varies with the five chosen metrics.  The mathematical model of this variability is unknown.  Therefore, as an initial quantitative estimate, a linear regression was performed at each location individually and all locations together for each metric and the absolute values of the error from Equation \ref{eq:initialerror}.  We will refer to this as the actual error.  Also, multivariate linear regressions were performed for a subset of the variables and all of the variables together at each location individually and all of the locations together.  While there is no particular reason to assume linear behavior, this initial analysis will give us a chance to visualize the data and determine if another form of regression would be more appropriate or if quantitative analysis is feasible.  With these regression, given the actual value of a metric, we can predict the error in the land surface temperature at that pixel.  

As described above, the scene selection specifications are different for each location.  Therefore, each location is considered individually to investigate how such a regression behaves with differing datasets.  The goal of the regression analysis is to be able to predict the possible error (in degrees kelvin) associated with the predicted LST value at each pixel.  If we were to implement this method of error analysis, we would need a large database of ground truth and predicted temperatures from sufficiently variable conditions to build our regression models.  Considering the linear regression model at individual locations gives us a better idea of the variability with location and the type and volume of data we would need to build such models.

The following sections summarize the regression analysis results for each metric at each location individually and all locations together.  There are three methods presented to analyze the performance of our regression analysis.  

Firstly, we can consider the shape of the data and if it appears to follow the linear relationship used to model it.  In the following sections, for each metric for each location individually and all locations together, the error is plotted as a function of the metric and the linear regression model is shown on the same plot.  This is one method of visual analysis.

\begin{equation}
\mbox{residual} = \mbox{ABS}(\mbox{Predicted Error} - \mbox{Actual Error})
\label{eq:residual}
\end{equation}

Secondly, we calculate the residual as shown in Equation \ref{eq:residual}.  This is the difference between the error predicted by the linear regression model and the absolute value of the error between the predicted land surface temperature and buoy temperature, which we refer to as the actual error.  Smaller residuals indicate our regression analysis is accurately predicting the error associated with a pixel.  In a perfect linear relationship, the residual would be zero for all scenes.  However, we suspect the relationship may be linear only over some range of errors.  Because they are the most difficult for us to understand, we are particularly concerned with the moderate errors, 5 K to 10 K, and if we can determine the accuracy of the land surface temperatures retrieved at these pixels.  We perform a simple qualitative visual analysis by plotting the residual against the error for each point.  

Finally, we calculate the mean and standard deviation of the residuals for each metric at each location.  This is a quantitative analysis of the results of the regression analysis.

\subsubsection{Transmission in Regression Analysis}

Figures \ref{fig:ssTauReg}, \ref{fig:ltTauReg}, \ref{fig:rocTauReg}, \ref{fig:delmarTauReg}, and \ref{fig:gaTauReg} show the transmission plotted as a function of the actual error for the Salton Sea, Lake Tahoe, Rochester, Delmar, and Georgia respectively.  Also on each plot is the linear regression model.  Figure \ref{fig:TauReg} shows the same plot with all locations and the line of best fit.  All plots are shown with the same transmission and error ranges.  Figures \ref{fig:ssTauResidual}, \ref{fig:ltTauResidual}, \ref{fig:rocTauResidual}, \ref{fig:delmarTauResidual}, and \ref{fig:gaTauResidual} show the residual computed as shown in Equation \ref{eq:residual} plotted against the actual error calculated as shown in Equation \ref{eq:initialerror}.  All plots are shown with the same error and residual range.  Note that these ranges were chosen to include most points and maintain some degree of detail.  Some outliers may not be shown on the plot.  The mean and standard deviation of the residuals for each location are summarized in Table \ref{tab:TauResidual}.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssTauReg.png}
\caption{Actual error vs. transmission for the Salton Sea with the line of best fit.}
\label{fig:ssTauReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssTauResidual.png}
\caption{Residual vs. actual error for transmission regression at the Salton Sea.}
\label{fig:ssTauResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltTauReg.png}
\caption{Actual error vs. transmission for Lake Tahoe with the line of best fit.}
\label{fig:ltTauReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltTauResidual.png}
\caption{Residual vs. actual error for transmission regression at Lake Tahoe.}
\label{fig:ltTauResidual}
\end{minipage}
\end{figure}

Because the scenes over the Salton Sea and Lake Tahoe are well behaved, they can be modeled with a linear regression with relatively low residuals.  Looking at Figures \ref{fig:ssTauReg} and \ref{fig:ltTauReg}, the data is not necessarily linearly behaved but all have relatively high transmission values and the initial range of errors is small, so the residuals are small.  Most points fit the linear model with only a handful of anomalies as shown in Figures \ref{fig:ssTauResidual} and \ref{fig:ltTauResidual}.  Notice that the Salton Sea regression has a positive slope while the Lake Tahoe regression has a negative slope, indicating that although the residuals are low, the data is not behaving as expected.  We expect the error to decrease as the transmission increases, resulting in a negative gradient.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocTauReg.png}
\caption{Actual error vs. transmission for Rochester with the line of best fit.}
\label{fig:rocTauReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocTauResidual.png}
\caption{Residual vs. actual error for transmission regression at Rochester.}
\label{fig:rocTauResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarTauReg.png}
\caption{Actual error vs. transmission for Delmar with the line of best fit.}
\label{fig:delmarTauReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarTauResidual.png}
\caption{Residual vs. actual error for transmission regression at Delmar.}
\label{fig:delmarTauResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaTauReg.png}
\caption{Actual error vs. transmission for Georgia with the line of best fit.}
\label{fig:gaTauReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaTauResidual.png}
\caption{Residual vs. actual error for transmission regression at Georgia.}
\label{fig:gaTauResidual}
\end{minipage}
\end{figure}

Scenes over Rochester, Delmar, and Georgia are not as well-behaved, as shown in Figures \ref{fig:rocTauReg}, \ref{fig:delmarTauReg}, and \ref{fig:gaTauReg}.  The range of transmission is larger for these three sites and the range of errors is also much larger.  Visual analysis shows that these relationships are not linear, and this is also reflected in the residuals in Figures \ref{fig:rocTauResidual}, \ref{fig:delmarTauResidual}, and \ref{fig:gaTauResidual}.  The regressions result in a positive, almost constant, and negative gradient for Rochester, Delmar and Georgia respectively, indicating that the data cannot be modeled as decreasing error with increasing transmission.  Although the relationships do not appear to be linear, it is not easy to visually identify another model that would accurately represent the data.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/TauReg.png}
\caption{Actual error vs. transmission with the line of best fit for all locations.}
\label{fig:TauReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/TauResidual.png}
\caption{Residual vs. actual error for transmission regression at all locations.}
\label{fig:TauResidual}
\end{minipage}
\end{figure}

Finally, considering the linear regression for all locations together in Figure \ref{fig:TauReg}, the data does not appear to be linear and this is reflected in Figure \ref{fig:TauResidual}.  Because of the large number of scenes in the Lake Tahoe data set, and the relatively large proportion of scenes with errors between 1 K and 2 K, the linear regression model is largely influenced by these points and scenes with errors between 1 K and 2 K have the minimum residuals.  Many scenes with errors between 5 K and 10 K have unacceptably high residuals.  This is also reflected in Table \ref{tab:TauResidual}.  The means and standard deviations of the residuals are low for Salton Sea and Lake Tahoe; although the means are not excessively large for the rest of the locations, the standard deviations are considerably larger.  This indicates that the mean is influenced by the large portion of scenes with low errors and correspondingly low residuals; these have the largest influence on the linear regression model, but there are a handful of scenes with larger errors, and larger residuals, as indicated by the standard deviation.  This does not give us confidence that our confidence metric will identify and predict scenes with moderate amounts of error.

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c |}
\hline
Location & Mean [K] & Standard Deviation [K] \\ \hline
Salton Sea & 0.595 & 0.826 \\ \hline
Lake Tahoe & 0.449 & 0.351 \\ \hline
Rochester & 1.746 & 1.618 \\ \hline
Delmar & 2.085 & 2.359 \\ \hline
Georgia & 2.177 & 2.609 \\ \hline
All Locations & 1.406 & 2.025 \\ \hline
\end{tabular}
\caption{Mean and standard deviation of residuals for transmission regression.}
\label{tab:TauResidual}
\end{center}
\end{table}

\subsubsection{Relative Humidity in Regression Analysis}

Figures \ref{fig:ssRHReg}, \ref{fig:ltRHReg}, \ref{fig:rocRHReg}, \ref{fig:delmarRHReg}, and \ref{fig:gaRHReg} show the errors plotted as a function of relative humidity for each location individually with the linear regression model for that location included on the plot.  Figures \ref{fig:ssRHResidual}, \ref{fig:ltRHResidual}, \ref{fig:rocRHResidual}, \ref{fig:delmarRHResidual}, and \ref{fig:gaRHResidual} show the residuals plotted against the error for these linear regression models.  Figures \ref{fig:RHReg} and \ref{fig:RHResidual} show the same for all locations together.  The means and standard deviations of the residuals are summarized in Table \ref{tab:RHResidual}.  

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssRHReg.png}
\caption{Actual error vs. relative humidity for the Salton Sea with the line of best fit.}
\label{fig:ssRHReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssRHResidual.png}
\caption{Residual vs. actual error for relative humidity regression at the Salton Sea.}
\label{fig:ssRHResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltRHReg.png}
\caption{Actual error vs. relative humidity for Lake Tahoe with the line of best fit.}
\label{fig:ltRHReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltRHResidual.png}
\caption{Residual vs. actual error for relative humidity regression at Lake Tahoe.}
\label{fig:ltRHResidual}
\end{minipage}
\end{figure}

Similar to the models for transmission, Salton Sea and Lake Tahoe provide the best results.  Considering Figures \ref{fig:ssRHReg} and \ref{fig:ltRHReg} more closely, even though the scenes were chosen for good retrieval conditions, there is a large range of relative humidities present, and they appear to behave linearly with error.  Although the range of errors is still small, there is a visual trend of increasing error with increasing relative humidity.  This is reinforced by the residuals shown in Figures \ref{fig:ssRHResidual} and \ref{fig:ltRHResidual}.  Particularly at Lake Tahoe, residuals do not increase with error, as in many other cases, indicating that the linear relationship more accurately represents all scenes and is not only true over a small range of data.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocRHReg.png}
\caption{Actual error vs. relative humidity for Rochester with the line of best fit.}
\label{fig:rocRHReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocRHResidual.png}
\caption{Residual vs. actual error for relative humidity regression at Rochester.}
\label{fig:rocRHResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarRHReg.png}
\caption{Actual error vs. relative humidity for Delmar with the line of best fit.}
\label{fig:delmarRHReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarRHResidual.png}
\caption{Residual vs. actual error for relative humidity regression at Delmar.}
\label{fig:delmarRHResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaRHReg.png}
\caption{Actual error vs. relative humidity for Georgia with the line of best fit.}
\label{fig:gaRHReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaRHResidual.png}
\caption{Residual vs. actual error for relative humidity regression at Georgia.}
\label{fig:gaRHResidual}
\end{minipage}
\end{figure}

Although the results for Rochester, Delmar and Georgia in Figures \ref{fig:rocRHReg}, \ref{fig:delmarRHReg}, and \ref{fig:gaRHReg} appear to be more linearly behaved than transmission, and all have positive gradients as expected, there are a still number of anomalies that indicate that these would not model the data accurately enough for good error prediction.  At all three locations, but particularly in Georgia, there are larger residuals even when the actual error is small in Figures \ref{fig:rocRHResidual}, \ref{fig:delmarRHResidual}, and \ref{fig:gaRHResidual}.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/RHReg.png}
\caption{Actual error vs. relative humidity with the line of best fit for all locations.}
\label{fig:RHReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/RHResidual.png}
\caption{Residual vs. actual error for relative humidity regression at all locations.}
\label{fig:RHResidual}
\end{minipage}
\end{figure}

The results for the linear regression model for all locations are very similar to those for transmission.  Largely influenced by the large number of scenes with 1 K to 2 K error, the minimum in the residuals is at this point.  Larger residuals at the smallest errors and moderate errors are concerning.  It appears that with this model we can only accurately predict the error over a small range.  This is reinforced by the means and standard deviations as shown in Table \ref{tab:RHResidual}.  Salton Sea and Lake Tahoe both have small means and standard deviations; the means for all other locations could be acceptably small but the larger standard deviations, as supported by the plots, indicate that there are a number of scenes that are not accurately modeled.

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c |}
\hline
Location & Mean [K] & Standard Deviation [K] \\ \hline
Salton Sea & 0.549 & 0.567 \\ \hline
Lake Tahoe & 0.444 & 0.347 \\ \hline
Rochester & 0.347 & 1.681 \\ \hline
Delmar & 1.660 & 2.109 \\ \hline
Georgia & 2.224 & 2.569 \\ \hline
All Locations & 1.439 & 1.981 \\ \hline
\end{tabular}
\caption{Mean and standard deviation of residuals for relative humidity regression.}
\label{tab:RHResidual}
\end{center}
\end{table}

\subsubsection{Maximum Temperature in Regression Analysis}

Actual error is plotted versus maximum temperature for the Salton Sea, Lake Tahoe, Rochester, Delmar and Georgia in Figures \ref{fig:ssTReg}, \ref{fig:ltTReg}, \ref{fig:rocTReg}, \ref{fig:delmarTReg}, and \ref{fig:gaTReg} respectively with the linear regression models shown on the plots.  Correspondingly, the residuals are plotted versus the actual error for the same locations in Figures \ref{fig:ssTResidual}, \ref{fig:ltTResidual}, \ref{fig:rocTResidual}, \ref{fig:delmarTResidual}, and \ref{fig:gaTResidual}.  The same is shown for all locations in Figures \ref{fig:TReg} and \ref{fig:TResidual}.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssTReg.png}
\caption{Actual error vs. maximum temperature for the Salton Sea with the line of best fit.}
\label{fig:ssTReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssTResidual.png}
\caption{Residual vs. actual error for maximum temperature regression at the Salton Sea.}
\label{fig:ssTResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltTReg.png}
\caption{Actual error vs. maximum temperature for Lake Tahoe with the line of best fit.}
\label{fig:ltTReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltTResidual.png}
\caption{Residual vs. actual error for maximum temperature regression at Lake \\ Tahoe.}
\label{fig:ltTResidual}
\end{minipage}
\end{figure}

As with transmission, the scenes for the Salton Sea and Lake Tahoe have tendencies of linear behavior with maximum temperature and such a linear model would be reasonable for either single set data as shown in Figures \ref{fig:ssTReg} and \ref{fig:ltTReg}.  However, the slopes of the linear models are slight, with a slight positive gradient in the Salton Sea regression and a slight negative gradient in the Lake Tahoe regression.  We would expect the error to increase with maximum temperature, unlike the trend shown in the Lake Tahoe data.  With only one anomaly at the Salton Sea, all other residuals at both sites are less than 2 K in Figures \ref{fig:ssTResidual} and \ref{fig:ltTResidual}.  It is important to note that most actual errors for all scenes at both sites are below 4 K.  Larger residuals are less likely with a smaller error range.  Regardless of the accuracy of our linear regression, predicting any small error will result in a small residual, which is not helpful for this analysis of our error prediction.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocTReg.png}
\caption{Actual error vs. maximum temperature for Rochester with the line of best fit.}
\label{fig:rocTReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocTResidual.png}
\caption{Residual vs. actual error for maximum temperature regression at \\ Rochester.}
\label{fig:rocTResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarTReg.png}
\caption{Actual error vs. maximum temperature for Delmar with the line of best fit.}
\label{fig:delmarTReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarTResidual.png}
\caption{Residual vs. actual error for maximum temperature regression at Delmar.}
\label{fig:delmarTResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaTReg.png}
\caption{Actual error vs. maximum temperature for Georgia with the line of best fit.}
\label{fig:gaTReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaTResidual.png}
\caption{Residual vs. actual error for maximum temperature regression at Georgia.}
\label{fig:gaTResidual}
\end{minipage}
\end{figure}

The data for maximum temperature at Rochester, Delmar, and Georgia so not have linear tendencies as a group as shown in Figures \ref{fig:rocTReg}, \ref{fig:delmarTReg}, and \ref{fig:gaTReg}; all three regressions have positive gradients as expected, but there are enough anomalies to make the linear models unrealistic for predicting error for all scenes.  Unlike some of the other metrics, where the model is decidedly more accurate over a small range of errors, regressions with maximum temperature at these three locations have a variety of residuals over the whole range shown in Figures \ref{fig:rocTResidual}, \ref{fig:delmarTResidual}, and \ref{fig:gaTResidual}.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/TReg.png}
\caption{Actual error vs. maximum temperature with the line of best fit for all locations.}
\label{fig:TReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/TResidual.png}
\caption{Residual vs. actual error for maximum temperature regression at all \\ locations.}
\label{fig:TResidual}
\end{minipage}
\end{figure}

Figure \ref{fig:TReg} shows that all locations plotted together does not result in a linear data set.  This can be observed visually and also by the linear regression model with an almost constant slope; in fact, the regression is influenced so much by the Lake Tahoe scenes that it has a slightly negative slope although we expect error to increase with increasing maximum temperature as it did with all individual locations except Lake Tahoe.  This is further illustrated in Figure \ref{fig:TResidual}; the pattern in the residuals shows a distinct minimum just below an error of 2 K, which is approximately equal to the almost constant value of the linear regression.  Because of the constant nature of the model, there are larger residuals at error values smaller and larger than this constant.  This suggests a linear model would not accurately predict errors for all of the locations, as supported by Table \ref{tab:TResidual}.  There are lower means and standard deviations for both the Salton Sea and Lake Tahoe and larger means and much larger standard deviations at all other locations, indicating that the linear regression models do not accurately predict the error for all points.

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c |}
\hline
Location & Mean [K] & Standard Deviation [K] \\ \hline
Salton Sea & 0.702 & 0.816 \\ \hline
Lake Tahoe & 0.426 & 0.337 \\ \hline
Rochester & 1.733 & 1.632 \\ \hline
Delmar & 2.110 & 2.342 \\ \hline
Georgia & 2.143 & 2.553 \\ \hline
All Locations & 1.529 & 2.031 \\ \hline
\end{tabular}
\caption{Mean and standard deviation of residuals for maximum temperature regression.}
\label{tab:TResidual}
\end{center}
\end{table}

\subsubsection{Dew Point Depression in Regression Analysis}

Figures \ref{fig:ssDiffReg}, \ref{fig:ltDiffReg}, \ref{fig:rocDiffReg}, \ref{fig:delmarDiffReg} and \ref{fig:gaDiffReg} show the actual error plotted against the dew point depression with the linear models and Figures \ref{fig:ssDiffResidual}, \ref{fig:ltDiffResidual}, \ref{fig:rocDiffResidual}, \ref{fig:delmarDiffResidual}, and \ref{fig:gaDiffResidual} illustrate the corresponding residuals.  Figures \ref{fig:DiffReg} and \ref{fig:DiffResidual} show the same for all locations.  

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssDiffReg.png}
\caption{Actual error vs. dew point depression for the Salton Sea with the line of best fit.}
\label{fig:ssDiffReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssDiffResidual.png}
\caption{Residual vs. actual error for dew point depression regression at the \\ Salton Sea.}
\label{fig:ssDiffResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltDiffReg.png}
\caption{Actual error vs. dew point depression for Lake Tahoe with the line of best fit.}
\label{fig:ltDiffReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltDiffResidual.png}
\caption{Residual vs. actual error for dew point depression regression at Lake Tahoe.}
\label{fig:ltDiffResidual}
\end{minipage}
\end{figure}

Results with the dew point depression metric for the Salton Sea and Lake Tahoe in Figures \ref{fig:ssDiffReg} and \ref{fig:ltDiffReg} look similar to, but inverted from the relative humidity results.  This is expected as the dew point depression is derived from and related to the relative humidity.  It is considered as a different method of confidence metric determination only to investigate if another relationship provides more clarity but they appear to give redundant results.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocDiffReg.png}
\caption{Actual error vs. dew point depression for Rochester with the line of best fit.}
\label{fig:rocDiffReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocDiffResidual.png}
\caption{Residual vs. actual error for dew point depression regression at Rochester.}
\label{fig:rocDiffResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarDiffReg.png}
\caption{Actual error vs. dew point depression for Delmar with the line of best fit.}
\label{fig:delmarDiffReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarDiffResidual.png}
\caption{Residual vs. actual error for dew point depression regression at Delmar.}
\label{fig:delmarDiffResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaDiffReg.png}
\caption{Actual error vs. dew point depression for Georgia with the line of best fit.}
\label{fig:gaDiffReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaDiffResidual.png}
\caption{Residual vs. actual error for dew point depression regression at Georgia.}
\label{fig:gaDiffResidual}
\end{minipage}
\end{figure}

Actual error plotted as a function of dew point depression in Figures \ref{fig:rocDiffReg}, \ref{fig:delmarDiffReg}, and \ref{fig:gaDiffReg} for Rochester, Delmar, and Georgia respectively also look similarly inverted from the relative humidity results at these locations.  All have negative gradients as expected but the data does not appear to behave linearly and this is confirmed by the residuals.  There are large residuals for varying magnitudes of actual error in Figures \ref{fig:rocDiffResidual}, \ref{fig:delmarDiffResidual}, and \ref{fig:gaDiffResidual}.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/DiffReg.png}
\caption{Actual error vs. dew point depression with the line of best fit for all locations.}
\label{fig:DiffReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/DiffResidual.png}
\caption{Residual vs. actual error for dew point depression regression at all \\ locations.}
\label{fig:DiffResidual}
\end{minipage}
\end{figure}

The plot for all locations together shown in Figure \ref{fig:DiffReg} is inverted from the relative humidity plot shown in Figure \ref{fig:RHReg}.  As a general pattern, actual error decreases as dew point depression increases as expected and in Figure \ref{fig:DiffResidual} the residuals from the dew point depression regression are very similar to the residuals for the relative humidity regression.  Residuals are smallest for scenes with errors between 1 K and 2 K due to the large number of scenes at these actual error values that largely influence the regression.  However, residuals are larger for smaller errors and much larger for larger errors as shown in Figure \ref{fig:DiffResidual}.  This is concerning for predicting confidence in our best and worst results.  Results for the means and standard deviations of the residuals for dew point depression, summarized in Table \ref{tab:DiffResidual}, are very similar to those for relative humidity, shown in Table \ref{tab:RHResidual}.  It does not appear, as we were hoping, that one of these metrics provides a different perspective on the error analysis and neither sufficiently predicts error for the entire dataset.

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c |}
\hline
Location & Mean [K] & Standard Deviation [K] \\ \hline
Salton Sea & 0.572 & 0.473 \\ \hline
Lake Tahoe & 0.451 & 0.343 \\ \hline
Rochester & 1.675 & 1.647 \\ \hline
Delmar & 2.090 & 2.334 \\ \hline
Georgia & 2.201 & 2.603 \\ \hline
All Locations & 1.460 & 1.975 \\ \hline
\end{tabular}
\caption{Mean and standard deviation of residuals for dew point depression regression.}
\label{tab:DiffResidual}
\end{center}
\end{table}

\subsubsection{Column Water Vapor in Regression Analysis}

Figures \ref{fig:ssCWVReg}, \ref{fig:ltCWVReg}, \ref{fig:rocCWVReg}, \ref{fig:delmarCWVReg}, and \ref{fig:gaCWVReg} show the actual errors plotted as a function of the column water vapor for Salton Sea, Lake Tahoe, Rochester, Delmar and Georgia respectively; the corresponding residuals are shown in Figures \ref{fig:ssCWVResidual}, \ref{fig:ltCWVResidual}, \ref{fig:rocCWVResidual}, \ref{fig:delmarCWVResidual}, and \ref{fig:gaCWVResidual}.  The same is shown for all locations in Figures \ref{fig:CWVReg} and \ref{fig:CWVResidual}.  Although column water vapor is also a measure of humidity, it is derived differently than the relative humidity and dew point depression, so it can provide new insight in our confidence metric determination.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssCWVReg.png}
\caption{Actual error vs. column water vapor for the Salton Sea with the line of best fit.}
\label{fig:ssCWVReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssCWVResidual.png}
\caption{Residual vs. actual error for column water vapor regression at the Salton Sea.}
\label{fig:ssCWVResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltCWVReg.png}
\caption{Actual error vs. column water vapor for Lake Tahoe with the line of best fit.}
\label{fig:ltCWVReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltCWVResidual.png}
\caption{Residual vs. actual error for column water vapor regression at Lake Tahoe.}
\label{fig:ltCWVResidual}
\end{minipage}
\end{figure}

Regression results for column water vapor look most similar to those for transmission.  Most of the results are well-behaved but do not appear linear as shown in Figures \ref{fig:ssCWVReg} and \ref{fig:ltCWVReg}.  The Salton Sea regression has a positive gradient as expected because errors should increase with column water vapor, but the Lake Tahoe regression has a slight negative gradient.  All actual errors and corresponding residuals are small, as shown in Figures \ref{fig:ssCWVReg} and \ref{fig:ltCWVReg}, but the data does not follow the linearity relationship as expected or desired for error prediction.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocCWVReg.png}
\caption{Actual error vs. column water vapor for Rochester with the line of best fit.}
\label{fig:rocCWVReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocCWVResidual.png}
\caption{Residual vs. actual error for column water vapor regression at Rochester.}
\label{fig:rocCWVResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarCWVReg.png}
\caption{Actual error vs. column water vapor for Delmar with the line of best fit.}
\label{fig:delmarCWVReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarCWVResidual.png}
\caption{Residual vs. actual error for column water vapor regression at Delmar.}
\label{fig:delmarCWVResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaCWVReg.png}
\caption{Actual error vs. column water vapor for Georgia with the line of best fit.}
\label{fig:gaCWVReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaCWVResidual.png}
\caption{Residual vs. actual error for column water vapor regression at Georgia.}
\label{fig:gaCWVResidual}
\end{minipage}
\end{figure}

Actual error is plotted as a function of column water vapor for Rochester, Delmar and Georgia in Figures \ref{fig:rocCWVReg}, \ref{fig:delmarCWVReg}, and \ref{fig:gaCWVReg}.  Also similar to transmission at these locations, these results all have regressions with positive gradients as expected, but the data is not linear nor well-behaved, illustrated by the residuals in Figures \ref{fig:rocCWVResidual}, \ref{fig:delmarCWVResidual}, and \ref{fig:gaCWVResidual}.  There is a large range of column water vapor values and a varied range of residual magnitudes over the entire range of actual error, rather than increasing residuals with increasing error as seen, although not desired, with some other metrics.  These data do not appear to be modeled well with linear regressions and there is not another visually obvious model for the data.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/CWVReg.png}
\caption{Actual error vs. column water vapor with the line of best fit for all locations.}
\label{fig:CWVReg}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/CWVResidual.png}
\caption{Residual vs. actual error for column water vapor regression at all locations.}
\label{fig:CWVResidual}
\end{minipage}
\end{figure}

The regression model for all locations together is shown in Figure \ref{fig:CWVReg} with the corresponding residuals shown in Figure \ref{fig:CWVResidual}.  Although the regression has a positive gradient as expected, similar to outcomes for most other metrics, the residuals are at a minimum for scenes with 1 K to 2 K error, indicating that the regression model is influenced by the large number of scenes with this range.  Higher residuals for the smallest and largest errors are concerning.  Table \ref{tab:CWVResidual} shows that although the means are reasonable, the higher standard deviations at Rochester, Delmar, Georgia and all locations together indicate that while the error for average scenes may be well predicted, errors for scenes with the smallest and largest errors are not predicted well.

Note that in Figure \ref{fig:CWVReg}, if we were to draw a vertical line at 3 cm and give a high confidence to anything below 3 cm and a low confidence to any result with a total column water vapor above 3 cm, we capture many of the poor performers in our low confidence category without eliminating very many good results.  This is one indication we may have more success with a thresholding method as we will discuss in Section \ref{sec:threshold}.

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c |}
\hline
Location & Mean [K] & Standard Deviation [K] \\ \hline
Salton Sea & 0.622 & 0.826 \\ \hline
Lake Tahoe & 0.446 & 0.343 \\ \hline
Rochester & 1.692 & 1.632 \\ \hline
Delmar & 2.089 & 2.358 \\ \hline
Georgia & 2.187 & 2.617 \\ \hline
All Locations & 1.464 & 2.045 \\ \hline
\end{tabular}
\caption{Mean and standard deviation of residuals for column water vapor regression.}
\label{tab:CWVResidual}
\end{center}
\end{table}

\subsubsection{Three Metrics in Regression Analysis}

Attempting to capture the effects of multiple metrics, a multivariate linear regression was performed with three of the five metrics.  Because relative humidity, dew point depression, and column water vapor are all measures of humidity, a multivariate linear regression was performed with transmission, maximum temperature, and relative humidity.  The goal is to capture the behavior of each metric and reduce the influence of anomalies in any one metric.  Because the relationship between three metrics and the actual error is considered, plots like we have used to analyze all other metrics are four-dimensional and therefore cannot be visualized; the residuals are plotted for each location individually in Figures \ref{fig:ssThreeResidual}, \ref{fig:ltThreeResidual}, \ref{fig:rocThreeResidual}, \ref{fig:delmarThreeResidual}, and \ref{fig:gaThreeResidual} respectively.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssThreeResidual.png}
\caption{Residual vs. actual error for three metric regression at the Salton Sea.}
\label{fig:ssThreeResidual}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltThreeResidual.png}
\caption{Residual vs. actual error for three metric regression at Lake Tahoe.}
\label{fig:ltThreeResidual}
\end{minipage}
\end{figure}


Results for the Salton Sea and Lake Tahoe are difficult to analyze without being able to visualize the data.  Because the data is so well-behaved for the samples that we have at these two sites, the error range is small and the residuals are small, shown in Figures \ref{fig:ssThreeResidual} and \ref{fig:ltThreeResidual}, as they have been for most other regressions at these two sites.  We are unable to conclude whether this is only due to small actual errors or more accurate error prediction.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocThreeResidual.png}
\caption{Residual vs. actual error for three metric regression at Rochester.}
\label{fig:rocThreeResidual}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarThreeResidual.png}
\caption{Residual vs. actual error for three metric regression at Delmar.}
\label{fig:delmarThreeResidual}
\end{minipage}
\end{figure}

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaThreeResidual.png}
\caption{Residual vs. actual error for three metric regression at Georgia.}
\label{fig:gaThreeResidual}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ThreeResidual.png}
\caption{Residual vs. actual error for three metric regression at all locations.}
\label{fig:ThreeResidual}
\end{minipage}
\end{figure}


Residuals at Rochester, Delmar and Georgia, shown in Figures \ref{fig:rocThreeResidual}, \ref{fig:delmarThreeResidual}, and \ref{fig:gaThreeResidual} are more informative than residuals at the Salton Sea and Lake Tahoe.  The residuals are not excessively large and do not appear to have any particular pattern of behavior with error; that is, there are large and small residuals throughout the range of errors at all three locations.  Most importantly, in a visual comparison to the single metric regressions, there is not a significant improvement in residuals.

The residuals for the three metric regression at all locations in Figure \ref{fig:ThreeResidual} are also very similar to the patterns seen in the single metric regressions.  Although there are more low residuals at the lowest errors, there is still a trend of the lowest residuals in the 1 K to 2 K error range and increasing residuals with increasing error.  The regression is likely most influenced by the large set of scenes with 1 K to 2 K actual error, with the reoccurring theme of difficulty in predicting errors for the smallest and largest errors.  This is reiterated by the means and standard deviations of the residuals as shown in Table \ref{tab:ThreeResidual}, very similar to most single metric results.  The small means but larger standard deviations indicate that while the residuals are centered around a reasonable value, there is difficulty in predicting error for scenes different from the average.

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c |}
\hline
Location & Mean [K] & Standard Deviation [K] \\ \hline
Salton Sea & 0.503 & 0.597 \\ \hline
Lake Tahoe & 0.422 & 0.337 \\ \hline
Rochester & 1.736 & 1.474 \\ \hline
Delmar & 2.096 & 2.344 \\ \hline
Georgia & 2.147 & 2.400 \\ \hline
All Locations & 1.392 & 1.992 \\ \hline
\end{tabular}
\caption{Mean and standard deviation of residuals for three metric regression.}
\label{tab:ThreeResidual}
\end{center}
\end{table}

\subsubsection{All Metrics in Regression Analysis}

Finally, a linear regression was performed using all metrics.  We realize it is shown above that relative humidity and dew point depression provide redundant information, and column water is also a measure of humidity, but a multivariate linear regression with all five metrics was calculated in an attempt to utilize as much information as possible.  Because the data is six-dimensional, only the residuals can be plotted; this is shown in Figures \ref{fig:ssAllResidual}, \ref{fig:ltAllResidual}, \ref{fig:rocAllResidual}, \ref{fig:delmarAllResidual}, and \ref{fig:gaAllResidual} for each individual location.

% validation/regression_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ssAllResidual.png}
\caption{Residual vs. actual error for all metric regression at the Salton Sea.}
\label{fig:ssAllResidual}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/ltAllResidual.png}
\caption{Residual vs. actual error for all metric regression at Lake Tahoe.}
\label{fig:ltAllResidual}
\end{minipage}
\end{figure}

As with the other regressions, data at the Salton Sea and Lake Tahoe are well-behaved in our sample set and it is difficult to analyze because the actual error range and the residuals are small as shown in Figures \ref{fig:ssAllResidual} and \ref{fig:ltAllResidual}, so this tells us little about the abilities of the regression to predict error.

% validation/threshold_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/rocAllResidual.png}
\caption{Residual vs. actual error for all metric regression at Rochester.}
\label{fig:rocAllResidual}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/delmarAllResidual.png}
\caption{Residual vs. actual error for all metric regression at Delmar.}
\label{fig:delmarAllResidual}
\end{minipage}
\end{figure}

% validation/threshold_analysis.pro
\begin{figure}[H]
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/gaAllResidual.png}
\caption{Residual vs. actual error for all metric regression at Georgia.}
\label{fig:gaAllResidual}
\end{minipage}
\begin{minipage}[b]{0.47\textwidth}
\centering
\includegraphics[scale = 0.29]{results/AllResidual.png}
\caption{Residual vs. actual error for all metric regression at all locations.}
\label{fig:AllResidual}
\end{minipage}
\end{figure}

Residuals for Rochester, Delmar and Georgia in Figures \ref{fig:rocAllResidual}, \ref{fig:delmarAllResidual}, and \ref{fig:gaAllResidual} are, as expected, very similar to those for the three metric regression.  It does not appear that the two additional metrics have any added value.  There are anomalies and varying residuals throughout the range of actual errors, indicating that we cannot accurately predict error using this regression.

Finally, the residuals for the regression with all metrics at all locations is shown in Figure \ref{fig:AllResidual}.  This looks similar the three metric regression results shown in Figure \ref{fig:ThreeResidual}.  The means and standard deviations summarized in Table \ref{tab:AllResidual} are also similar to the three metric regression shown in Table \ref{tab:ThreeResidual}.  The all metric regression does not have more value added than the single or three metric regression.  Like the others, it is largely influenced but the large number of scenes between 1 K and 2 K and does not appear to give accurate error analysis at the smallest and largest errors.

\begin{table}[H]
\begin{center}
\begin{tabular}{| c | c | c |}
\hline
Location & Mean [K] & Standard Deviation [K] \\ \hline
Salton Sea & 0.477 & 0.501 \\ \hline
Lake Tahoe & 0.411 & 0.338 \\ \hline
Rochester & 1.501 & 1.474 \\ \hline
Delmar & 2.077 & 2.313 \\ \hline
Georgia & 2.133 & 2.412 \\ \hline
All Locations & 1.397 & 1.982 \\ \hline
\end{tabular}
\caption{Mean and standard deviation of residuals for all metric regression.}
\label{tab:AllResidual}
\end{center}
\end{table}

\subsubsection{Concluding Remarks on Regression Analysis}

Overall, regression for each metric or combination of metrics tends to yield similar results that indicate linear regression analysis is not a feasible method of confidence metric determination.  We are aware that there are a number of obvious problems with our initial approach to this analysis.  Perhaps most influential is the sample set we are using.  Regression analysis for each individual location is useful for initial analysis but would be extremely difficult to implement operationally.  This would require a set of truth data for each region to develop models for individual locations.  The results for regressions including all locations show an obvious bias toward groups of scenes with an average amount of error.  If the results were truly linear, this should not be the case.  The influence by the group of average scenes is discouraging for the use of a linear regression.  The selection of scenes for the regression data set would be extremely important.  Finally, even if such a dataset can be built, analysis of the actual error plotted as a function of each metric does not indicate that a linear model is best for the data.  Visual analysis does not lead to any obvious mathematical model for the data.  These initial regression analyses will prove useful in developing other methods of confidence estimation.

\subsection{Threshold Analysis}
\label{sec:threshold}

Section \ref{sec:metrics} discusses how we expect error to behave with each metric.  Further investigation into a number of individual scenes with a range of errors validates these expectations.  However, as shown in the plots in Section \ref{sec:regression}, these relationship are neither linear, nor do they follow another obvious mathematical model, nor are they absolute.  That is, while they can be true for most scenes, these factors are not absolute in influencing the errors in land surface temperature.  Because of this, we began investigating a qualitative method of error analysis.  Rather than attempting to predict the magnitude of error at any one pixel, we attempt to give a qualitative evaluation of the likelihood of accuracy in each.

Using the same metrics described in Section \ref{sec:metrics}, a threshold for each metric was determined.  Pixels are classified as high or low confidence based on the value of the metric for that pixel falling above or below the threshold.  For example, a threshold for transmission is determined.  Because we expect transmission to be inversely related to error, pixels with transmission above this threshold are given a high confidence, meaning that we are confident in our LST prediction for this pixel, while scenes with transmission below this threshold are classified as low confidence, meaning we are unsure of our ability to accurately retrieve the land surface temperature for this pixel.

Analogous to residuals in the regression analysis, we evaluate this method of error analysis by quantifying errors of omission and errors of commission.  We define an error of omission as a prediction of low confidence when the land surface temperature retrieval is sufficiently accurate and an error of commission as a prediction of high confidence when the land surface temperature is inaccurate.  Percentages of the errors of omission or commission are calculated as the ratio of points categorized improperly to the total number of points in the data set.  To gain an even better understanding we include the ratio of the number of points classified as errors of commission to the number of points assigned a high confidence.  This provides an estimate of the percentage of points which we claim high confidence but have errors greater than the standard.  We call this commission in high confidence only.  Errors of omission cause us to distrust data that has acceptable errors, which results in eliminating good data.  However, errors of commission would cause us to use and trust data that actually has large errors, which can cause considerably larger problems.  Although we will consider input from the user community about the desired magnitudes of error and confidence, as discussed in Section \ref{sec:thresholddetermination}, generally we wish to reduce errors of commission to minimize trusting data with poor results.  This is repeated for each individual metric at each individual location and all locations together.  Note that in regression analysis, including all locations in one analysis actually changed error predictions.  In threshold analysis, the results for all locations together is simply a combination of results from each individual location, so the calculated percentages of error, means, and standard deviations may change, but the actual error prediction for any individual scene will not.  The obvious flaw in this analysis is the definition of and dependence on a standard for sufficiently accurate land surface temperature retrieval and the sharp cutoff created by both the threshold and the standard.

As a first attempt, thresholds were chosen for each metric.  These were chosen mostly arbitrarily based only on our experience with and manual investigations of a few scenes of the data.  After a brief initial analysis, most of these threshold were found to be reasonable so an initial set of threshold analysis is presented below without further investigation into threshold determination.  As a first look at this method of confidence metric determination, standards of 1 K and 2 K are used to estimate the errors of omission and commission (errors less than 1 K and 2 K are deemed sufficiently accurate).  This needs to be further investigated in the community of users based on applications but is initially implying that users are willing to accept, and still use, 1 K or 2 K error in their LST product.

\subsubsection{Transmission in Threshold Analysis}

Figures \ref{fig:ssTauThres}, \ref{fig:ltTauThres}, \ref{fig:rocTauThres}, \ref{fig:delmarTauThres}, and \ref{fig:gaTauThres} show transmission plotted as a function of actual error for the Salton Sea, Lake Tahoe, Rochester, Delmar and Georgia respectively.  Note the error range for these plots is 0 K to 5 K in order to capture the detail at the lower errors; some scenes with larger errors are not shown.  Figure \ref{fig:TauThres} shows the error plotted against the transmission for all locations for an error range of 0 K to 10 K to capture a larger number of points; this conveniently also shows how many points were hidden in the previous plots.  Each plot also shows a line representing the initial transmission threshold of 0.8.  Points above this line are assigned a high confidence, as we expect higher transmission values to lead to more accurate land surface temperature retrieval.  Points below this line assigned a low confidence.  Also shown in the plots are vertical lines representing the 1 K and 2 K standards used to determine the percentage of points that are considered errors of omission and the percentage of points that are considered errors of commission.  ``Omission" and ``Commission" are labeled on the plots; points in this quadrant, above/below the threshold and left/right of the standard, are considered to be assigned inaccurate confidence metrics.  Points in the two opposing quadrants are considered to be assigned the correct confidence.  The corresponding tables, Tables \ref{tab:ssTauThres}, \ref{tab:ltTauThres}, \ref{tab:rocTauThres}, \ref{tab:delmarTauThres}, and \ref{tab:gaTauThres}, show the percentages of points that are considered errors of omission and commission for both the 1 K and 2 K standard, for the Salton Sea, Lake Tahoe, Rochester, Delmar and Georgia respectively.  These tables also show the mean and standard deviation of the errors of the points at each location classified as high confidence.  Note that these values consider points that are both correctly classified as high confidence and errors of commission.  This would provide us an initial estimate of the error on points that we assign a high confidence, and how sure we are of this error.  Finally, commission in high confidence is shown for both the 1 K and 2 K standard.

All points, regardless of the error range of the plots, are included in the calculations, unless classified as cloudy by the cloud detection described in Section \ref{sec:clouddetection}.  Cloudy scenes are not shown in the plots nor used in calculations.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/ssTauThres.png}
\caption{Plot of transmission vs. actual error for threshold analysis at the Salton Sea.}
\label{fig:ssTauThres}
\end{figure}
\end{minipage}
\hspace{0.0cm}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | } \hline
Errors of Omission for 1 K Standard &  21.43\% \\ \hline
Errors of Commission for 1 K Standard &  7.14\% \\ \hline
Errors of Omission for 2 K Standard & 21.43\% \\ \hline
Errors of Commission for 2 K Standard & 7.14\% \\ \hline
Mean Error of High Confidence &  0.719 K \\ \hline
Standard Deviation of High Confidence &  1.194 K \\ \hline
Commission in High Confidence for 1 K & 10.00\% \\ \hline
Commission in High Confidence for 2 K & 10.00\% \\ \hline
\end{tabular}
\caption{Statistics for transmission threshold analysis at the Salton Sea.}
\label{tab:ssTauThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/ltTauThres.png}
\caption{Plot of transmission vs. actual error for threshold analysis at Lake Tahoe.}
\label{fig:ltTauThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 1.43\% \\ \hline
Errors of Commission for 1 K Standard & 20.71\% \\ \hline
Errors of Omission for 2 K Standard & 2.14\% \\ \hline
Errors of Commission for 2 K Standard & 2.14\% \\ \hline
Mean Error of High Confidence & 0.705 K \\ \hline
Standard Deviation of High Confidence & 0.573 K \\ \hline
Commission in High Confidence for 1 K & 26.13\% \\ \hline
Commission in High Confidence for 2 K & 2.70\% \\ \hline
\end{tabular}
\caption{Statistics for transmission threshold analysis at Lake Tahoe.}
\label{tab:ltTauThres}
\end{table}
\end{minipage}

As with the regression analysis, results at the Salton Sea and Lake Tahoe are well-behaved as they were chosen on days good for land surface temperature retrieval.  The threshold analysis is more consistent than regression analysis with changing locations.  With these well-behaved datasets we investigate our ability to predict high confidence for good results.  The Salton Sea is particularly difficult to analyze due to the small sample size.  Just under 30\% of the data are assigned the incorrect confidence as shown in Table \ref{tab:ssTauThres} but this is a total of four points and Figure \ref{fig:ssTauThres} shows that the errors of omission are very close to the threshold.  The mean error is an acceptable magnitude but the standard deviation is quite large due to single error of commission with a  large error as shown in the plot.  At Lake Tahoe, most errors are due to commission so points with high transmission also had large errors.  However, with a standard of of 2 K, the percent of points as errors of commissions decreases considerably as shown in Table \ref{tab:ltTauThres}.  The mean error of high confidence is encouraging as is the standard deviation.  Considering the commission in high confidence, just over a quarter of the points that we claim have low errors actually have errors larger than acceptable at the 1 K.  This decreases considerably at the 2 K standard.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/rocTauThres.png}
\caption{Plot of transmission vs. actual error for threshold analysis at Rochester.}
\label{fig:rocTauThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 25.97\% \\ \hline
Errors of Commission for 1 K Standard & 11.69\% \\ \hline
Errors of Omission for 2 K Standard & 37.66\% \\ \hline
Errors of Commission for 2 K Standard & 5.19\% \\ \hline
Mean Error of High Confidence & 2.218 K \\ \hline
Standard Deviation of High Confidence & 3.091 K \\ \hline
Commission in High Confidence for 1 K & 50.00\% \\ \hline
Commission in High Confidence for 2 K & 22.22\% \\ \hline
\end{tabular}
\caption{Statistics for transmission threshold analysis at Rochester.}
\label{tab:rocTauThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/delmarTauThres.png}
\caption{Plot of transmission vs. actual error for threshold analysis at Delmar.}
\label{fig:delmarTauThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 17.59\% \\ \hline
Errors of Commission for 1 K Standard & 12.04\% \\ \hline
Errors of Omission for 2 K Standard & 34.26\% \\ \hline
Errors of Commission for 2 K Standard & 6.48\% \\ \hline
Mean Error of High Confidence & 2.512 K \\ \hline
Standard Deviation of High Confidence & 4.166 K \\ \hline
Commission in High Confidence for 1 K & 40.63\% \\ \hline
Commission in High Confidence for 2 K & 37.50\% \\ \hline
\end{tabular}
\caption{Statistics for transmission threshold analysis at Delmar.}
\label{tab:delmarTauThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/gaTauThres.png}
\caption{Plot of transmission vs. actual error for threshold analysis at Georgia.}
\label{fig:gaTauThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 23.73\% \\ \hline
Errors of Commission for 1 K Standard & 11.86\% \\ \hline
Errors of Omission for 2 K Standard & 40.68\% \\ \hline
Errors of Commission for 2 K Standard & 3.39\% \\ \hline
Mean Error of High Confidence & 0.953 K \\ \hline
Standard Deviation of High Confidence & 0.833 K \\ \hline
Commission in High Confidence for 1 K & 41.28\% \\ \hline
Commission in High Confidence for 2 K & 11.76\% \\ \hline
\end{tabular}
\caption{Statistics for transmission threshold analysis at Georgia.}
\label{tab:gaTauThres}
\end{table}
\end{minipage}

As expected, errors are less well-behaved at Rochester, Delmar and Georgia as shown in Figures \ref{fig:rocTauThres}, \ref{fig:delmarTauThres}, and \ref{fig:gaTauThres}.  There are more scenes with larger actual errors, but many fall below the 0.8 threshold line as expected.  However, there are many scenes with lower transmission that still have small actual errors, leading to higher errors of omission as shown in Tables \ref{tab:rocTauThres}, \ref{tab:delmarTauThres}, and \ref{tab:gaTauThres}.  At all three locations, with the 1 K standard, more than 30\% of the data is incorrectly assigned a low confidence, and more than 40\% at the 2 K standard.  At Rochester and Delmar, the mean error of the high confidence scenes is between 2 K and 3 K, but more concerning are the large standard deviations indicating that these scenes are not concentrated at this mean but also contains scenes with larger errors as supported by the plots on Figures \ref{fig:rocTauThres}, \ref{fig:delmarTauThres}, and \ref{fig:gaTauThres}.  The commission in high confidence is large for both of these locations as well, although decreases at the 2 K standard.  The mean and standard deviation at Georgia is more encouraging but this site still has a high percentage of errors of omission; the commission in high confidence at the 2 K standard is lower at Georgia than at Rochester or Delmar.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/TauThres.png}
\caption{Plot of transmission vs. actual error for threshold analysis at all locations.}
\label{fig:TauThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 14.57\% \\ \hline
Errors of Commission for 1 K Standard & 14.82\% \\ \hline
Errors of Omission for 2 K Standard & 24.12\% \\ \hline
Errors of Commission for 2 K Standard & 4.27\% \\ \hline
Mean Error of High Confidence & 1.181 K \\ \hline
Standard Deviation of High Confidence & 2.150 K \\ \hline
Commission in High Confidence for 1 K & 31.38\% \\ \hline
Commission in High Confidence for 2 K & 9.04\% \\ \hline
\end{tabular}
\caption{Statistics for transmission threshold analysis at all locations.}
\label{tab:TauThres}
\end{table}
\end{minipage}

Consdering all locations, close to 30\% of the data points are incorrectly classified.  However, the mean of the high confidence scenes  from Table \ref{tab:TauThres} is 1.181 K with a standard devotion of 2.150 K.  This is an encouraging result although possibly unfairly skewed by Lake Tahoe scenes and the percent of errors of omission is still high.  The commission in high confidence at the 2 K standard is below 10\% which is encouraging.

From a visual analysis of Figures \ref{fig:ssTauThres}, \ref{fig:ltTauThres}, \ref{fig:rocTauThres}, \ref{fig:delmarTauThres}, \ref{fig:gaTauThres}, and \ref{fig:TauThres}, it does not appear a major adjustment to the initial transmission threshold would significantly improve results.  At most locations, disregarding results at the Salton Sea and Lake Tahoe, there are large actual errors throughout the range of transmissions indicating that adjusting the transmission threshold would cause either the omission or commission errors to increase.  As discussed above, the relationship of higher error with lower transmission is neither linear nor absolute.

\subsubsection{Relative Humidity in Threshold Analysis}

Relative humidity is plotted as a function of error for each validation site in Figures \ref{fig:ssRHThres}, \ref{fig:ltRHThres}, \ref{fig:rocRHThres}, \ref{fig:delmarRHThres} and \ref{fig:gaRHThres} for an error range of 0 K to 5 K.  The initial relative humidity threshold of 70\% is shown on the plots along with the 1 K and 2 K standards.  Tables quantifying the errors of omission and commission as well as the mean and standard deviation of high confidence pixels are shown for corresponding locations in Tables \ref{tab:ssRHThres}, \ref{tab:ltRHThres}, \ref{tab:rocRHThres}, \ref{tab:delmarRHThres}, and \ref{tab:gaRHThres}.  The same is shown for all locations over a larger range of errors in Figure \ref{fig:RHThres} with the corresponding calculations in Table \ref{tab:RHThres}.  

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/ssRHThres.png}
\caption{Plot of relative humidity vs. actual error for threshold analysis at the Salton Sea.}
\label{fig:ssRHThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 7.14\% \\ \hline
Errors of Commission for 1 K Standard & 7.14\% \\ \hline
Errors of Omission for 2 K Standard & 7.14\% \\ \hline
Errors of Commission for 2 K Standard & 7.14\% \\ \hline
Mean Error of High Confidence & 0.527 K \\ \hline
Standard Deviation of High Confidence & 0.584 K \\ \hline
Commission in High Confidence for 1 K & 8.33\% \\ \hline
Commission in High Confidence for 2 K & 8.33\% \\ \hline
\end{tabular}
\caption{Statistics for relative humidity threshold analysis at the Salton Sea.}
\label{tab:ssRHThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/ltRHThres.png}
\caption{Plot of relative humidity vs. actual error for threshold analysis at Lake Tahoe.}
\label{fig:ltRHThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 11.43\% \\ \hline
Errors of Commission for 1 K Standard & 15.71\% \\ \hline
Errors of Omission for 2 K Standard & 16.43\% \\ \hline
Errors of Commission for 2 K Standard & 1.43\% \\ \hline
Mean Error of High Confidence & 0.676 K \\ \hline
Standard Deviation of High Confidence & 0.545 K \\ \hline
Commission in High Confidence for 1 K & 24.44\% \\ \hline
Commission in High Confidence for 2 K & 2.22\% \\ \hline
\end{tabular}
\caption{Statistics for relative humidity threshold analysis at Lake Tahoe.}
\label{tab:ltRHThres}
\end{table}
\end{minipage}

Only one scene is assigned an incorrect high confidence and an incorrect low confidence at the Salton Sea, as shown in Figure \ref{fig:ssRHThres}, and both the mean and standard deviation of high confidence scenes is low, as shown in Table \ref{tab:ssRHThres}.  For Lake Tahoe, the percentage of scenes given incorrect confidences significantly decreases for the 2 K standard due to the decrease in errors of commission as can be observed in Figure \ref{fig:ltRHThres}.  There are still a handful of scenes with high relative humidities and accurate land surface temperature retrieval, but the mean and standard deviation of high confidence scenes is encouraging as shown in Table \ref{tab:ltRHThres}.  The commission in high confidence at the 2 K standard for both scenes is also encouraging.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/rocRHThres.png}
\caption{Plot of relative humidity vs. actual error for threshold analysis at Rochester.}
\label{fig:rocRHThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 33.77\% \\ \hline
Errors of Commission for 1 K Standard & 5.19\% \\ \hline
Errors of Omission for 2 K Standard & 48.05\% \\ \hline
Errors of Commission for 2 K Standard & 1.30\% \\ \hline
Mean Error of High Confidence & 1.931 K \\ \hline
Standard Deviation of High Confidence & 2.992 K \\ \hline
Commission in High Confidence for 1 K & 57.14\% \\ \hline
Commission in High Confidence for 2 K & 14.29\% \\ \hline
\end{tabular}
\caption{Statistics for relative humidity threshold analysis at Rochester.}
\label{tab:rocRHThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/delmarRHThres.png}
\caption{Plot of relative humidity vs. actual error for threshold analysis at Delmar.}
\label{fig:delmarRHThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 26.85\% \\ \hline
Errors of Commission for 1 K Standard & 6.48\% \\ \hline
Errors of Omission for 2 K Standard & 48.15\% \\ \hline
Errors of Commission for 2 K Standard & 5.56\% \\ \hline
Mean Error of High Confidence & 2.776 K \\ \hline
Standard Deviation of High Confidence & 3.779 K \\ \hline
Commission in High Confidence for 1 K & 43.75\% \\ \hline
Commission in High Confidence for 2 K & 37.50\% \\ \hline
\end{tabular}
\caption{Statistics for relative humidity threshold analysis at Delmar.}
\label{tab:delmarRHThres}
\end{table}
\end{minipage}

For both Rochester and Delmar, errors of omission are considerably higher than errors of commission; a very large portion of the data would be classified as low confidence due to the large number of scenes with high relative humidities, as shown in Figures \ref{fig:rocRHThres} and \ref{fig:delmarRHThres}.  This will be a problem in areas with generally humid conditions.  Because few scenes would be classified as high confidence, there are only a handful of errors of commission to influence the high confidence mean and standard deviation, as shown in Tables \ref{tab:rocRHThres} and \ref{tab:delmarRHThres}.  However, particularly at Delmar, there are a number of high confidence scenes with errors large enough to make the mean and standard deviation greater than is desirable.  Georgia has similar results as shown in Figure \ref{fig:gaRHThres}, but there are fewer scenes with low relative humidities and large errors, such that the results are improved at the 2 K standard, shown in Table \ref{tab:gaRHThres}, and the mean and standard deviations are smaller than those for Rochester and Delmar.  The commission in high confidence at the 2 K standard is lowest in Rochester but larger than is desirable at all three locations.  So few scenes are assigned a high confidence in this case that a small number of errors can make this percentage of commission in high confidence large.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/gaRHThres.png}
\caption{Plot of relative humidity vs. actual error for threshold analysis at Georgia.}
\label{fig:gaRHThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 33.90\% \\ \hline
Errors of Commission for 1 K Standard & 8.47\% \\ \hline
Errors of Omission for 2 K Standard & 5.42\% \\ \hline
Errors of Commission for 2 K Standard & 3.39\% \\ \hline
Mean Error of High Confidence & 1.282 K \\ \hline
Standard Deviation of High Confidence & 1.023 K \\ \hline
Commission in High Confidence for 1 K & 55.56\% \\ \hline
Commission in High Confidence for 2 K & 22.22\% \\ \hline
\end{tabular}
\caption{Statistics for relative humidity threshold analysis at Georgia.}
\label{tab:gaRHThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/RHThres.png}
\caption{Plot of relative humidity vs. actual error for threshold analysis at all locations.}
\label{fig:RHThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 23.12\% \\ \hline
Errors of Commission for 1 K Standard & 9.80\% \\ \hline
Errors of Omission for 2 K Standard & 36.43\% \\ \hline
Errors of Commission for 2 K Standard & 3.02\% \\ \hline
Mean Error of High Confidence & 1.282 K \\ \hline
Standard Deviation of High Confidence & 1.023 K \\ \hline
Commission in High Confidence for 1 K & 29.10\% \\ \hline
Commission in High Confidence for 2 K & 8.86\% \\ \hline
\end{tabular}
\caption{Statistics for relative humidity threshold analysis at all locations.}
\label{tab:RHThres}
\end{table}
\end{minipage}

Considering the results for all scenes shown in Figure \ref{fig:RHThres} and Table \ref{tab:RHThres}, there are a large number of errors of omission due to the abundance of scenes with high relative humidities but low errors.  However, there are few scenes with large error and low relative humidity, such that the errors of commission are low, the mean and standard deviation of high confidence scenes is acceptable, and the commission in high confidence at the 2 K standard is less than ten percent.  This is greatly influenced by the number of Lake Tahoe scenes with low error and relative humidity.  Because there are a large number of scenes with low error, increasing the relative humidity threshold would decrease the errors of omission; however, considering only scenes with larger than desired errors, the relative humidity threshold at 70\% seems to be well matched to correctly predicting their low confidence.

\subsubsection{Maximum Temperature in Threshold Analysis}

Plots for maximum temperature as a function of error are shown in Figures \ref{fig:ssTThres}, \ref{fig:ltTThres}, \ref{fig:rocTThres}, \ref{fig:delmarTThres}, and \ref{fig:gaTThres} for the Salton Sea, Lake Tahoe, Rochester, Delmar and Georgia respectively.  Tables \ref{fig:ssTThres}, \ref{fig:ltTThres}, \ref{fig:rocTThres}, \ref{fig:delmarTThres}, and \ref{fig:gaTThres} show the values derived from these figures.  Each plot also includes the threshold line, at 305 K for the maximum temperature and vertical lines for the 1 K and 2 K standards.  Figure \ref{fig:TThres} shows this same data for all locations over a larger error range with the corresponding data in Table \ref{tab:TThres}.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/ssTThres.png}
\caption{Plot of maximum temperature vs. actual error for threshold analysis at the Salton Sea.}
\label{fig:ssTThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 21.43\% \\ \hline
Errors of Commission for 1 K Standard & 7.14\% \\ \hline
Errors of Omission for 2 K Standard & 21.43\% \\ \hline
Errors of Commission for 2 K Standard & 7.14\% \\ \hline
Mean Error of High Confidence & 0.711 K \\ \hline
Standard Deviation of High Confidence & 1.199 K \\ \hline
Commission in High Confidence for 1 K & 10.00\% \\ \hline
Commission in High Confidence for 2 K & 10.00\% \\ \hline
\end{tabular}
\caption{Statistics for maximum temperature threshold analysis at the Salton Sea.}
\label{tab:ssTThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/ltTThres.png}
\caption{Plot of maximum temperature vs. actual error for threshold analysis at Lake Tahoe.}
\label{fig:ltTThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 11.43\% \\ \hline
Errors of Commission for 1 K Standard & 20.00\% \\ \hline
Errors of Omission for 2 K Standard & 12.86\% \\ \hline
Errors of Commission for 2 K Standard & 2.14\% \\ \hline
Mean Error of High Confidence & 0.755 K \\ \hline
Standard Deviation of High Confidence & 0.585 K \\ \hline
Commission in High Confidence for 1 K & 29.17\% \\ \hline
Commission in High Confidence for 2 K & 3.13\% \\ \hline
\end{tabular}
\caption{Statistics for maximum temperature threshold analysis at Lake Tahoe.}
\label{tab:ltTThres}
\end{table}
\end{minipage}

Because the data at the Salton Sea and Lake Tahoe have a relatively small range of errors, the mean and standard deviation of the high confidence results are small in Tables \ref{tab:ssTThres} and \ref{tab:ltTThres}.  The commission in high confidence for both, particularly at the 2 K standard, are also low.  However, there are a number of results with low errors that have high maximum temperatures, leading to errors of omission as shown in Figures \ref{fig:ssTThres} and \ref{fig:ltTThres}.  Climates are obviously variable with location and this is our first indication that the same threshold may not be optimal for all sites.  Increasing the threshold would eliminate these errors of omission, but would result in all points falling below the threshold, or high confidence in all points.  Therefore, a more diverse data set is needed to evaluate the utility of this metric in this capacity.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/rocTThres.png}
\caption{Plot of maximum temperature vs. actual error for threshold analysis at Rochester.}
\label{fig:rocTThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 0.00\% \\ \hline
Errors of Commission for 1 K Standard & 36.36\% \\ \hline
Errors of Omission for 2 K Standard & 0.00\% \\ \hline
Errors of Commission for 2 K Standard & 18.18\% \\ \hline
Mean Error of High Confidence & 1.907 K \\ \hline
Standard Deviation of High Confidence & 2.395 K \\ \hline
Commission in High Confidence for 1 K & 49.12\% \\ \hline
Commission in High Confidence for 2 K & 24.56\% \\ \hline
\end{tabular}
\caption{Statistics for maximum temperature threshold analysis at Rochester.}
\label{tab:rocTThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/delmarTThres.png}
\caption{Plot of maximum temperature vs. actual error for threshold analysis at Delmar.}
\label{fig:delmarTThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 0.00\% \\ \hline
Errors of Commission for 1 K Standard & 50.00\% \\ \hline
Errors of Omission for 2 K Standard & 0.00\% \\ \hline
Errors of Commission for 2 K Standard & 27.78\% \\ \hline
Mean Error of High Confidence & 2.449 K \\ \hline
Standard Deviation of High Confidence & 3.164 K \\ \hline
Commission in High Confidence for 1 K & 58.70\% \\ \hline
Commission in High Confidence for 2 K & 32.61\% \\ \hline
\end{tabular}
\caption{Statistics for maximum temperature threshold analysis at Delmar.}
\label{tab:delmarTThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/gaTThres.png}
\caption{Plot of maximum temperature vs. actual error for threshold analysis at Georgia.}
\label{fig:gaTThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 0.00\% \\ \hline
Errors of Commission for 1 K Standard & 52.54\% \\ \hline
Errors of Omission for 2 K Standard & 0.00\% \\ \hline
Errors of Commission for 2 K Standard & 27.12\% \\ \hline
Mean Error of High Confidence & 2.379 K \\ \hline
Standard Deviation of High Confidence & 3.485 K \\ \hline
Commission in High Confidence for 1 K & 56.36\% \\ \hline
Commission in High Confidence for 2 K & 29.09\% \\ \hline
\end{tabular}
\caption{Statistics for maximum temperature threshold analysis at Georgia.}
\label{tab:gaTThres}
\end{table}
\end{minipage}

At Rochester, Delmar and Georgia, in Figures \ref{fig:rocTThres}, \ref{fig:delmarTThres}, and \ref{fig:gaTThres}, all points are below the threshold, resulting in high means and standard deviations for the high confidence points and no errors of omission in Tables \ref{tab:rocTThres}, \ref{tab:delmarTThres}, and \ref{tab:gaTThres}.  This would be assigning high confidence to every point and indicates that the threshold needs to be adjusted, which is also supported by the Salton Sea and Lake Tahoe results and the larger percentage of commission in high confidence.  However, considering the data visually, lowering the threshold to decrease the errors of commission would also result in errors of omission for all locations.  Scenes with the largest maximum temperatures have a large spread of errors.  There is a general trend of only low errors for the lowest maximum temperatures, but a large error range for all other maximum temperatures.  This is the first indication that this metric may not be helpful in the threshold analysis.  Results are the same when all locations are plotted together.  While there are few points with maximum temperatures above the threshold, any decrease in the threshold would greatly increase the errors of omission in Figure \ref{fig:TThres} and Table \ref{tab:TThres}.  Also, the range of maximum temperatures is very different at each site.  This may indicate that rather than behaving as expected, with error increasing with maximum temperature, we can only infer low errors from the lowest maximum temperatures but very little from any maximum temperature values.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/TThres.png}
\caption{Plot of maximum temperature vs. actual error for threshold analysis at all locations.}
\label{fig:TThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 4.77\% \\ \hline
Errors of Commission for 1 K Standard & 36.68\% \\ \hline
Errors of Omission for 2 K Standard & 5.28\% \\ \hline
Errors of Commission for 2 K Standard & 16.08\% \\ \hline
Mean Error of High Confidence & 1.756 K \\ \hline
Standard Deviation of High Confidence & 2.612 K \\ \hline
Commission in High Confidence for 1 K & 45.81\% \\ \hline
Commission in High Confidence for 2 K & 20.65\% \\ \hline
\end{tabular}
\caption{Statistics for maximum temperature threshold analysis at all locations.}
\label{tab:TThres}
\end{table}
\end{minipage}

\subsubsection{Dew Point Depression in Threshold Analysis}

Dew point depression is plotted as a function of error in Figures \ref{fig:ssDiffThres}, \ref{fig:ltDiffThres}, \ref{fig:rocDiffThres}, \ref{fig:delmarDiffThres}, and \ref{fig:gaDiffThres} for the Salton Sea, Lake Tahoe, Rocehster, Delmar, and Georgia respectively with related data in Tables \ref{tab:ssDiffThres}, \ref{tab:ltDiffThres}, \ref{tab:rocDiffThres}, \ref{tab:delmarDiffThres} and \ref{tab:gaDiffThres}.  Each plot shows the original dew point depression threshold at 3.0 K and lines for both the 1 K and 2 K standards.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/ssDiffThres.png}
\caption{Plot of dew point depression vs. actual error for threshold analysis at the Salton Sea.}
\label{fig:ssDiffThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 0.00\% \\ \hline
Errors of Commission for 1 K Standard & 7.14\% \\ \hline
Errors of Omission for 2 K Standard & 0.00\% \\ \hline
Errors of Commission for 2 K Standard & 7.14\% \\ \hline
Mean Error of High Confidence & 0.487 K \\ \hline
Standard Deviation of High Confidence & 0.577 K \\ \hline
Commission in High Confidence for 1 K & 7.69\% \\ \hline
Commission in High Confidence for 2 K & 7.69\% \\ \hline
\end{tabular}
\caption{Statistics for dew point depression threshold analysis at the Salton Sea.}
\label{tab:ssDiffThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/ltDiffThres.png}
\caption{Plot of dew point depression vs. actual error for threshold analysis at Lake Tahoe.}
\label{fig:ltDiffThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 5.71\% \\ \hline
Errors of Commission for 1 K Standard & 18.57\% \\ \hline
Errors of Omission for 2 K Standard & 7.86\% \\ \hline
Errors of Commission for 2 K Standard & 1.43\% \\ \hline
Mean Error of High Confidence & 0.689 K \\ \hline
Standard Deviation of High Confidence & 0.546 K \\ \hline
Commission in High Confidence for 1 K & 25.49\% \\ \hline
Commission in High Confidence for 2 K & 1.86\% \\ \hline
\end{tabular}
\caption{Statistics for dew point depression threshold analysis at Lake Tahoe.}
\label{tab:ltDiffThres}
\end{table}
\end{minipage}

For the Salton Sea, there is no error of omission because all dew point depressions are larger than the threshold as shown in Figure \ref{fig:ssDiffThres}.  The mean and standard deviation in Table \ref{tab:ssDiffThres} are small by the nature of the actual errors at this site but the commission in high confidence is also low, particularly at the 2 K standard.  However, increasing the threshold would increase the error of omission without decreasing error of commission.  The sample is too small and the data too well-behaved to make any useful evaluations or conclusions.  Lake Tahoe provides a little more variability in dew point depression but still a small range of errors.  Especially at the 2 K standard, as shown in Figures \ref{fig:ltDiffThres} and Table \ref{tab:ltDiffThres}, there are low errors of omission and commission and a large number of results successfully classified.  The commission in high confidence is particularly low at the 2 K standard.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/rocDiffThres.png}
\caption{Plot of dew point depression vs. actual error for threshold analysis at Rochester.}
\label{fig:rocDiffThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 12.99\% \\ \hline
Errors of Commission for 1 K Standard & 14.29\% \\ \hline
Errors of Omission for 2 K Standard & 23.38\% \\ \hline
Errors of Commission for 2 K Standard & 6.49\% \\ \hline
Mean Error of High Confidence & 1.587 K \\ \hline
Standard Deviation of High Confidence & 2.339 K \\ \hline
Commission in High Confidence for 1 K & 36.67\% \\ \hline
Commission in High Confidence for 2 K & 16.67\% \\ \hline
\end{tabular}
\caption{Statistics for dew point depression threshold analysis at Rochester.}
\label{tab:rocDiffThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/delmarDiffThres.png}
\caption{Plot of dew point depression vs. actual error for threshold analysis at Delmar.}
\label{fig:delmarDiffThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 9.26\% \\ \hline
Errors of Commission for 1 K Standard & 27.78\% \\ \hline
Errors of Omission for 2 K Standard & 18.52\% \\ \hline
Errors of Commission for 2 K Standard & 14.81\% \\ \hline
Mean Error of High Confidence & 2.127 K \\ \hline
Standard Deviation of High Confidence & 3.198 K \\ \hline
Commission in High Confidence for 1 K & 51.72\% \\ \hline
Commission in High Confidence for 2 K & 27.59\% \\ \hline
\end{tabular}
\caption{Statistics for dew point depression threshold analysis at Delmar.}
\label{tab:delmarDiffThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/gaDiffThres.png}
\caption{Plot of dew point depression vs. actual error for threshold analysis at Georgia.}
\label{fig:gaDiffThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 20.34\% \\ \hline
Errors of Commission for 1 K Standard & 28.81\% \\ \hline
Errors of Omission for 2 K Standard & 32.20\% \\ \hline
Errors of Commission for 2 K Standard & 15.25\% \\ \hline
Mean Error of High Confidence & 2.066 K \\ \hline
Standard Deviation of High Confidence & 2.764 K \\ \hline
Commission in High Confidence for 1 K & 58.62\% \\ \hline
Commission in High Confidence for 2 K & 31.03\% \\ \hline
\end{tabular}
\caption{Statistics for dew point depression threshold analysis at Georgia.}
\label{tab:gaDiffThres}
\end{table}
\end{minipage}

Rochester, Delmar and Georgia have more variable results in Figures \ref{fig:rocDiffThres}, \ref{fig:delmarDiffThres} and \ref{fig:gaDiffThres}.  Results for Rochester in Figure \ref{fig:rocDiffThres} are well matched to the threshold and look as expected.  There are a handful of errors of omission, but generally points with large errors have small dew points depressions and are correctly given low confidence.  The mean error and standard deviation is still larger than desired for high confidence results as is the percent of commission in high confidence.  Although slightly lower for Rochester, the commission in high confidence is too large at all three sites.  Points for Delmar and Georgia look less well-match to the threshold and more like results for maximum temperature; both the means and standard deviations are large as shown in Tables \ref{tab:delmarDiffThres} and \ref{tab:gaDiffThres}, but adjusting the threshold does not appear to improve results.  There are a variety of errors throughout the range of dew point depressions.  Finally, results for all locations are shown in Figure \ref{fig:DiffThres}.  With the 2 K standard, around 25\% of the data is classified incorrectly; the error and standard deviation of the high confidence results is larger than desired, as is the commission in high confidence, but adjusting the threshold does not appear to improve results.  Most points with a small dew point depression and large errors are correctly given low confidence; increasing the threshold would increase the error of omission and there are already a large percentage of errors of omission due to the points with small dew point depressions and small actual errors.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/DiffThres.png}
\caption{Plot of dew point depression vs. actual error for threshold analysis at all locations.}
\label{fig:DiffThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 10.05\% \\ \hline
Errors of Commission for 1 K Standard & 21.36\% \\ \hline
Errors of Omission for 2 K Standard & 17.09\% \\ \hline
Errors of Commission for 2 K Standard & 8.29\% \\ \hline
Mean Error of High Confidence & 1.325 K \\ \hline
Standard Deviation of High Confidence & 2.178 K \\ \hline
Commission in High Confidence for 1 K & 36.64\% \\ \hline
Commission in High Confidence for 2 K & 14.22\% \\ \hline
\end{tabular}
\caption{Statistics for dew point depression threshold analysis at all locations.}
\label{tab:DiffThres}
\end{table}
\end{minipage}

\subsubsection{Column Water Vapor in Threshold Analysis}

Salton Sea, Lake Tahoe, Rochester, Delmar and Georgia column water vapor results are shown in Figures \ref{fig:ssCWVThres}, \ref{fig:ltCWVThres}, \ref{fig:rocCWVThres}, \ref{fig:delmarCWVThres}, and \ref{fig:gaCWVThres} with corresponding Tables \ref{tab:ssCWVThres}, \ref{tab:ltCWVThres}, \ref{tab:rocCWVThres}, \ref{tab:delmarCWVThres}, and \ref{tab:gaCWVThres}.  The initial column water vapor threshold is set at 2 cm; the 1 K and 2 K standards are also shown on the plots.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/ssCWVThres.png}
\caption{Plot of column water vapor vs. actual error for threshold analysis at the Salton Sea.}
\label{fig:ssCWVThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 7.14\% \\ \hline
Errors of Commission for 1 K Standard & 7.14\% \\ \hline
Errors of Omission for 2 K Standard & 7.14\% \\ \hline
Errors of Commission for 2 K Standard & 7.14\% \\ \hline
Mean Error of High Confidence & 0.626 K \\ \hline
Standard Deviation of High Confidence & 1.104 K \\ \hline
Commission in High Confidence for 1 K & 8.33\% \\ \hline
Commission in High Confidence for 2 K & 8.33\% \\ \hline
\end{tabular}
\caption{Statistics for column water vapor threshold analysis at the Salton Sea.}
\label{tab:ssCWVThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/ltCWVThres.png}
\caption{Plot of column water vapor vs. actual error for threshold analysis at Lake Tahoe.}
\label{fig:ltCWVThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 25.00\% \\ \hline
Errors of Commission for 1 K Standard & 17.14\% \\ \hline
Errors of Omission for 2 K Standard & 29.29\% \\ \hline
Errors of Commission for 2 K Standard & 2.14\% \\ \hline
Mean Error of High Confidence & 0.786 K \\ \hline
Standard Deviation of High Confidence & 0.601 K \\ \hline
Commission in High Confidence for 1 K & 32.88\% \\ \hline
Commission in High Confidence for 2 K & 4.11\% \\ \hline
\end{tabular}
\caption{Statistics for column water vapor threshold analysis at Lake Tahoe.}
\label{tab:ltCWVThres}
\end{table}
\end{minipage}

Illustrated in Figure \ref{fig:ssCWVThres}, the errors at the Salton Sea are too small to make a judgement on the column water vapor threshold.  Almost all points are correctly given high confidence.  Only one point has a larger than average column water vapor, correctly assigned a low confidence, and one point has a large error and low column water vapor, incorrectly assigned a high confidence.  Lake Tahoe results provide a larger range of column water vapor values for a dataset with mostly small errors.  Over 40\% of the data is given incorrect confidence with the 1 K standard, and over 30\% with the 2 K standard.  The means for both Salton Sea and Lake Tahoe are small in Tables \ref{tab:ssCWVThres} and \ref{tab:ltCWVThres} respectively, due to the nature of the actual errors on these datasets; the standard deviation is larger than desired for Salton Sea but acceptably small for Lake Tahoe.  The commission in high confidence is relatively low at the 2 K standard for both sites.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/rocCWVThres.png}
\caption{Plot of column water vapor vs. actual error for threshold analysis at Rochester.}
\label{fig:rocCWVThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 20.78\% \\ \hline
Errors of Commission for 1 K Standard & 15.58\% \\ \hline
Errors of Omission for 2 K Standard & 29.87\% \\ \hline
Errors of Commission for 2 K Standard & 6.49\% \\ \hline
Mean Error of High Confidence & 1.837 K \\ \hline
Standard Deviation of High Confidence & 2.583 K \\ \hline
Commission in High Confidence for 1 K & 48.00\% \\ \hline
Commission in High Confidence for 2 K & 20.00\% \\ \hline
\end{tabular}
\caption{Statistics for column water vapor threshold analysis at Rochester.}
\label{tab:rocCWVThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/delmarCWVThres.png}
\caption{Plot of column water vapor vs. actual error for threshold analysis at Delmar.}
\label{fig:delmarCWVThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 12.04\% \\ \hline
Errors of Commission for 1 K Standard & 19.44\% \\ \hline
Errors of Omission for 2 K Standard & 24.07\% \\ \hline
Errors of Commission for 2 K Standard & 9.26\% \\ \hline
Mean Error of High Confidence & 2.561 K \\ \hline
Standard Deviation of High Confidence & 4.046 K \\ \hline
Commission in High Confidence for 1 K & 45.65\% \\ \hline
Commission in High Confidence for 2 K & 21.74\% \\ \hline
\end{tabular}
\caption{Statistics for column water vapor threshold analysis at Delmar.}
\label{tab:delmarCWVThres}
\end{table}
\end{minipage}

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.47\textwidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/gaCWVThres.png}
\caption{Plot of column water vapor vs. actual error for threshold analysis at Georgia.}
\label{fig:gaCWVThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.47\textwidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 13.56\% \\ \hline
Errors of Commission for 1 K Standard & 13.56\% \\ \hline
Errors of Omission for 2 K Standard & 28.81\% \\ \hline
Errors of Commission for 2 K Standard & 3.39\% \\ \hline
Mean Error of High Confidence & 0.919 K \\ \hline
Standard Deviation of High Confidence & 0.752 K \\ \hline
Commission in High Confidence for 1 K & 33.33\% \\ \hline
Commission in High Confidence for 2 K & 8.33\% \\ \hline
\end{tabular}
\caption{Statistics for column water vapor threshold analysis at Georgia.}
\label{tab:gaCWVThres}
\end{table}
\end{minipage}

Results for Rochester, Delmar and Georgia all have a large percentage of the data incorrectly classified, roughly 25\% to 35\% for both standards in all cases as described in Tables \ref{tab:rocCWVThres}, \ref{tab:delmarCWVThres} and \ref{tab:gaCWVThres}.  However, the results with column water do appear to follow the trend of larger column water vapor and larger errors.  There are still results with small errors and large column water vapors, but fewer results with large errors and small column water vapors.  Unlike maximum temperature and dew point depression in particular, which have little distinct shape in their results and a large range of errors within a small range of the metrics, there is shape to the column water vapor data.  In these three locations, after visually analyzing Figures \ref{fig:rocCWVThres}, \ref{fig:delmarCWVThres}, and \ref{fig:gaCWVThres}, it appears that a slight increase in the threshold could decrease the error of omission without significantly increasing the error of commission or the means and standard deviation of the high confidence results.  Particularly at Delmar, but also Rochester, the mean and standard deviation of the high confidence results is still higher than other locations and higher than desirable.  The commission in high confidence is below ten percent for the 2 K standard at Georgia, but still quite large at both Rochester and Delmar.

% validation/threshold_analysis.pro
\begin{minipage}[c]{0.5\linewidth}
\centering
\begin{figure}[H]
\includegraphics[scale = 0.28]{results/CWVThres.png}
\caption{Plot of column water vapor vs. actual error for threshold analysis at all locations.}
\label{fig:CWVThres}
\end{figure}
\end{minipage}
\begin{minipage}[c]{0.5\linewidth}
\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{ | c | c | c | } \hline
Errors of Omission for 1 K Standard & 18.34\% \\ \hline
Errors of Commission for 1 K Standard & 16.58\% \\ \hline
Errors of Omission for 2 K Standard & 27.14\% \\ \hline
Errors of Commission for 2 K Standard & 5.28\% \\ \hline
Mean Error of High Confidence & 1.393 K \\ \hline
Standard Deviation of High Confidence & 2.429 K \\ \hline
Commission in High Confidence for 1 K & 36.67\% \\ \hline
Commission in High Confidence for 2 K & 11.67\% \\ \hline
\end{tabular}
\caption{Statistics for column water vapor threshold analysis at all locations.}
\label{tab:CWVThres}
\end{table}
\end{minipage}

Considering all locations together, there is a still a large percentage of the data incorrectly classified as shown in Table \ref{tab:CWVThres}.  However, the data appears to have more shape than other metrics which is encouraging for future analysis.  Although the threshold seems to be initially well predicted in Figure \ref{fig:CWVThres}, it appears that increasing the threshold slightly could significantly decrease the error of omission while only slightly increasing errors of commission.  However, as discussed, it is likely we want to keep the errors of commission as small as possible.  Currently the commission in high confidence for the 2 K standard is just above ten percent for all locations.  The mean and standard deviations are reasonable in magnitude for this metric.

\subsubsection{Concluding Remarks on Threshold Analysis}

At an initial glance, it does not appear that the threshold analysis provides a better method of error estimation than regression analysis.  However, we would argue that there is more promising potential for improvement and adjustment to this method that would allow us to build a better method of error prediction.  Most troubling is still the sample set we are using.  While we are considering a reasonable number of scenes (398 in total), this is considerably smaller after removing clouds and strongly influenced by the large number of scenes at Lake Tahoe, which were selected for days of good land surface temperature retrieval.  This skews results, particularly means, standard deviations, and placement of thresholds when considering all locations together.  In most cases, there is still a large percentage of points assigned incorrect confidence.  However, metrics such as transmission, dew point depression and column water vapor provide a data set with an observable shape, unlike maximum temperature and relative humidity which appear to have a range of errors within a small range of the metric.  Another advantage of the threshold analysis is that although truth data is necessary to determine the thresholds, a truth data set is not directly necessary when operationally predicting error.  We believe, as discussed below in Section \ref{sec:confidenceimprovements}, that adjustments and improvements to this threshold analysis can lead to a feasible method of error analysis.

\section{Concluding Remarks}

The goal of this chapter was to present our initial findings from the first set of scenes processed with our automated process.  Evaluation of our findings requires comparison to some form of accepted truth so we begin by describing the sites we used for comparison and how we obtained our ground truth data in Section \ref{sec:groundtruthsites}.  We present our initial error in Section \ref{sec:initialerror} by analyzing the differences between our predicted LST and the ground truth LST of water for a number of scenes at each of our test sites.  Finally we present two methods of confidence metric estimation in Section \ref{sec:confidencemetrics}, one qualitative and one quantitative.  Although neither has particularly successful performance in terms of a final solution, we find our qualitative threshold analysis has more potential for improvement.

This leads us to our final chapter; our initial analysis of results and investigation of confidence metric determination allow us to better define our future work in Chapter \ref{ch:futurework}.  We will discuss how to improve our method of error analysis, extending our process to have the ability to create a global product, and any adjustments or improvements we can make.

\chapter{Future Work}
\label{ch:futurework}

This chapter aims to present the steps necessary to complete this work.  We have mentioned throughout areas that we would deal with or consider later and they should be addressed in this chapter.  We begin in Section \ref{sec:confidenceimprovements} by proposing steps to improve and complete our method of confidence metric estimation.  In Section \ref{sec:adjustments} we consider any additional improvements or adjustments to the initial proposed process that have come to light considering our initial set of results and error analysis.  Finally, our final objective in Section \ref{sec:objectives} is the extension of the process to global coverage.  In Section \ref{sec:globalprocessing} we present our initial plans for selecting a global dataset and what steps are required to complete a global product.

\section{Confidence Metric Improvements}
\label{sec:confidenceimprovements}

The bulk of our most recent work lies in determining a feasible method of assigning a confidence metric on a per pixel basis.  As discussed in Section \ref{sec:confidencemetrics}, two original methods of error analysis were investigated.  It is difficult to make direct comparisons because they were evaluated differently, but both were unsuccessful at consistently assigning a confidence or error to each pixel.  However, we feel that the threshold analysis method has more potential for improvement and could lead to a feasible method of error analysis.

\subsection{Threshold Determination}
\label{sec:thresholddetermination}

A thorough investigation of the threshold levels for each metric will be conducted.  The threshold for each metric will be optimized by investigating the success of error analysis over the whole range of reasonable thresholds.  We consider the number of scenes correctly assigned high confidence, in error of commission, correctly assigned low confidence, and in error of omission for every feasible threshold.  The summation of these four points should sum to the total number of scenes (after cloud removal) for each threshold.  An example of such an investigation is shown in Figure \ref{fig:optimizeTransmission}; this plot was created with a 1 K standard.  The original threshold is shown as the vertical line; a threshold set where the correct high confidence intersects the correct low confidence would optimize the number of correctly assigned confidence results while a threshold set where the errors of commission intersect the errors of omission would minimize the number of incorrectly assigned confidence results.  As shown, the current initial threshold is between these two extremes.

% validation/threshold_analysis.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{results/optimizeTransmission.png}
\caption{Investigation to optimize transmission threshold by considering success of error analysis with threshold over entire reasonable range.}
\label{fig:optimizeTransmission}
\end{figure}

Notice that two of the three curves are flat in Figure \ref{fig:optimizeTransmission}.  We can learn very little about the appropriate threshold from a flat curve; from this, we do learn that transmission may not be beneficial for setting confidence thresholds so we will have to investigate other metrics or combinations of metrics in order to have successful confidence estimation.

An important aspect of threshold determination is the desired result of the error analysis.  Is it more important to assign low confidence to all pixels that may have a large error?  Or is it most important that high confidence pixels have a very low error?  We discussed in Section \ref{sec:threshold} the importance of low errors of commission, but investigating applications and the desires of the end users is another aspect of future work in threshold determination.

\subsection{Multilevel Confidence Estimation}

Rather than simply assigning a high confidence or low confidence to each pixel, we would like to assign multiple levels of confidence based on multiple thresholds.  Ideally, we will have an expected mean and standard deviation associated with each confidence level.  That is, pixels in this confidence level have an average error of this mean with this standard deviation, given in kelvin.  As per the discussion above in Section \ref{sec:thresholddetermination}, the determination of categories can be driven by the desire of end users.  We could have a threshold that contains only the best points that we are certain have low errors, a middle category with relatively well-behaved results, and a category of pixels that we think have large errors. Or, we could have a category containing pixels that we are certain have large errors, a middle category of relatively well-behaved results, and a category of what we think are good results.

An example of such an analysis is shown in Table \ref{tab:multilevelTransmission}.  As an initial unsophisticated categorization, we classify scenes with a transmission above 0.9 as the best scenes, scenes with a transmission between 0.8 and 0.9 as good scenes, and scenes with a transmission below 0.8 as bad scenes.  Note that cloudy scenes based on the cloud detection described in Section \ref{sec:clouddetection} have been eliminated.

\begin{table}[H]
\begin{center}
\begin{tabular}{|c | c | c |}
\hline
Category & Mean [K] & Standard Deviation [K] \\ \hline
Best & 0.868 K & 1.083 K \\ \hline
Good & 1.500 K & 2.828 K \\ \hline
Bad & 2.318 K & 2.867 K \\ \hline
\end{tabular}
\caption{Initial multilevel threshold determination for transmission including all scenes.  Best scenes have a transmission greater than 0.9, good scenes have a transmission between 0.8 and 0.9, and bad scenes have a transmission below 0.8.}
\label{tab:multilevelTransmission}
\end{center}
\end{table}

This analysis does not account for how many scenes are correctly or incorrectly classified, only the mean and standard deviation of each category.  We would ideally like to report a mean and standard deviation of error along with each category as shown here.  Although this is an initial estimation of multilevel thresholds, it can be seen in Table \ref{tab:multilevelTransmission} that the mean error increases with each category and the standard deviation is larger in the good and low confidence categories than it is in the best category.

\subsection{Confidence Estimation With Multiple Metrics}

With the regression analysis, we explored multivariate linear regressions as a method of utilizing a maximum amount of data for our error analysis.  We would like to utilize multiple metrics in threshold analysis as well.  An analogous procedure in threshold analysis would result in an abundance of scenes with low confidence or an abundance of high confidence scenes depending on the priority of the logical operation.  However, we would like to explore sliding thresholds.  For example, if a scene has a low maximum temperature we may accept higher relative humidity values and still expect accurate land surface temperature retrieval.  But with a high maximum temperature, it may be necessary to have a low relative humidity to achieve accurate LST retrieval.  This has not yet been implemented in any form.

This would allow us to utilize more information from each pixel; particularly for metrics that did not appear to have usable shape, such as relative humidity and maximum temperature, we can explore the relationship between these metrics to make use of the data.  We do not yet have any initial results for this as the concept is in its initial stages.

\subsection{Larger Sample Set}

As discussed above, some of our limitations on confidence estimation are due to the limitations of our sample set.  Although we have a good number of scenes, the distribution of these scenes, and their selection based on clouds and ability to retrieve land surface temperature, leads to biased results.  We have plans to augment this data set with scenes from the great lakes and the California coast, as well as using fewer scenes from Lake Tahoe so that they no longer skew or dominate the calculated means.  This should help to make our analysis less biased and more realistic.

\subsection{Improved Cloud Detection}

Section \ref{sec:clouddetection} describes our initial method of cloud detection.  The method is conservative in its assignment of clouds and developed from simple investigation of our results.  We would like to implement a more robust cloud detection but have concerns about the computational intensity of such an addition.  It is also important to decide if we want to have a separate category for clouds in our threshold analysis or if it is acceptable to assign cloudy pixels low confidence.  We lean towards a separate category of clouds in our confidence metric determination because, as shown in the histograms in Chapter \ref{ch:initialresults}, the magnitude of error in cloudy pixels is larger than those we would like to assign low confidence.  This would affect the mean and standard deviation we assign to each category.  And, as previously discussed, the temperature predicted in cloudy pixels is not simply an inaccurate prediction of the surface temperature; it may quite accurately capture the temperature of the cloud.

We will explore the implementation of simple cloud detection algorithms to improve our results.  We will also consider using the cloud information already contained in the metadata of some Landsat products.

\section{Adjustments and Improvements}
\label{sec:adjustments}

Once we have validated the feasibility of our process and implemented a method of error analysis or confidence metric determination, we will need to verify each step in the process.  As mentioned throughout, we can implement minor adjustments to optimize the process.  This may include adjusting the heights at which MODTRAN is executed as discussed in Section \ref{sec:heightinterpolation} or the weighting exponent from Shepard's method in Section \ref{sec:spatialinterpolation}, among others.

\section{Global Processing}
\label{sec:globalprocessing}

As discussed in Section \ref{sec:narrdataset}, current atmospheric profiles are extracted from the North American Regional Reanalysis dataset.  However, as can be implied from the name, this dataset only covers North America.  One of the many benefits of Landsat is the global coverage every 16 days.  NARR was chosen as an initial implementation for the coverage and resolution it provided over the United States in particular, as well as for the likelihood of continuing availability and distribution of the product.  The final step is to select a dataset that will provide global coverage and allow us to modify this process to produce a global product.  Two possible products are described below.

\subsection{MERRA Datset}
\label{sec:merradataset}

MERRA, the modern-era retrospective reanalysis for research and applications, uses a version of Goddard Earth Observing System Data Assimilation System Version 5 (GEOS-5).  Some inputs for the MERRA data product include radiosondes, wind profiles, aircraft data, dropsondes, and rain rates among other things.  It provides 1.25$^\circ$ resolution around the globe 8-times daily at 42 pressure levels, with data available from 1979 to present \cite{merra}.  The 1.25$^\circ$ resolution results in 288 points in longitude and 144 points in latitude.  This is the same temporal resolution as the NARR dataset, with improved resolution in pressure but reduced spatial resolution.  This dataset, like NARR, gives the geopotential height, specific humidity, and air temperature necessary for MODTRAN.  However, MERRA also provides the relative humidity, eliminating the need for a specific humidity to relative humidity conversion.  MERRA data for this work is downloaded as HDF files from the OPeNDAP data access from \\ {\tt http://goldsmr3.sci.gsfc.nasa.gov/opendap/MERRA/MAI3CPASM.5.2.0/contents.html} \\ \cite{merra_data}.

\subsection{NCEP Dataset}
\label{sec:ncepdataset}

NCEP/NCAR Reanalysis 1, referred to as the NCEP (National Centers for Environmental Prediction) dataset, provides data from 1840 to present.  It also uses state of the art reanalysis to generate a consistent set of variables from inputs similar to other reanalysis such as radiosondes, pibals, and aircraft data.  It is presented in a 2.5$^\circ$ by 2.5$^\circ$ global grid (144 by 73) 4-times daily; some variables are given at 17 pressure levels and others at 8 pressure levels.  While air temperature and geopotential are given at 17 pressure levels, specific humidity and relative humidity are both given at 8 pressure levels, reducing the resolution of our process to 8 pressure levels \cite{ncep}.  This is reduced resolution is all dimensions.  The NCEP data for this work was downloaded as packed NetCDF files from the FTP \\ {\tt ftp.cdc.noaa.gov/Datasets/ncep.reanalysis/pressure} \\ \cite{ncep_data}.

Table \ref{tab:datasets} provides a comparison between NARR and the two global datasets.

\begin{table}[H]
\begin{center}
\begin{tabular}{|c | c | c | c |}
\hline
 & NARR & MERRA & NCEP \\ \hline
Coverage & North America & Global & Global \\ \hline
\multirow{3}{*}{Spatial} & 32 km. spacing & 1.25$^\circ$ x 1.25$^\circ$ & 2.5$^\circ$ x 2.5$^\circ$ \\
 & (0.3$^\circ$ at equator) & (140 km at equator) & (278 km at equator) \\
 & 349 x 277 & 288 x 144 & 144 x 73 \\ \hline
 \multirow{2}{*}{Temporal} & 8x daily & 8x daily & 4x daily \\
  & 3-hr intervals & 3-hr intervals & 6-hr intervals \\ \hline
 \multirow{2}{*}{Pressure Levels} & 29 levels & 42 levels & 8 levels \\
  & 1000 - 100 hPa & 1000 - 0.1 hPa & 1000 - 300 hPa \\ \hline
\end{tabular}
\caption{Comparison of datasets for atmospheric profiles.}
\label{tab:datasets}
\end{center}
\end{table}

\subsection{Initial Results}

The methodology proposed in Chapter \ref{ch:methodology} was adapted using the same interpolations and methods for each of the above described datasets.  A subset of 33 scenes with available ground truth data from Chapter \ref{ch:initialresults} was selected.  By using our global datasets on scenes over North America, we can compare the results to both truth and results generated using NARR data.  Figures \ref{fig:narrhistogram}, \ref{fig:merrahistogram}, and \ref{fig:ncephistogram} show error histograms generated using the same 33 scenes.  Errors were calculated using Equation \ref{eq:initialerror}.  It should be noted that there are scenes selected from the Salton Sea (6), Lake Tahoe (11), Rochester (9) and Delmar (7) but not Georgia.

\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{results/narrhistogram.png}
\caption{Histogram of errors for 33 scenes using the NARR dataset for atmospheric profiles.}
\label{fig:narrhistogram}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{results/merrahistogram.png}
\caption{Histogram of errors for 33 scenes using the MERRA dataset for atmospheric profiles.}
\label{fig:merrahistogram}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale = 0.6]{results/ncephistogram.png}
\caption{Histogram of errors for 33 scenes using the NCEP dataset for atmospheric profiles.}
\label{fig:ncephistogram}
\end{figure}

From manual investigation of the data discussed in Section \ref{sec:initialerror}, the left most bin in these histograms ($<-8 K$) can be considered clouds.  Table \ref{tab:globalerrors} summarizes the mean and standard deviation of the errors from each dataset after removing the scenes detected to be clouds using the initial cloud detection method described in Section \ref{sec:clouddetection}.

\begin{table}[H]
\begin{center}
\begin{tabular}{|c | c | c |}
\hline
Dataset & Mean & Standard Deviation \\ \hline
NARR & 1.311 K & 1.575 K \\ \hline
MERRA & 1.357 K & 1.304 K \\ \hline
NCEP & 1.420 K & 1.434 K \\ \hline
\end{tabular}
\caption{Means and standard deviations of errors for 33 scenes processed using three different datasets.}
\label{tab:globalerrors}
\end{center}
\end{table}

Initial results indicate that MERRA may lead to better results than NCEP for a global product.  Not only is the MERRA error and standard deviation more comparable to that of the NARR dataset, but the shape of the histogram is also similar.  NCEP has a slight positive bias which is not observed in any other set of results.  Considering Table \ref{tab:datasets}, the difference between NCEP and MERRA is likely due to the spatial resolution.  Although there are fewer samples per day and fewer pressure levels, from a brief investigation into the data, the largest changes in sampling and interpolation come in the spatial domain.  The NCEP dataset could result in a  single point within an entire Landsat scene, leading to large spatial interpolations.

This is a brief and initial investigation with only a small sample of scenes into which global dataset is optimal.  Most importantly from this, we can assert that adaptation to and implementation of a global product is feasible.  Our simply study indicates that there does not appear to be a dramatic shift with either choice so there is not necessarily a bad option or a significantly better option.  We will also need to adapt our method of confidence metric estimation to this global dataset.

\section{Concluding Remarks}

The goal of this chapter was to briefly discuss what work remains in this project.  We begin where we left off in Chapter \ref{ch:initialresults} making suggestions and indicating the steps we will take to improve and complete our confidence metric determination.  We then discuss other adjustments and improvements in Section \ref{sec:adjustments} and conclude by summarizing the steps necessary to extend the process to global coverage in Section \ref{sec:globalprocessing}.

We hope to have accurately presented the feasibility of our process along with the steps we will take to complete and improve our work.

% \section{Summary and Recommendations}

\appendix
\chapter{MODTRAN Inputs and Outputs}
\label{app:modtranIO}

This work uses MODTRAN4 Version 3 Revision 1 \cite{modtran}.  Because MODTRAN was developed in the punch card era, where programs and collections of data were stored on punch cards, input and output files are referred as the card deck and each file is called a tape file.  The tape5 file is a precisely formatted input file and the execution of MODTRAN produces the tape6, tape7, tape7.scn, tape8 and the pltout and pltout.scn files.

MODTRAN is executed by inputting data into the tape5 file.  Because of the historical punch card system, formatting of this file is extremely important.  There have been various GUIs developed so that the user can specify inputs and a correctly formatted tape5 is generated for them.  However, it is extremely important to understand each input to the program as many GUIs can have defaults that may or may not be desired.  Each line in the tape5 file is referred to as a card; based on certain inputs, some cards are necessary while others can be omitted.  A summary of the necessary cards and their corresponding inputs to MODTRAN for the runs completed in this work is summarized in Table \ref{tab:modtraninputs}.  Consult the MODTRAN manual for a more detailed description of the specific formatting \cite{modtran}.

Figure \ref{fig:tape5} shows an example a default tape5 file for this work containing each of the inputs described in Table \ref{tab:modtraninputs}.  It has a complete NARR atmosphere but still contains flags for the temperature, surface albedo, and ground altitude.

%\begin{table}[H]
%\small
%\begin{center}
\small
\begin{longtable}{|c | C{5cm} | c | C{5cm} |}
\hline
Variables & Description & Input & Explanation  \\ \hline
\multicolumn{4}{|c|}{Card 1} \\ \hline
MODTRN & band model algorithm for radiative transport & T & using MODTRAN band model \\ \hline
SPEED & correlated k-option & M & `medium' speed Correlated-k option \\ \hline
MODEL & geographical/seasonal atmosphere & 7 & user-specified model atmosphere \\ \hline
ITYPE & atmospheric line-of-sight & 3 & vertical or slant path to space or ground \\ \hline
IEMSCT & mode of execution & 2 & spectral thermal and solar/lunar radiance \\ \hline
IMULT & multiple scattering & 1 & execute with multiple scattering \\ \hline
M1 & profile for temperature and pressure & 0 & \\
M2 & profile for $H_2O$ & 0 & JCHAR parameter in Card 2C1 \\
M3 & profile for $O_3$ & 0 &  supplies necessary profiles because \\
M4 & profile for $CH_4$ & 0 &  user supplies model atmosphere \\
M5 & profile for $N_2O$ & 0 & \\
M6 & profile for $CO$ & 0 & \\ \hline
MDEF & $CO_2$, $O_2$, $NO$, $SO_2$, $NO_2$, $NH_3$, and $HNO_3$ profiles & 1 & default heavy species profiles \\ \hline
IM & read user input data & 1 & always read new user input data \\ \hline
NOPRNT & controls output & 0 & normal tape6 output \\ \hline
TPTEMP & boundary temperature & tmp.000 & boundary temperature input based on current MODTRAN run \\ \hline
SURREF & albedo of the Earth & alb0 & surface albedo input based on current MODTRAN run \\ \hline
\multicolumn{4}{|c|}{Card 1A} \\ \hline
DIS & select multiple scattering algorithme & T & activate discrete ordinate multiple scattering algorithm (slower and more accurate) DISORT \\ \hline
DISAZM & azimuth dependence flag & blank & excludes azimuth dependence \\ \hline
NSTR & number of streams in scattering algorithm & 8 & uses recommend 8 streams in DISORT \\ \hline
LSUN & spectral resolution of irradiance & F & default solar 5 cm$^{-1}$ spectral resolution irradiance \\ \hline
ISUN & FWHM of triangular scanning function & 0 & default values for FWHM \\ \hline
CO2MX & CO$_2$ mixing ratio in ppmv & 360.00000 & default value is 330 ppmv, recommended is closer to 365 ppmv \\ \hline
H20STR & vertical water vapor column character string & 0 & uses default water vapor column \\ \hline
03STR & vertical ozone column character string & 0 & default ozone column used \\ \hline
LSUNFL & reading solar radiance data & F & use default solar radiance data \\ \hline
LBMNAM & read band model parameter data & F & default band model (1 cm$^{-1}$ bin) database \\ \hline
LFLTNM & read file for user-defined instrument filter & F & no user defined instrument filter function \\ \hline
H2OAER & relating aerosol properties and relative humidity & blank & fixed H$_2$O properties even though water amount has changed \\ \hline
LDATDR & reading MODTRAN data files & blank & data files assumed to be in directory in DATA/ \\ \hline
SOLCON & scaling TOA irradaince & 0.000 & do not scale TOA solar irradiance \\ \hline
\multicolumn{4}{|c|}{Card 2} \\ \hline
APLUS & aerosol profiles & blank & default aerosol profiles \\ \hline
IHAZE & type of extinction and meteorological range & 1 & rural extinction, default VIS = 23 km \\ \hline
CNOVAM & aerosol model & blank & default aerosol model \\ \hline
ISEASN & appropriate seasonal aerosol profile for tropospheric and stratospheric aerosols & 0 & season determined by model, spring-summer when model = 7 \\ \hline
ARUSS & defining aerosol optical properties & blank & default aerosol optical properties \\ \hline
IVULCN & stratospheric aerosols and extinction & 0 & background stratospheric profile and extinction \\ \hline
ICSTL & air mass character where 1 = open ocean, 10 = strong continental influence & 0 & uses default air mass character = 3 \\ \hline
ICLD & cloud and rain models & 0 & no clouds or rain \\ \hline
IVSA & army vertical structure algorithm & 0 & does not use army vertical structure algorithm for aerosols in boundary layer \\ \hline
VIS & surface meteorological range & 0.000 & uses default meteorological range set by IHAZE \\ \hline
WSS & current wind speed (m/s) & 0.000 & only used with IHAZE = 3 or IHAZE = 10 \\ \hline
WHH & 24-hour average wind speed & 0.000 & only used with IHAZE = 3 \\ \hline
RAINRT & specifies the rain rate & 0.000 & default is 0 for no rain \\ \hline
GNDALT & altitude of the surface relative to sea level (km) & gdalt & altitude input based on current MODTRAN run \\ \hline
\multicolumn{4}{|c|}{Card 2C} \\ \hline
ML & number of atmospheric levels & mml & number of levels in profile determined based on current MODTRAN run \\ \hline
IRD1 & reading of Card 2C2 & 0 & no reading of Card 2C2 \\ \hline
IRD2 & reading of Card 2C3 & 0 & no reading of Card 2C3 \\ \hline
HMODEL & identification of new model atmosphere & blank & no new model atmosphere identified \\ \hline
REE & earth radius in kilometers & blank & only read in model = 8 \\ \hline
\multicolumn{4}{|c|}{Card 2C1} \\ \hline
ZM & altitude of layer boundary &  & input for each atmospheric layer in the current MODTRAN run \\ \hline
P & pressure of layer boundary &  & input for each atmospheric layer in the current MODTRAN run \\ \hline
T & temperature of layer boundary &  &  input for each atmospheric layer in the current MODTRAN run \\ \hline
WMOL(1) & water vapor & &  input for each atmospheric layer in the current MODTRAN run \\ \hline
WMOL(2) & carbon dioxide & 0.000e+00 & not specified for any layer \\ \hline
WMOL(3) & ozone & 0.000e+00 & no specified for any layer \\ \hline
JCHAR(1) & units of pressure at layer boundary & A & specifies pressure in mb \\ \hline
JCHAR(2) & units of temperature at layer boundary & A & specified temperature in K \\ \hline
JCHAR(3) & specifies which water vapor & H & specified water vapor as relative humidity in\% \\ \hline
JCHAR(4) & defaults to M1 - M6 and MDEF & blank & MDEF = 1 specifies \\
JCHAR(5) & values when WMOL(2-3) are zero & blank & default profiles \\ \hline
JCHAR(6) & & blank & \\
JCHAR(7) & & blank & \\
JCHAR(8) & & blank & \\
JCHAR(9) & corresponds to  & blank & never read based on\\
JCHAR(10) & WMOL(4-12) & blank & IRD1 in Card 2C \\
JCHAR(11) & & blank & \\
JCHAR(12) & & blank & \\
JCHAR(13) & & blank & \\
JCHAR(14) & & blank & \\ \hline
JCHARX & units for CFCs and other heavy molecules & blank & MDEF = 1 specifying default profiles \\ \hline
\multicolumn{4}{|c|}{Card 3} \\ \hline
H1 & initial altitude (km) & 100.000 & observer/sensor altitude of 100 km \\ \hline
H2 & tangent height (km) & 0.000 & target on the ground \\ \hline
ANGLE & initial zenith angle (0-180 degrees) as measured from H1 & 180.000 & sensor looking at the ground \\ \hline
RANGE & path length (km) & 0.000 & path length from sensor to ground \\ \hline
BETA & earth center angle subtended but H1 and H2 (0-180 degrees) & 0.000 & sensor pointing directly at target \\ \hline
RO & radius of the Earth (km) at particular altitude of calculation & 0.000 & uses default mid-latitude value of 6371.23 km for MODEL = 7 \\ \hline
LENN & path length specification & 0 & short path length \\ \hline
PHI & zenith angle as measured from H2 towards H1 (0-180 degrees) & 0.000 & \\ \hline
\multicolumn{4}{|c|}{Card 3A1} \\ \hline
IPARM & method of specifying lunar/solar geometry on Card 3A2 & 1 & see Card 3A2 inputs \\ \hline
IPH & specification of phase function & 2 & mid-generated internal database of aerosol phase functions for MODTRAN models \\ \hline
IDAY & day of year from 1 to 365 to specify sun's locations & jay & day of year input from current MODTRAN run \\ \hline
ISOURC & extraterrestrial source & 0 & extraterrestrial source is the sun \\ \hline
\multicolumn{4}{|c|}{Card 3A2} \\ \hline
PARM1 & observer latitude (-90$^\circ$ to +90$^\circ$) & latitu & latitude input from current MODTRAN run \\ \hline
PARM2 & observer longitude (0$^\circ$ to 360$^\circ$ West of Greenwich) & longit & longitude input from current MODTRAN run \\ \hline
PARM3 & sun latitude & 0.000 & not required for IPARM = 1 \\ \hline
PARM4 & sun longitude & 0.000 & not required for IPARM = 1 \\ \hline
TIME & Greenwich time & 12.000 & 12 Z used for all MODTRAN runs \\ \hline
PSIPSO & true path azimuth from H1 to H2 & 0.000 & degrees East of true North \\ \hline
ANGLEM & phase angle of the moon & 0.000 & not required in our settings \\ \hline
G & asymmetry factor & 0.000 & not required in our settings \\ \hline
\multicolumn{4}{|c|}{Card 4} \\ \hline
V1 & initial frequency in wavenumber or wavelengths & 10.000 & wavelength in microns \\ \hline
V2 & final frequency in wavenumber of wavelengths & 13.000 & wavelength in microns \\ \hline
DV & frequency or wavelength increment used for spectral outputs & 0.050 & wavelength increment in microns \\ \hline
FWHM & slit function full width at half maximum & 0.050 & FWHM of slit function in microns \\ \hline
YFLAG & values in output files & R & output radiances (rather than transmittances) \\ \hline
XFLAG & units of values in output files & M & spectral wavelength in microns \\ \hline
DLIMIT & separate output from repeat in MODTRAN runs & blank & not necessary in our settings, no repeat \\ \hline
FLAGS & seven character string & see below &  \\ \hline
FLAGS(1:1) & spectral units & M & spectral units in microns \\ \hline
FLAGS(2:2) & slit function & blank & default slit function \\ \hline
FLAGS(3:3) & FWHM characteristics & blank & FWHM is absolute \\ \hline
FLAGS(4:4) & degradation of results & A & degrade all radiance and transmittance components \\ \hline
FLAGS(5:5) & degradation settings & blank & do no save current results \\ \hline
FLAGS(6:6) & degradation settings & blank & do not use saved results \\ \hline
FLAGS(7:7) & ``spec flux" file & blank & do not write a spectral flux table \\ \hline
MLFLX & number of atmospheric levels of spectral flux values & blank & spectral flux values output at all atmospheric levels \\ \hline
\multicolumn{4}{|c|}{Card 5} \\ \hline
IRPT & program execution setting & 0 & stop program \\ \hline
%\end{tabular}
\caption{MODTRAN inputs to generate tape5 files for this work.}
\label{tab:modtraninputs}
%\end{center} 
%\end{table}
\end{longtable}

\begin{figure}[H]
\centering
\includegraphics[scale = 0.7]{appendix/tape5.png}
\caption{Image of an example of a tape5 file.}
\label{fig:tape5}
\end{figure}

\normalsize

\chapter{MODTRAN Run Study}
\label{app:modtranrunstudy}

A major portion of this work is the generation of the radiative transfer parameters.  As implied in Section \ref{sec:parameters}, there are a number of different methods to generate these parameters and the selection of the method is a balance between accuracy and computational intensity.

The most computationally intensive method uses six MODTRAN runs at combinations of three different temperatures and two different surface albedos.  The governing equation 

\[
L_{obs} = (L_T\epsilon+(1-\epsilon)L_d)\tau + L_u
\]

reduces to 

\[
L_{obs} = L_T\epsilon\tau + L_u
\]

when $\epsilon$=1.  Therefore, we use three MODTRAN runs at three different temperatures ($T_1$ = 273 K, $T_2$ =  295 K, and $T_3$ = 310 K) with $\epsilon$=1 to generate the transmission and upwelled radiance as shown in Figure \ref{fig:sixmodtranruns}.  We use an additional three MODTRAN runs, at the same three temperatures with $\epsilon$=0.9, to perform a second linear regression.  In this case, the slope and intercept can be rearranged, with the known transmission and upwelled radiance, to solve for the downwelled radiance using the equations shown in Figure \ref{fig:sixmodtranruns}.  

% power points/17Jan2012.ppt
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{appendix/sixmodtranruns.png}
\caption{Linear regressions and equations necessary to generate radiative transfer parameters with six MODTRAN runs.}
\label{fig:sixmodtranruns}
\end{figure}

This method requires the greatest number of MODTRAN runs (6) as well as two linear regressions.

Another method utilizes only four MODTRAN runs.  The calculations for this method are the same as the six run method, but we perform both linear regressions with only two points rather than three.  So, we use two MODTRAN runs at two different temperatures ($T_1$ = 273 K and $T_3$ = 310 K) with $\epsilon$ = 1 and use a linear regression to solve for transmission and upwelled radiance.  We then use two MODTRAN runs at the same two temperatures with $\epsilon$ = 0.9 and a linear regression, with the known transmission and upwelled radiance, to solve for the downwelled radiance.  This method is shown in Figure \ref{fig:fourmodtranruns}.

% power points/17Jan2012.ppt
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{appendix/fourmodtranruns.png}
\caption{Linear regressions and equations necessary to generate radiative transfer parameters with four MODTRAN runs.}
\label{fig:fourmodtranruns}
\end{figure}

This method requires the same two linear regressions but with fewer MODTRAN runs (4).  The danger of using a two point linear regression is the error compounded by the error in a single point.  This study should illustrate the difference, if any, in results between the three-point and two-point linear regressions.

There is another method that requires three MODTRAN runs, as described in Section \ref{sec:parameters}.  We use a two-point linear regression with two MODTRAN runs at two different temperatures ($T_1$ = 273 K and $T_3$ = 310 K) and $\epsilon$ = 1 as shown in Figure \ref{fig:threemodtranruns} to generate transmission and upwelled radiance, as with the four run method.  Then, rather than using a two point linear regression to solve for the downwelled radiance, we rearrange the governing equation to solve for the downwelled radiance and perform only one run with $\epsilon$ = 0.9.  Although the temperature of the MODTRAN run should not matter, because the linear relationship with real data is not perfect, we use T = `000'.  This uses the temperature of the lowest atmospheric layer as the ground temperature for this run.  This guarantees that we are using a ground temperature relatively close to the land surface temperature of the target.  This is illustrated in Figure \ref{fig:threemodtranruns}.

% power points/17Jan2012.ppt
\begin{figure}[H]
\centering
\includegraphics[scale = 0.55]{appendix/threemodtranruns.png}
\caption{Linear regression and equations necessary to generate radiative transfer parameters with three MODTRAN runs.}
\label{fig:threemodtranruns}
\end{figure}

This requires one less MODTRAN run and one less linear regression if we find that solving for the downwelled radiance in this method is accurate.  Similar to the two-point linear regression, this relies on a single MODTRAN run and any error from this single run could be compounded in our downwelled radiance results.  In this case, unlike the six and four run methods, the retrieved radiative transfer parameters can vary slightly with the boundary temperature used in the calculations.  Using the air temperature of the lowest layer of the atmospheric profile should guarantee the boundary temperature is reasonably close to the LST of the pixels where this downwelled radiance will be used.

In order to determine the optimal method, we generated radiative transfer parameters using all three methods with the same atmosphere.  We used these radiative transfer parameters to generate the radiance due to the temperature and convert this to a temperature using a look up table as described in Section \ref{sec:parameters} using a range of boundary temperatures.  In perfect results, we expect to retrieve these boundary temperatures.  The retrieved temperature is plotted against height for test temperatures of 260 K, 280 K, 300 K, and 320 K is Figures \ref{fig:temp260}, \ref{fig:temp280}, \ref{fig:temp300}, and \ref{fig:temp320} respectively.

% MODTRANDATA/plot_number_modtran_runs.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{appendix/temp260.png}
\caption{Retrieved temperatures using three, four and six MODTRAN runs to generate radiative transfer parameters with a land surface temperature of 260 K.}
\label{fig:temp260}
\end{figure}

% MODTRANDATA/plot_number_modtran_runs.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{appendix/temp280.png}
\caption{Retrieved temperatures using three, four and six MODTRAN runs to generate radiative transfer parameters with a land surface temperature of 280 K.}
\label{fig:temp280}
\end{figure}

% MODTRANDATA/plot_number_modtran_runs.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{appendix/temp300.png}
\caption{Retrieved temperatures using three, four and six MODTRAN runs to generate radiative transfer parameters with a land surface temperature of 300 K.}
\label{fig:temp300}
\end{figure}

% MODTRANDATA/plot_number_modtran_runs.pro
\begin{figure}[H]
\centering
\includegraphics[scale = 0.5]{appendix/temp320.png}
\caption{Retrieved temperatures using three, four and six MODTRAN runs to generate radiative transfer parameters with a land surface temperature of 320 K.}
\label{fig:temp320}
\end{figure}

Note the scale of each plot; the range spans only 0.5 K.  Therefore, the differences in the retrieval results are small and all three methods are comparable.  The four run and six run methods are almost identical, indicating there is negligible difference between the three-point and two-point linear regression.  Note that the three run method improves slightly as temperature increases;  as discussed in Section \ref{sec:confidencemetrics}, LST retrieval is more difficult with higher temperatures.  While the four run and six run methods are constant for all temperatures, the three run method adapts slightly to this change, causing better results at higher temperatures.  Therefore, because all three methods produce comparable results with three runs slightly better at higher temperatures and having the lowest computational intensity, the three run method was selected to be implemented in this work.

\bibliographystyle{apalike}
\bibliography{bibliography}

\end{document}

%*****NOTES********

%Sections:
%ABSTRACT
%INTRODUCTION
%OBJECTIVES
%BACKGROUND AND THEORY
%METHODOLOGY AND APPROACH
%RESULTS
%SUMMARY AND RECOMMENDATIONS
%APPENDICES

%Things to Include:
%governing equation, sensor reaching radiance
%NARR data set and reanalysis
%land surface temperature
%MODTRAN
%MODTRAN run study, temperature dependence
%temporal interpolation
%spatial interpolation
%height interpolation
%pixel iteration
%conversions - coordinates, humidity, height
%coordinate systems
%filters
%error analysis
%landsat history
%atmospheric compensation - atmospheric parameters
%deliverables
%high density temp and humidity map


%***********TEMPLATES************

%\begin{figure}[H]
%\centering
%\includegraphics[scale = 1.2]{downwelled.png}
%\caption{Downwelled Radiance.}
%\label{fig:downwelled}
%\end{figure}

%\begin{figure}[H]
%\begin{minipage}[b]{0.47\textwidth}
%\centering
%\includegraphics[scale = 3]{originalCrop}
%\caption{Vertical edge cropped from the original image.}
%\label{fig:originalCrop}
%\end{minipage}
%\hspace{0.5cm}
%\begin{minipage}[b]{0.5\linewidth}
%\centering
%\includegraphics[scale = 3]{maskedCrop}
%\caption{Vertical edge cropped from the masked image.}
%\label{fig:maskedCrop}
%\end{minipage}
%\end{figure}

%\begin{table}[H]
%\begin{center}
%\begin{tabular}{|c | c | c | c |}
%\hline
%Trial&z-distance, Z (cm)&0 to 1st order distance, y(cm)&Diffracted Angle, $\theta$, (deg) \\ \hline
%1&90&24&14.93 \\ \hline
%2&75 cm&20 cm&14.93 \\ \hline
%Average& & &14.93 \\ \hline
%\end{tabular}
%\caption{Determining the wavelength of the LASER.}
%\label{tab:wavelength}
%\end{center}
%\end{table}

%\begin{equation}
%OTF(\xi) = \int_{-\infty}^\infty {LFS}(x){\cdot}e^{-j2\pi{x}\xi}dx
%\label{eq:OTF}
%\end{equation}