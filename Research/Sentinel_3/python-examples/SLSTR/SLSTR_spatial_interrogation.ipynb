{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLSTR spatial plotting, quality control and data interrogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Version: 2.0\n",
    "    Date: 03/09/2018\n",
    "    Author: Ben loveday, Plymouth Marine Laboratory\n",
    "    \n",
    "    Notes:\n",
    "    \n",
    "    This routine has been designed to work with SLSTR L2 NRT data, which is available as \n",
    "    tiles. It can be easily adapted for application to L1 data, but care should be taken\n",
    "    if using it to analyse L2 NTC data, as this is delivered as a half orbit PDU.\n",
    "\n",
    "This routine shows examples of how to use python netcdf libraries to ingest Level 2 SLSTR data, mask it according to quality control variables, correct for bias, select only for dual view data and compare it against other, coincident geo-physical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, we usually have a few sections of code at the top that occur before we enter the main programme. These\n",
    "sections typically include:\n",
    "1. importing modules\n",
    "2. defining functions that are called in the main programme\n",
    "3. defining arguments that are passed to the main programme (we can't do this when running in interactive mode e.g. ipython of jupyter notebook. We only really use this in batch mode)\n",
    "\n",
    "Comment: We do not really require this next line, it is here only for consistency with the batch version. It tells batch python where python is so that (under linux and OSx) we can call the function as a direct executable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we begin by importing all of the external modules that we will be using in this script; they are annotated with brief explanations of what they do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tools that allow us access tot system functions, e.g. get working directory, check path.\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# import high level python system functions\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# import tools that let us manipulate dates and times\n",
    "import datetime\n",
    "\n",
    "# import tools that let us manipulate arrays (makes Python more like Matlab for matrix operations)\n",
    "import numpy as np\n",
    "\n",
    "# import tools that allow us to pass variables form external sources (not possible in jupyter or ipython)\n",
    "import argparse\n",
    "\n",
    "# import tools that facilitate string pattern matching\n",
    "import fnmatch\n",
    "\n",
    "# import tools that let us create log files to write to\n",
    "import logging\n",
    "\n",
    "# import tools for netCFD4 manipulation\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "# import tools for plotting, making subplots, and utilising map projections\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# turn off warnings. Bad practice, but we don't want to see them here....\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have imported all of our modules, we are going to define a quick function for later use. This function, called load_variables will read a variable form an open netCDF file, and make sure we have control of variable masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-functions---------------------------------------------------------------------\n",
    "def load_variables(nc_fid, varname, rem_mask=True, verbose=False):\n",
    "    '''\n",
    "     Quick function to load variables as numpy array, flatten and apply new mask based on fill value \n",
    "    '''\n",
    "    if rem_mask:\n",
    "        return_variable = nc_fid.variables[varname][:]\n",
    "        if 'Masked' in str(type(return_variable)):\n",
    "            try:\n",
    "                return_fill     = nc_fid.variables[varname]._FillValue\n",
    "                return_variable = return_variable.data\n",
    "                return_variable[return_variable == return_fill] = np.nan\n",
    "            except:\n",
    "                if verbose:\n",
    "                    print('No fill value')\n",
    "    else:\n",
    "        return_variable = nc_fid.variables[varname][:]\n",
    "        \n",
    "    if len(np.shape(return_variable)) == 3:\n",
    "        return_variable = np.squeeze(return_variable)\n",
    "    \n",
    "    return return_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next section is defines two paths for where we read our input data from (current working directory), and where we write our log files to (again, current working directory). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-default parameters------------------------------------------------------------\n",
    "DEFAULT_ROOT_DIR    = os.getcwd()\n",
    "DEFAULT_LOG_PATH    = os.getcwd()\n",
    "DEFAULT_FILE_FILTER = '*SLSTR*.nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section is only relevant for batch mode, and controls how we read in arguments passed from externally. It is not relevant here, so it is commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-args--------------------------------------------------------------------------\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('-d', '--root_dir', type=str, default = DEFAULT_ROOT_DIR, help = 'Glider root directory')\n",
    "#parser.add_argument('-l', '--log_path', type=str, default = DEFAULT_LOG_PATH,help = 'log file output path')\n",
    "#parser.add_argument('-f', '--file_filter', type=str, default = DEFAULT_FILE_FILTER,help = 'default file filter')\n",
    "#args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#----------------------------------------------------PRE-AMBLE COMPLETE-----------------------------------------------\n",
    "\n",
    "Right, after all of that preparation, we are at the main entrance point for our code. We begin by defining our logfile so we can record any errors here if things go wrong, or any info/debug messages we may want along the way if we don't want them printed to screen (or to the console in interactive mode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-main-------------------------------------------------------------------------\n",
    "# preliminary stuff\n",
    "logfile = os.path.join(DEFAULT_LOG_PATH,\"SLSTR_test_plot_\"+datetime.datetime.now().strftime('%Y%m%d_%H%M')+\".log\")\n",
    "# we define a verbose flag to control how much info we want to see. It can also be useful to define a debug flag\n",
    "# for even more information.\n",
    "verbose=False\n",
    "no_show=False\n",
    "\n",
    "if no_show:\n",
    "    plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined a log file above, and here we set up how python will use it. Note that this is the first time we use the 'print' command. Print will output its contents to the screen, and here, this output will appear below the box when we run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file logger\n",
    "try:\n",
    "    if os.path.exists(logfile):\n",
    "        os.remove(logfile)\n",
    "    print(\"logging to: \"+logfile)\n",
    "    logging.basicConfig(filename=logfile,level=logging.DEBUG)\n",
    "except:\n",
    "    print(\"Failed to set logger\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, lets proceed with loading some SLSTR data. The first thing we need to do is find the relevant netCDF files that contain the data that we want to plot. This next block of code collects the names of all netCDF files in our DEFAULT_ROOT_DIR path. We can make this more specific by adapting the DEFAULT_FILE_FILTER variable from \"*.nc\".\n",
    "\n",
    "We begin by setting up an empty \"list\" variables called nc_files, and append to this list as we proceed through a series of loops, defined by the \"for\" statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -get the files-------------------------------------------------------------\n",
    "nc_files=[]\n",
    "for root, _, filenames in os.walk(DEFAULT_ROOT_DIR):\n",
    "    for filename in fnmatch.filter(filenames, DEFAULT_FILE_FILTER):\n",
    "        nc_files.append(os.path.join(root, filename))\n",
    "        if verbose:\n",
    "            print('Found: '+filename)\n",
    "        logging.info('Found: '+os.path.join(root, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check what files we have by looping through the list...\n",
    "\n",
    "In python you can loop through the values in a list using \"for item in list:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nc_file in nc_files:\n",
    "    print(nc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets loop through the ones we have found and start to look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nc_file in nc_files:\n",
    "    if verbose:\n",
    "        print(nc_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next line opens our netCDF file. It does not read any data in yet, just makes the contents accessible. We should remember to close this link, especially if we are opening lots of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    nc_fid = Dataset(nc_file,'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading our coordinate variables, using the function that we defined at the top of the script. \n",
    "\n",
    "note: python is very accepting of white space, but the next line would flag as a problem in a code-checker like pylint. It is spaced like this to make it easy to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    LON           = load_variables(nc_fid,'lon')\n",
    "    LAT           = load_variables(nc_fid,'lat')\n",
    "    TIME          = load_variables(nc_fid,'adi_dtime_from_sst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the quality and masking variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    L2P_FLAGS     = load_variables(nc_fid,'l2p_flags')\n",
    "    QUALITY_LEVEL = load_variables(nc_fid,'quality_level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we load our data variables and close the netCDF file link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    SST_raw       = load_variables(nc_fid,'sea_surface_temperature',rem_mask = False)\n",
    "    SST           = load_variables(nc_fid,'sea_surface_temperature')\n",
    "    SST_STD_DEV   = load_variables(nc_fid,'sses_standard_deviation')\n",
    "    SST_BIAS      = load_variables(nc_fid,'sses_bias')\n",
    "    SST_ALG_TYPE  = load_variables(nc_fid,'sst_algorithm_type')\n",
    "    WIND_SPEED    = load_variables(nc_fid,'wind_speed')\n",
    "    nc_fid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets set up our figure and make an initial plot of our SST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig  = plt.figure(figsize=(6,6), dpi=150)\n",
    "    plt.imshow(SST)\n",
    "    if no_show:\n",
    "        fig.savefig('plot1.png',bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot successful, but this is ugly, not very helpful as it is not on any geographical map, incorrect as we have not taken abias into account, and has not been quality controlled! Lets take steps to improve this by:\n",
    "1. reprojecting the data onto a map\n",
    "2. make a contour plot against our LON and LAT data (we use contourf here as it is faster, but pcolor is more appropriate)\n",
    "3. apply a more sensible colour bar for SST data\n",
    "4. adding a colour bar\n",
    "\n",
    "Then:\n",
    "1. Masking our data for specific features and qulity values\n",
    "2. Correcting our the SST for bias and considering the standard deviation\n",
    "3. Considering dual SST only.\n",
    "\n",
    "Lastly:\n",
    "1. Checking associated variables; e.g. wind speed\n",
    "\n",
    "So, lets perform the steps in the first list. The following code block does exactly that; reprojects (using the basemap toolkit), makes a filled contour plot (using contourf), applies a colour scale (cmap) and adds a colour bar (plt.colorbar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig  = plt.figure(figsize=(10,10), dpi=300)\n",
    "\n",
    "    # set projection\n",
    "    m = plt.axes(projection=ccrs.PlateCarree(central_longitude=0.0))\n",
    "\n",
    "    # set my vertical plotting order and fontsize\n",
    "    zordcoast=0\n",
    "    fsz=12\n",
    "    SST_plot = SST.copy()\n",
    "    vmin=np.nanmean(SST_plot)-3*np.nanstd(SST_plot)\n",
    "    vmax=np.nanmean(SST_plot)+3*np.nanstd(SST_plot)\n",
    "    SST_plot[SST_plot<vmin] = np.nan\n",
    "    SST_plot[SST_plot>vmax] = np.nan\n",
    "\n",
    "    # plot the data\n",
    "    p1 = plt.pcolormesh(LON,LAT,SST_plot,cmap=plt.cm.jet,vmin=vmin,vmax=vmax)\n",
    "\n",
    "    # add embelishments\n",
    "    m.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "    m.add_feature(cfeature.LAND, facecolor='0.75')\n",
    "    g1 = m.gridlines(draw_labels = True)\n",
    "    g1.xlabels_top = False\n",
    "    g1.xlabel_style = {'size': 16, 'color': 'gray'}\n",
    "    g1.ylabel_style = {'size': 16, 'color': 'gray'}\n",
    "    \n",
    "    cbar = plt.colorbar(p1, orientation='horizontal')\n",
    "    cbar.set_label('SST [K]',fontsize=fsz);\n",
    "    plt.title('SLSTR SST [K]', fontsize=fsz);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if no_show:\n",
    "        fig.savefig('plot2.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A definite improvement, our data is now accompanied by a scale, with units, and is reprojected so we can relate it to a map.\n",
    "\n",
    "However, we still have not interrogated our data. \n",
    "\n",
    "One of the most important things we need to do with SST data is consider the quality level - so lets start by doing that. \n",
    "\n",
    "The next code bloack will display the values of the quality level, stored in the quality level variables in the L2 WST product. Usually, we only consider the product viable where the quality flag is five, but can use quality level 4 in some circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig  = plt.figure(figsize=(10*int(np.nanmax(QUALITY_LEVEL))+1,10), dpi=150)\n",
    "    gs  = gridspec.GridSpec(1, int(np.nanmax(QUALITY_LEVEL))+1)\n",
    "    contour_vals = np.arange(np.nanmin(QUALITY_LEVEL)-1,np.nanmax(QUALITY_LEVEL)+1,1)\n",
    "    gs.update(wspace=0.1, hspace=0.1)\n",
    "    # loop through each algorithm\n",
    "    for ii in np.arange(0,int(np.nanmax(QUALITY_LEVEL))+1):\n",
    "        m = plt.subplot(gs[0,ii], projection=ccrs.PlateCarree(central_longitude=0.0))\n",
    "        MASKED_QUALITY_LEVEL = QUALITY_LEVEL.astype('float')\n",
    "        MASKED_QUALITY_LEVEL[MASKED_QUALITY_LEVEL != float(ii)] = np.nan\n",
    "        \n",
    "        # plot the data\n",
    "        plt.pcolormesh(LON,LAT,np.ma.masked_invalid(MASKED_QUALITY_LEVEL),vmin=0,vmax=5)\n",
    "        plt.text(33,-17.5,ii,fontweight='bold',fontsize=fsz*2)\n",
    "        \n",
    "        # add embelishments\n",
    "        m.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "        m.add_feature(cfeature.LAND, facecolor='0.75')\n",
    "        g1 = m.gridlines(draw_labels = False)\n",
    "        g1.xlabel_style = {'size': 16, 'color': 'gray'}\n",
    "        g1.ylabel_style = {'size': 16, 'color': 'gray'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if no_show:\n",
    "        fig.savefig('plot3.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, lets mask out any data that have a quality value of 2 or lower..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    SST[QUALITY_LEVEL<=4]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the SST field has two associated measurements that we need to consider, the bias, and the standard deviation. So lets plot these..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig  = plt.figure(figsize=(20,20), dpi=300)\n",
    "    gs  = gridspec.GridSpec(1, 2)\n",
    "    fsz = 20\n",
    "\n",
    "    m = plt.subplot(gs[0,0], projection=ccrs.PlateCarree(central_longitude=0.0))\n",
    "\n",
    "    # plot the data\n",
    "    SST_plot = SST_BIAS.copy()\n",
    "    vmin=np.nanmean(SST_plot)-3*np.nanstd(SST_plot)\n",
    "    vmax=np.nanmean(SST_plot)+3*np.nanstd(SST_plot)\n",
    "    SST_plot[SST_plot<vmin] = np.nan\n",
    "    SST_plot[SST_plot>vmax] = np.nan\n",
    "\n",
    "    p1 = plt.pcolormesh(LON,LAT,SST_plot,cmap=plt.cm.jet,vmin=vmin,vmax=vmax)\n",
    "    # add embelishments\n",
    "    m.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "    m.add_feature(cfeature.LAND, facecolor='0.75')\n",
    "    g1 = m.gridlines(draw_labels = True)\n",
    "    g1.xlabels_top = False\n",
    "    g1.ylabels_right = False\n",
    "    g1.xlabel_style = {'size': 16, 'color': 'gray'}\n",
    "    g1.ylabel_style = {'size': 16, 'color': 'gray'}\n",
    "\n",
    "    cbar = plt.colorbar(p1, orientation='horizontal', pad=0.05)\n",
    "    cbar.set_label('SST bias [K]',fontsize=fsz)\n",
    "\n",
    "    m = plt.subplot(gs[0,1], projection=ccrs.PlateCarree(central_longitude=0.0))\n",
    "    # plot the data\n",
    "    SST_plot = SST_STD_DEV.copy()\n",
    "    vmin=np.nanmean(SST_plot)-3*np.nanstd(SST_plot)\n",
    "    vmax=np.nanmean(SST_plot)+3*np.nanstd(SST_plot)\n",
    "    SST_plot[SST_plot<vmin] = np.nan\n",
    "    SST_plot[SST_plot>vmax] = np.nan\n",
    "\n",
    "    p1 = plt.pcolormesh(LON,LAT,SST_plot,cmap=plt.cm.jet,vmin=vmin,vmax=vmax)\n",
    "    # add embelishments\n",
    "    m.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "    m.add_feature(cfeature.LAND, facecolor='0.75')\n",
    "    g1 = m.gridlines(draw_labels = True)\n",
    "    g1.xlabels_top = False\n",
    "    g1.ylabels_right = False\n",
    "    g1.xlabel_style = {'size': 16, 'color': 'gray'}\n",
    "    g1.ylabel_style = {'size': 16, 'color': 'gray'}\n",
    "\n",
    "    cbar = plt.colorbar(p1, orientation='horizontal', pad=0.05)\n",
    "    cbar.set_label('SST standard deviation [K]',fontsize=fsz);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if no_show:\n",
    "        fig.savefig('plot4.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SST value we are interested in needs to be corrected for the bias, so lets do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    SST = SST + SST_BIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the bias and standard deviation plots that there are some sharp lines across the image. SLSTR uses 5 algorithms to estimate SST. Some of these algorithms use the nadir view only, while some take advantage of the 'Dual View' capability of the sensor. Dual view takes two images of the surface, one at nadir and one at an oblique angle. This allows it to better characterise the effects of the atmosphere. In practice, the nadir view is wider than the dual view, which results in a stripe along the middle of the swath. We can check which algorithms were used to derive the SST estimate by checking the SST_ALG_TYPE variable, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "    fig  = plt.figure(figsize=(10*int(np.nanmax(SST_ALG_TYPE))+1,10), dpi=150)\n",
    "    gs  = gridspec.GridSpec(1, 6)\n",
    "    gs.update(wspace=0.1, hspace=0.1)\n",
    "    fsz = 12\n",
    "\n",
    "    contour_vals = np.arange(np.nanmin(SST_ALG_TYPE)-1,np.nanmin(SST_ALG_TYPE)+1,1)\n",
    "\n",
    "    # loop through each algorithm\n",
    "    for ii in np.arange(0,int(np.nanmax(SST_ALG_TYPE))+1):\n",
    "        m = plt.subplot(gs[0,ii], projection=ccrs.PlateCarree(central_longitude=0.0))\n",
    "        MASKED_ALG_TYPE = SST_ALG_TYPE.astype('float')\n",
    "        MASKED_ALG_TYPE[MASKED_ALG_TYPE != float(ii)] = np.nan\n",
    "        # plot the data\n",
    "        plt.pcolormesh(LON,LAT,np.ma.masked_invalid(MASKED_ALG_TYPE),cmap=plt.cm.jet,vmin=0,vmax=5)\n",
    "        if ii == 0:\n",
    "            plt.text(33,-17.5,'No retrieval',fontweight='bold',fontsize=fsz*2)\n",
    "        if ii == 1:\n",
    "            plt.text(33,-17.5,'N2',fontweight='bold',fontsize=fsz*2)\n",
    "        if ii == 2:\n",
    "            plt.text(33,-17.5,'N3R',fontweight='bold',fontsize=fsz*2)\n",
    "        if ii == 3:\n",
    "            plt.text(33,-17.5,'N3',fontweight='bold',fontsize=fsz*2)\n",
    "        elif ii == 4:\n",
    "            plt.text(33,-17.5,'D2',fontweight='bold',fontsize=fsz*2)\n",
    "        elif ii == 5:\n",
    "            plt.text(33,-17.5,'D3',fontweight='bold',fontsize=fsz*2)\n",
    "\n",
    "        # add embelishments\n",
    "        m.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "        m.add_feature(cfeature.LAND, facecolor='0.75')\n",
    "        g1 = m.gridlines(draw_labels = False)\n",
    "\n",
    "        g1.xlabel_style = {'size': 16, 'color': 'gray'}\n",
    "        g1.ylabel_style = {'size': 16, 'color': 'gray'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if no_show:\n",
    "        fig.savefig('plot5.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We should remember that, just because a measurement is Nadir view only, it does not mean that it is bad! Sometimes the nadir view is the best to use. Here, though, lets finally plot our nadir+dual and our dual view data, corrected for bias, and masked for a quality level of 3 or greater. We will overlay the plot with contours from contemporaneous ECMWF wind data, that is included in with SLSTR L2 WAT products, as part of the GHRSST specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%capture\n",
    "    SST_C = SST-273.15\n",
    "\n",
    "    fig  = plt.figure(figsize=(20,20), dpi=150)\n",
    "    gs  = gridspec.GridSpec(3, 1, height_ratios=[20,0.5,1])\n",
    "    gs.update(wspace=0.01, hspace=0.01)\n",
    "\n",
    "    # set my vertical plotting order and fontsize\n",
    "    zordcoast=0\n",
    "    fsz=20\n",
    "\n",
    "    # plot the data\n",
    "    SST_plot = SST_C.copy()\n",
    "    vmin=int(np.nanmean(SST_plot)-3*np.nanstd(SST_plot))-1\n",
    "    vmax=int(np.nanmean(SST_plot)+3*np.nanstd(SST_plot))+1\n",
    "    SST_plot[SST_plot<vmin] = np.nan\n",
    "    SST_plot[SST_plot>vmax] = np.nan\n",
    "\n",
    "    m = plt.subplot(gs[0,0], projection=ccrs.PlateCarree(central_longitude=0.0))\n",
    "    p1 = plt.contourf(LON,LAT,SST_plot,100,cmap=plt.cm.jet,vmin=vmin,vmax=vmax,zorder=-1)\n",
    "    CS = plt.contour(LON,LAT,WIND_SPEED,10,linewidths=1.0,cmap=plt.get_cmap('Greys'),zorder=0)\n",
    "    plt.clabel(CS, fontsize=10, inline=1,zorder=1)\n",
    "\n",
    "    # add embelishments\n",
    "    m.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "    m.add_feature(cfeature.LAND, facecolor='0.75')\n",
    "    g1 = m.gridlines(draw_labels = True)\n",
    "    g1.xlabels_top = False\n",
    "    g1.xlabel_style = {'size': 16, 'color': 'gray'}\n",
    "    g1.ylabel_style = {'size': 16, 'color': 'gray'}\n",
    "\n",
    "    # add colorbar\n",
    "    axes0 = plt.subplot(gs[2,0])\n",
    "    cbar = plt.colorbar(p1, cax=axes0, orientation='horizontal')\n",
    "    cbar.ax.tick_params(labelsize=fsz) \n",
    "    cbar.set_label('Bias corrected, quality controlled, whole view SST [$^{o}$C]',fontsize=fsz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    bbox_inches='tight'\n",
    "    fig.savefig(os.path.join(DEFAULT_ROOT_DIR,'SLSTR_whole_SST_demo.png'),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    %%capture\n",
    "\n",
    "    SST_C = SST-273.15\n",
    "    SST_C[SST_ALG_TYPE<4] = np.nan\n",
    "\n",
    "    fig  = plt.figure(figsize=(20,20), dpi=150)\n",
    "    gs  = gridspec.GridSpec(3, 1, height_ratios=[20,1,1])\n",
    "    gs.update(wspace=0.01, hspace=0.01)  \n",
    "\n",
    "    # set my vertical plotting order and fontsize\n",
    "    zordcoast=0\n",
    "    fsz=20\n",
    "\n",
    "    # plot the data\n",
    "    SST_plot = SST_C.copy()\n",
    "    vmin=int(np.nanmean(SST_plot)-3*np.nanstd(SST_plot))-1\n",
    "    vmax=int(np.nanmean(SST_plot)+3*np.nanstd(SST_plot))+1\n",
    "    SST_plot[SST_plot<vmin] = np.nan\n",
    "    SST_plot[SST_plot>vmax] = np.nan\n",
    "\n",
    "    m = plt.subplot(gs[0,0], projection=ccrs.PlateCarree(central_longitude=0.0))\n",
    "    p1 = m.contourf(LON,LAT,SST_plot,100,cmap=plt.cm.jet,vmin=vmin,vmax=vmax,zorder=-1)\n",
    "    CS = m.contour(LON,LAT,WIND_SPEED,10,linewidths=1.0,cmap=plt.get_cmap('Greys'),zorder=0)\n",
    "    plt.clabel(CS, fontsize=14, inline=1,zorder=1)\n",
    "\n",
    "    # add embelishments\n",
    "    m.coastlines(resolution='50m', color='black', linewidth=1)\n",
    "    m.add_feature(cfeature.LAND, facecolor='0.75')\n",
    "    g1 = m.gridlines(draw_labels = True)\n",
    "    g1.xlabels_top = False\n",
    "    g1.xlabel_style = {'size': 16, 'color': 'gray'}\n",
    "    g1.ylabel_style = {'size': 16, 'color': 'gray'}\n",
    "    \n",
    "    # add colorbar\n",
    "    axes0 = plt.subplot(gs[2,0])\n",
    "    cbar = plt.colorbar(p1, cax=axes0, orientation='horizontal')\n",
    "    cbar.ax.tick_params(labelsize=fsz) \n",
    "    cbar.set_label('Bias corrected, quality controlled, dual view SST [$^{o}$C]',fontsize=fsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    bbox_inches='tight'\n",
    "    fig.savefig(os.path.join(DEFAULT_ROOT_DIR,'SLSTR_dual_SST_demo.png'),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
