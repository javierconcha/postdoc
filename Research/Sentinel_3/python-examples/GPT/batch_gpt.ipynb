{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT batch script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This routine shows an example of how to use python to call SNAP's GPT processor, to allow automated processing of S3A OLCI L1 images from the command line.\n",
    "\n",
    "    Version: 1.1\n",
    "    Author: B Loveday, PML\n",
    "    Notes:\n",
    "    1. A batch scripting version of the same file, batch_gpt.py, can be found in the same folder.\n",
    "    2. Both this script, and the batch version, will require you to adapt the paths to the GPT executable and data\n",
    "       on your local system.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing some python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "from os import path, listdir, system\n",
    "import fnmatch\n",
    "import fileinput\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to tell our code where the GPT executable is. The default path is hown below, but you may have to adapt this depending on where you installed SNAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "# set up the environment, path to your gpt processor\n",
    "gptProcessor = '/Users/jconchas/Applications/snap/bin/gpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must point the code to our config file (in the same directory as this file), and the data we downloaded. It is the configuration file that describes the processes that SNAP will perform in our automated chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jconchas/Documents/Research/Sentinel_3/python-examples/GPT/GPT_L1_input\n",
      "/Users/jconchas/Documents/Research/Sentinel_3/python-examples/GPT/GPT_L2_output\n"
     ]
    }
   ],
   "source": [
    "# define your graph xml, and input and output directory paths\n",
    "template_xml = path.join(os.getcwd(),'config_template.xml')\n",
    "input_dir = path.join(os.getcwd(),'GPT_L1_input')\n",
    "output_dir = path.join(os.getcwd(),'GPT_L2_output')\n",
    "print(input_dir)\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we search the input directory to find Level-1 Sentinel-3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/jconchas/Documents/Research/Sentinel_3/python-examples/GPT/GPT_L1_input/S3A_OL_1_EFR____20181003T014336_20181003T014636_20181003T034142_0179_036_231_2340_MAR_O_NR_002.SEN3/xfdumanifest.xml']\n"
     ]
    }
   ],
   "source": [
    "# INPUTS\n",
    "# make a list of all the input files in your input directory\n",
    "input_files=[]\n",
    "for root, _, filenames in os.walk(input_dir):\n",
    "    for filename in fnmatch.filter(filenames, '*xfdumanifest.xml'):\n",
    "        input_files.append(os.path.join(root, filename))\n",
    "        \n",
    "print(input_files)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we start the main part of our code, where we call GPT to process this L1 data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /Users/jconchas/Documents/Research/Sentinel_3/python-examples/GPT/GPT_L1_input/S3A_OL_1_EFR____20181003T014336_20181003T014636_20181003T034142_0179_036_231_2340_MAR_O_NR_002.SEN3/xfdumanifest.xml\n",
      "To: /Users/jconchas/Documents/Research/Sentinel_3/python-examples/GPT/GPT_L2_output/S3A_OL_1_EFR____20181003T014336_20181003T014636_20181003T034142_0179_036_231_2340_MAR_O_NR_002_SUBSET_IDEPIX_C2RCC.nc\n",
      "Generating config: /Users/jconchas/Documents/Research/Sentinel_3/python-examples/GPT/GPT_L1_input/S3A_OL_1_EFR____20181003T014336_20181003T014636_20181003T034142_0179_036_231_2340_MAR_O_NR_002.SEN3/run_config.xml\n",
      "Adapting config: /Users/jconchas/Documents/Research/Sentinel_3/python-examples/GPT/GPT_L1_input/S3A_OL_1_EFR____20181003T014336_20181003T014636_20181003T034142_0179_036_231_2340_MAR_O_NR_002.SEN3/run_config.xml\n",
      "Config ready; launching:\n",
      "/Users/jconchas/Applications/snap/bin/gpt /Users/jconchas/Documents/Research/Sentinel_3/python-examples/GPT/GPT_L1_input/S3A_OL_1_EFR____20181003T014336_20181003T014636_20181003T034142_0179_036_231_2340_MAR_O_NR_002.SEN3/run_config.xml\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "# this is the loop where the magic happens :-)\n",
    "# the loop goes over each input file in the input_files list\n",
    "for input_file in input_files:\n",
    "    file_tag = os.path.basename(os.path.dirname(input_file))\n",
    "    file_tag = file_tag.replace('.SEN3','')\n",
    "    output_file = input_file.replace(input_dir,output_dir)\n",
    "    output_file = output_file.replace('.SEN3/xfdumanifest.xml','_SUBSET_IDEPIX_C2RCC.nc')\n",
    "    # the output file is named from the input file with the _C2RCCC suffix.\n",
    "    # Here you will write a netcdf file. this can be changed\n",
    "    print('Processing: '+str(input_file))\n",
    "    print('To: '+str(output_file))\n",
    "    \n",
    "    # now adapt the config xml file for this specific input_file\n",
    "    my_config = input_file.replace('xfdumanifest.xml','run_config.xml')\n",
    "    if os.path.exists(my_config):\n",
    "        os.remove(my_config)\n",
    "\n",
    "    print('Generating config: '+str(my_config))\n",
    "    shutil.copy(template_xml,my_config)\n",
    "\n",
    "    print('Adapting config: '+str(my_config))\n",
    "    \n",
    "    # Read in the file\n",
    "    with open(my_config, 'r') as file :\n",
    "        filedata = file.read()\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('SOURCE_PRODUCT', input_file)\n",
    "    # Write the file out again\n",
    "    with open(my_config, 'w') as file:\n",
    "        file.write(filedata)\n",
    "\n",
    "    # Read in the file\n",
    "    with open(my_config, 'r') as file :\n",
    "        filedata = file.read()\n",
    "    # Replace the target string\n",
    "    filedata = filedata.replace('OUTPUT_PRODUCT', output_file)\n",
    "    # Write the file out again\n",
    "    with open(my_config, 'w') as file:\n",
    "        file.write(filedata)\n",
    "        \n",
    "    # the processing call is a follows below.\n",
    "    c2rcc_processingCall = gptProcessor + ' ' + my_config\n",
    "\n",
    "    # useful to check that the command call is correct before launching the call (comment / uncomment the next line)\n",
    "    print('Config ready; launching:')\n",
    "    print(c2rcc_processingCall)\n",
    "\n",
    "    # python call, uncomment when the printed call satisfies your requirements\n",
    "    system(c2rcc_processingCall)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
